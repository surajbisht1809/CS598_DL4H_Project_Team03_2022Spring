{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49fsvRy3ehFi","executionInfo":{"status":"ok","timestamp":1651154979898,"user_tz":300,"elapsed":653,"user":{"displayName":"Suraj Bisht","userId":"14494261012766270308"}},"outputId":"bec90ec4-fc34-46b9-ddee-91bf7252863c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NX-XlerAdtTa"},"outputs":[],"source":["import pandas as pd\n","import os\n","import numpy as np\n","#from gensim.models import Word2Vec, FastText\n","#import glove\n","#from glove import Corpus\n","\n","import collections\n","import gc \n","\n","import keras\n","from keras import backend as K\n","from keras import regularizers\n","from keras.models import Sequential, Model\n","from keras.layers import Flatten, Dense, Dropout, Input, concatenate, merge, Activation, Concatenate, LSTM, GRU\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, BatchNormalization, GRU, Convolution1D, LSTM\n","from keras.layers import UpSampling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D,MaxPool1D, merge\n","\n","#from keras.optimizers import Adam\n","\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, History, ReduceLROnPlateau\n","from keras.utils import np_utils\n","#from keras.backend.tensorflow_backend import set_session, clear_session, get_session\n","from keras.backend import set_session, clear_session, get_session\n","import tensorflow as tf\n","\n","\n","from sklearn.utils import class_weight\n","from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["# Reset Keras Session\n","def reset_keras(model):\n","    sess = get_session()\n","    clear_session()\n","    sess.close()\n","    sess = get_session()\n","\n","    try:\n","        del model # this is from global space - change this as you need\n","    except:\n","        pass\n","\n","    gc.collect() # if it's done something you should see a number being outputted"],"metadata":{"id":"-aIAOUBRGXEe"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jimBrnTCdtTx"},"outputs":[],"source":["def create_dataset(dict_of_ner):\n","    temp_data = []\n","    for k, v in sorted(dict_of_ner.items()):\n","        temp = []\n","        for embed in v:\n","            temp.append(embed)\n","        temp_data.append(np.mean(temp, axis = 0)) \n","    return np.asarray(temp_data)\n","\n","def make_prediction_multi_avg(model, test_data):\n","    probs = model.predict(test_data)\n","    y_pred = [1 if i>=0.5 else 0 for i in probs]\n","    return probs, y_pred\n","\n","def save_scores_multi_avg(predictions, probs, ground_truth, \n","                          \n","                          embed_name, problem_type, iteration, hidden_unit_size,\n","                          \n","                          sequence_name, type_of_ner):\n","    \n","    auc = roc_auc_score(ground_truth, probs)\n","    auprc = average_precision_score(ground_truth, probs)\n","    acc   = accuracy_score(ground_truth, predictions)\n","    F1    = f1_score(ground_truth, predictions)\n","    \n","    result_dict = {}    \n","    result_dict['auc'] = auc\n","    result_dict['auprc'] = auprc\n","    result_dict['acc'] = acc\n","    result_dict['F1'] = F1\n","    \n","    result_path = \"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/results/\"\n","    file_name = str(sequence_name)+\"-\"+str(hidden_unit_size)+\"-\"+embed_name\n","    file_name = file_name +\"-\"+problem_type+\"-\"+str(iteration)+\"-\"+type_of_ner+\"-avg-.p\"\n","    pd.to_pickle(result_dict, os.path.join(result_path, file_name))\n","\n","    print(auc, auprc, acc, F1)\n","    \n","def avg_ner_model(layer_name, number_of_unit, embedding_name):\n","\n","    if embedding_name == \"concat\":\n","        input_dimension = 200\n","        #print(\"input_dimension\", input_dimension)\n","    else:\n","        input_dimension = 100\n","    input_dimension = 100\n","    sequence_input = Input(shape=(24,104))\n","\n","    input_avg = Input(shape=(input_dimension, ), name = \"avg\")        \n","#     x_1 = Dense(256, activation='relu')(input_avg)\n","#     x_1 = Dropout(0.3)(x_1)\n","    \n","    if layer_name == \"GRU\":\n","        x = GRU(number_of_unit)(sequence_input)\n","    elif layer_name == \"LSTM\":\n","        x = LSTM(number_of_unit)(sequence_input)\n","\n","    x = keras.layers.Concatenate()([x, input_avg])\n","\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","    \n","    \n","    #logits_regularizer = tf.contrib.layers.l2_regularizer(scale=0.01)\n","    logits_regularizer = tf.keras.regularizers.L2(0.01)\n","    preds = Dense(1, activation='sigmoid',use_bias=False,\n","                         kernel_initializer=tf.keras.initializers.glorot_normal(), \n","                  kernel_regularizer=logits_regularizer)(x)\n","    \n","    \n","    #opt = Adam(lr=0.001, decay = 0.01)\n","    model = Model(inputs=[sequence_input, input_avg], outputs=preds)\n","    model.compile(loss='binary_crossentropy',\n","                  optimizer=\"adam\",\n","                  metrics=['acc'])\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XVpt6AQ2EGdS"},"outputs":[],"source":["lvl2_train =  pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/lvl2_imputer_train_los.pkl\")\n","lvl2_dev =  pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/lvl2_imputer_dev_los.pkl\")\n","lvl2_test =  pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/lvl2_imputer_test_los.pkl\")\n","\n","Ys =  pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/Ys_los.pkl\")\n","Ys_train =  pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/Ys_train_los.pkl\")\n","Ys_dev =  pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/Ys_dev_los.pkl\")\n","Ys_test =  pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/Ys_test_los.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uxy2Bi0aEGdT","executionInfo":{"status":"ok","timestamp":1651154993222,"user_tz":300,"elapsed":199,"user":{"displayName":"Suraj Bisht","userId":"14494261012766270308"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"741887ed-c050-44ba-9bcd-9ba752bd6990"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.07159904534606205\n","0.06725146198830409\n","0.07432150313152401\n","====\n","0.10680190930787589\n","0.09649122807017543\n","0.10855949895615867\n","====\n","0.43323389021479713\n","0.42105263157894735\n","0.4246346555323591\n","====\n","0.07696897374701671\n","0.07268170426065163\n","0.07954070981210856\n"]}],"source":["all_train_ids = set()\n","for i in Ys_train.itertuples():\n","    all_train_ids.add( i.Index[0] )\n","    \n","all_dev_ids = set()\n","for i in Ys_dev.itertuples():\n","    all_dev_ids.add( i.Index[0] )\n","    \n","all_test_ids = set()\n","for i in Ys_test.itertuples():\n","    all_test_ids.add( i.Index[0] )\n","\n","print (sum(Ys_train.mort_icu.values)*1.0 / len(Ys_train.mort_icu.values))\n","print (sum(Ys_dev.mort_icu.values)*1.0 / len(Ys_dev.mort_icu.values))\n","print (sum(Ys_test.mort_icu.values)*1.0 / len(Ys_test.mort_icu.values))\n","print (\"====\")\n","print (sum(Ys_train.mort_hosp.values)*1.0 / len(Ys_train.mort_hosp.values))\n","print (sum(Ys_dev.mort_hosp.values)*1.0 / len(Ys_dev.mort_hosp.values))\n","print (sum(Ys_test.mort_hosp.values)*1.0 / len(Ys_test.mort_hosp.values))\n","print (\"====\")\n","print (sum(Ys_train.los_3.values)*1.0 / len(Ys_train.los_3.values))\n","print (sum(Ys_dev.los_3.values)*1.0 / len(Ys_dev.los_3.values))\n","print (sum(Ys_test.los_3.values)*1.0 / len(Ys_test.los_3.values))\n","print (\"====\")\n","print (sum(Ys_train.los_7.values)*1.0 / len(Ys_train.los_7.values))\n","print (sum(Ys_dev.los_7.values)*1.0 / len(Ys_dev.los_7.values))\n","print (sum(Ys_test.los_7.values)*1.0 / len(Ys_test.los_7.values))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0UWuADlkdtUA","executionInfo":{"status":"ok","timestamp":1651155018512,"user_tz":300,"elapsed":25293,"user":{"displayName":"Suraj Bisht","userId":"14494261012766270308"}},"outputId":"11881623-a648-449f-ed27-3a95e656d53c"},"outputs":[{"output_type":"stream","name":"stdout","text":["train_ids =  [3, 9, 12, 13, 17, 19, 21, 25, 30, 31, 35, 41, 45, 52, 55, 56, 61, 62, 64, 65, 68, 71, 78, 81, 83, 85, 88, 97, 99, 100, 101, 103, 105, 106, 114, 115, 123, 124, 127, 129, 130, 133, 134, 135, 137, 140, 141, 143, 144, 146, 147, 149, 152, 160, 163, 169, 170, 171, 173, 174, 175, 177, 178, 186, 191, 195, 201, 202, 205, 208, 209, 211, 212, 214, 222, 225, 226, 228, 234, 238, 242, 245, 249, 251, 253, 255, 256, 261, 262, 265, 267, 268, 269, 270, 271, 272, 273, 274, 275, 279, 281, 287, 290, 298, 301, 302, 305, 306, 307, 309, 310, 313, 314, 315, 318, 319, 321, 323, 326, 329, 330, 335, 344, 345, 346, 347, 350, 351, 353, 354, 356, 360, 364, 366, 367, 370, 371, 379, 383, 389, 391, 394, 395, 396, 397, 400, 402, 406, 407, 409, 417, 418, 420, 421, 422, 424, 429, 434, 436, 437, 438, 439, 440, 445, 448, 452, 453, 458, 462, 464, 466, 468, 471, 472, 477, 481, 482, 485, 487, 489, 491, 492, 498, 503, 507, 510, 518, 523, 533, 536, 538, 539, 540, 543, 545, 554, 557, 558, 559, 561, 564, 569, 577, 580, 586, 590, 593, 599, 600, 601, 603, 605, 612, 614, 616, 624, 634, 638, 639, 642, 650, 653, 654, 655, 657, 663, 667, 671, 672, 674, 676, 678, 680, 681, 689, 690, 695, 699, 700, 705, 707, 708, 710, 715, 716, 719, 721, 723, 727, 729, 733, 740, 741, 743, 745, 747, 749, 750, 757, 766, 767, 771, 772, 774, 776, 779, 786, 787, 788, 793, 794, 797, 799, 805, 806, 808, 811, 813, 815, 816, 819, 820, 822, 831, 841, 843, 854, 859, 860, 867, 870, 871, 875, 878, 880, 883, 884, 886, 888, 891, 894, 897, 899, 902, 903, 909, 913, 921, 925, 928, 931, 935, 943, 945, 949, 950, 957, 960, 971, 975, 976, 977, 978, 980, 984, 989, 990, 992, 998, 1004, 1009, 1010, 1012, 1016, 1017, 1021, 1026, 1027, 1028, 1030, 1032, 1033, 1038, 1040, 1041, 1042, 1046, 1049, 1050, 1053, 1059, 1060, 1066, 1073, 1076, 1077, 1084, 1088, 1091, 1092, 1093, 1095, 1096, 1102, 1106, 1113, 1119, 1120, 1121, 1124, 1125, 1127, 1128, 1137, 1140, 1143, 1144, 1148, 1158, 1162, 1165, 1166, 1167, 1168, 1173, 1178, 1182, 1183, 1187, 1190, 1192, 1196, 1197, 1198, 1199, 1209, 1214, 1217, 1223, 1224, 1227, 1231, 1232, 1239, 1244, 1245, 1247, 1251, 1256, 1257, 1258, 1262, 1263, 1264, 1265, 1266, 1267, 1272, 1276, 1282, 1283, 1286, 1293, 1299, 1300, 1305, 1309, 1311, 1314, 1317, 1321, 1325, 1326, 1329, 1332, 1333, 1337, 1343, 1344, 1347, 1348, 1351, 1353, 1355, 1357, 1358, 1367, 1372, 1374, 1375, 1377, 1378, 1385, 1387, 1395, 1396, 1397, 1406, 1410, 1417, 1419, 1430, 1438, 1439, 1443, 1446, 1449, 1457, 1459, 1462, 1463, 1469, 1471, 1472, 1473, 1476, 1485, 1486, 1491, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1513, 1515, 1518, 1522, 1524, 1527, 1528, 1530, 1531, 1533, 1534, 1535, 1540, 1541, 1543, 1544, 1546, 1550, 1554, 1559, 1565, 1568, 1569, 1574, 1575, 1581, 1583, 1586, 1588, 1601, 1604, 1606, 1610, 1614, 1615, 1623, 1627, 1629, 1634, 1639, 1642, 1645, 1648, 1649, 1652, 1653, 1658, 1660, 1663, 1665, 1676, 1679, 1685, 1691, 1694, 1699, 1701, 1704, 1707, 1714, 1719, 1720, 1724, 1727, 1729, 1738, 1739, 1746, 1747, 1751, 1761, 1766, 1777, 1778, 1782, 1786, 1788, 1791, 1794, 1795, 1796, 1797, 1798, 1802, 1803, 1805, 1807, 1808, 1809, 1813, 1815, 1816, 1819, 1820, 1822, 1825, 1829, 1832, 1833, 1837, 1839, 1840, 1842, 1845, 1848, 1849, 1856, 1858, 1859, 1860, 1861, 1866, 1873, 1879, 1882, 1885, 1888, 1890, 1892, 1895, 1898, 1899, 1900, 1901, 1902, 1905, 1907, 1908, 1909, 1913, 1915, 1918, 1919, 1931, 1932, 1936, 1937, 1939, 1941, 1944, 1945, 1946, 1948, 1949, 1968, 1969, 1970, 1972, 1973, 1979, 1980, 1981, 1982, 1984, 1985, 1988, 1989, 1990, 1991, 1994, 1995, 1996, 2001, 2002, 2004, 2006, 2011, 2012, 2015, 2016, 2019, 2025, 2033, 2035, 2040, 2045, 2047, 2048, 2049, 2051, 2053, 2054, 2056, 2057, 2070, 2074, 2078, 2079, 2082, 2086, 2090, 2091, 2093, 2096, 2098, 2099, 2103, 2104, 2113, 2115, 2119, 2121, 2123, 2124, 2128, 2132, 2133, 2136, 2143, 2146, 2149, 2150, 2155, 2158, 2159, 2170, 2171, 2176, 2177, 2179, 2180, 2183, 2185, 2186, 2190, 2194, 2195, 2196, 2200, 2205, 2206, 2208, 2212, 2215, 2220, 2222, 2224, 2225, 2228, 2229, 2234, 2235, 2238, 2239, 2240, 2247, 2253, 2256, 2261, 2262, 2263, 2264, 2274, 2281, 2284, 2289, 2291, 2292, 2304, 2309, 2320, 2326, 2330, 2337, 2340, 2343, 2344, 2345, 2346, 2348, 2349, 2353, 2354, 2355, 2356, 2362, 2364, 2365, 2366, 2369, 2371, 2372, 2373, 2374, 2377, 2383, 2392, 2395, 2398, 2399, 2403, 2405, 2406, 2411, 2417, 2423, 2425, 2427, 2432, 2434, 2438, 2441, 2445, 2446, 2451, 2452, 2455, 2456, 2462, 2470, 2476, 2477, 2478, 2482, 2483, 2484, 2489, 2491, 2492, 2493, 2497, 2498, 2505, 2510, 2518, 2522, 2533, 2534, 2538, 2540, 2544, 2548, 2552, 2553, 2558, 2562, 2568, 2573, 2578, 2579, 2581, 2590, 2598, 2599, 2603, 2605, 2608, 2610, 2613, 2616, 2619, 2622, 2623, 2625, 2637, 2639, 2640, 2641, 2642, 2644, 2648, 2649, 2650, 2652, 2658, 2666, 2670, 2674, 2679, 2684, 2688, 2691, 2694, 2700, 2702, 2703, 2707, 2710, 2718, 2722, 2723, 2726, 2727, 2729, 2735, 2741, 2742, 2744, 2754, 2756, 2757, 2758, 2763, 2769, 2773, 2779, 2786, 2787, 2790, 2791, 2793, 2797, 2798, 2802, 2805, 2806, 2809, 2810, 2811, 2817, 2819, 2821, 2827, 2840, 2841, 2842, 2850, 2852, 2853, 2859, 2863, 2874, 2878, 2879, 2882, 2894, 2896, 2904, 2905, 2912, 2915, 2916, 2917, 2921, 2924, 2925, 2934, 2937, 2938, 2940, 2941, 2943, 2944, 2945, 2946, 2947, 2948, 2952, 2956, 2957, 2958, 2963, 2968, 2969, 2973, 2974, 2975, 2978, 2979, 2986, 2988, 2996, 3002, 3018, 3020, 3026, 3029, 3030, 3031, 3032, 3035, 3036, 3038, 3042, 3044, 3045, 3049, 3052, 3055, 3065, 3073, 3081, 3084, 3087, 3090, 3092, 3100, 3102, 3103, 3110, 3111, 3116, 3132, 3135, 3137, 3138, 3139, 3143, 3150, 3151, 3154, 3155, 3156, 3161, 3165, 3172, 3174, 3176, 3177, 3178, 3180, 3181, 3182, 3189, 3190, 3194, 3196, 3199, 3201, 3202, 3203, 3205, 3214, 3216, 3217, 3218, 3220, 3221, 3225, 3226, 3227, 3232, 3234, 3236, 3238, 3239, 3245, 3248, 3252, 3253, 3254, 3257, 3265, 3266, 3272, 3273, 3274, 3275, 3276, 3277, 3279, 3283, 3286, 3287, 3288, 3289, 3292, 3298, 3301, 3304, 3306, 3307, 3309, 3312, 3320, 3323, 3326, 3327, 3333, 3335, 3347, 3356, 3357, 3359, 3360, 3361, 3362, 3364, 3373, 3377, 3380, 3388, 3390, 3393, 3395, 3399, 3400, 3415, 3419, 3426, 3430, 3435, 3436, 3440, 3449, 3456, 3457, 3458, 3459, 3460, 3461, 3466, 3471, 3474, 3475, 3477, 3482, 3483, 3485, 3489, 3490, 3491, 3494, 3496, 3498, 3515, 3523, 3530, 3533, 3538, 3539, 3542, 3547, 3549, 3552, 3553, 3555, 3556, 3557, 3559, 3560, 3564, 3566, 3569, 3571, 3572, 3574, 3575, 3586, 3587, 3588, 3590, 3591, 3593, 3601, 3620, 3622, 3623, 3630, 3633, 3637, 3644, 3649, 3650, 3651, 3652, 3653, 3656, 3657, 3659, 3666, 3673, 3674, 3676, 3677, 3678, 3680, 3691, 3699, 3702, 3705, 3706, 3711, 3715, 3716, 3718, 3727, 3734, 3736, 3737, 3738, 3740, 3743, 3744, 3745, 3746, 3747, 3751, 3759, 3760, 3763, 3765, 3771, 3772, 3780, 3781, 3784, 3794, 3796, 3810, 3811, 3814, 3815, 3816, 3818, 3820, 3824, 3826, 3827, 3830, 3831, 3835, 3836, 3838, 3839, 3840, 3847, 3848, 3850, 3852, 3854, 3855, 3856, 3867, 3871, 3874, 3876, 3877, 3879, 3881, 3882, 3883, 3887, 3889, 3896, 3897, 3910, 3912, 3913, 3919, 3924, 3926, 3929, 3935, 3945, 3948, 3949, 3951, 3954, 3955, 3957, 3958, 3964, 3965, 3968, 3969, 3973, 3977, 3978, 3981, 3986, 3987, 3988, 3989, 3990, 3992, 3993, 3995, 3996, 3998, 3999, 4001, 4002, 4003, 4005, 4006, 4013, 4016, 4018, 4022, 4030, 4032, 4038, 4039, 4041, 4042, 4043, 4048, 4052, 4058, 4060, 4062, 4063, 4067, 4068, 4070, 4072, 4079, 4082, 4097, 4098, 4104, 4112, 4113, 4115, 4118, 4121, 4127, 4132, 4135, 4137, 4140, 4142, 4147, 4148, 4151, 4152, 4155, 4166, 4171, 4175, 4183, 4184, 4185, 4187, 4191, 4194, 4195, 4200, 4208, 4211, 4220, 4223, 4228, 4230, 4236, 4239, 4240, 4242, 4245, 4246, 4248, 4249, 4252, 4254, 4255, 4257, 4259, 4263, 4264, 4265, 4266, 4271, 4272, 4273, 4274, 4277, 4279, 4285, 4288, 4290, 4291, 4297, 4299, 4301, 4307, 4312, 4318, 4328, 4329, 4330, 4331, 4336, 4343, 4344, 4347, 4348, 4350, 4356, 4357, 4359, 4362, 4367, 4369, 4374, 4388, 4395, 4397, 4398, 4401, 4403, 4404, 4405, 4407, 4408, 4409, 4416, 4420, 4421, 4422, 4424, 4429, 4435, 4439, 4444, 4449, 4452, 4456, 4463, 4464, 4465, 4467, 4469, 4472, 4474, 4477, 4478, 4480, 4481, 4484, 4487, 4490, 4491, 4495, 4496, 4497, 4498, 4499, 4500, 4504, 4509, 4518, 4521, 4522, 4536, 4537, 4538, 4546, 4550, 4552, 4557, 4566, 4568, 4570, 4575, 4577, 4579, 4584, 4589, 4591, 4592, 4593, 4594, 4597, 4598, 4600, 4606, 4611, 4614, 4618, 4619, 4623, 4624, 4627, 4633, 4637, 4646, 4657, 4669, 4670, 4671, 4677, 4687, 4690, 4695, 4697, 4699, 4700, 4705, 4712, 4719, 4720, 4725, 4729, 4735, 4737, 4740, 4741, 4742, 4745, 4757, 4760, 4762, 4765, 4766, 4771, 4784, 4785, 4786, 4791, 4792, 4796, 4797, 4798, 4799, 4803, 4805, 4807, 4809, 4811, 4812, 4814, 4822, 4823, 4828, 4833, 4835, 4842, 4848, 4849, 4852, 4857, 4861, 4862, 4866, 4873, 4874, 4875, 4879, 4891, 4893, 4894, 4897, 4899, 4901, 4906, 4907, 4910, 4916, 4918, 4920, 4923, 4924, 4927, 4929, 4947, 4948, 4949, 4951, 4954, 4955, 4957, 4958, 4961, 4963, 4965, 4966, 4967, 4973, 4976, 4979, 4980, 4987, 4990, 4993, 5000, 5004, 5006, 5013, 5018, 5021, 5026, 5029, 5031, 5033, 5034, 5035, 5037, 5039, 5042, 5044, 5045, 5046, 5050, 5051, 5052, 5056, 5058, 5070, 5071, 5074, 5077, 5080, 5085, 5087, 5091, 5096, 5097, 5107, 5109, 5112, 5114, 5120, 5124, 5127, 5128, 5129, 5135, 5136, 5137, 5140, 5145, 5147, 5155, 5161, 5164, 5168, 5169, 5170, 5175, 5188, 5190, 5195, 5201, 5211, 5215, 5223, 5236, 5237, 5238, 5239, 5241, 5244, 5250, 5254, 5255, 5258, 5261, 5263, 5275, 5277, 5282, 5285, 5302, 5310, 5313, 5317, 5327, 5336, 5337, 5340, 5348, 5353, 5357, 5358, 5360, 5364, 5366, 5376, 5377, 5383, 5385, 5389, 5391, 5393, 5395, 5400, 5407, 5410, 5411, 5417, 5425, 5428, 5430, 5434, 5442, 5445, 5446, 5450, 5454, 5460, 5461, 5462, 5465, 5466, 5467, 5470, 5471, 5472, 5476, 5481, 5482, 5485, 5487, 5489, 5490, 5493, 5494, 5495, 5500, 5502, 5503, 5504, 5509, 5512, 5516, 5518, 5532, 5537, 5542, 5544, 5547, 5548, 5553, 5554, 5561, 5562, 5564, 5574, 5575, 5583, 5587, 5594, 5597, 5598, 5599, 5603, 5606, 5607, 5608, 5609, 5610, 5611, 5613, 5616, 5617, 5620, 5623, 5629, 5631, 5634, 5636, 5637, 5639, 5641, 5643, 5661, 5664, 5666, 5668, 5675, 5676, 5678, 5690, 5694, 5697, 5701, 5705, 5710, 5712, 5713, 5719, 5722, 5724, 5726, 5729, 5737, 5740, 5742, 5750, 5753, 5754, 5760, 5761, 5765, 5770, 5774, 5775, 5778, 5784, 5785, 5788, 5789, 5791, 5795, 5799, 5801, 5808, 5809, 5814, 5820, 5823, 5824, 5841, 5844, 5845, 5846, 5847, 5849, 5850, 5857, 5862, 5863, 5866, 5867, 5878, 5879, 5880, 5881, 5885, 5886, 5888, 5897, 5908, 5909, 5911, 5921, 5922, 5928, 5929, 5930, 5932, 5936, 5938, 5939, 5949, 5953, 5958, 5962, 5964, 5966, 5967, 5968, 5975, 5976, 5982, 5986, 5990, 5993, 5995, 5996, 6001, 6002, 6005, 6008, 6012, 6014, 6024, 6027, 6037, 6038, 6043, 6047, 6049, 6052, 6053, 6054, 6061, 6064, 6066, 6067, 6068, 6069, 6070, 6072, 6073, 6080, 6081, 6086, 6088, 6089, 6092, 6093, 6097, 6107, 6108, 6109, 6114, 6115, 6123, 6124, 6125, 6129, 6138, 6141, 6151, 6155, 6158, 6160, 6166, 6168, 6170, 6171, 6176, 6178, 6180, 6181, 6183, 6184, 6185, 6189, 6190, 6191, 6195, 6196, 6201, 6204, 6212, 6215, 6216, 6217, 6224, 6228, 6233, 6237, 6239, 6251, 6254, 6255, 6256, 6258, 6268, 6271, 6272, 6275, 6276, 6279, 6284, 6287, 6289, 6290, 6291, 6309, 6311, 6313, 6315, 6318, 6321, 6331, 6338, 6340, 6345, 6346, 6348, 6349, 6356, 6358, 6360, 6362, 6365, 6368, 6369, 6375, 6383, 6387, 6392, 6396, 6397, 6398, 6399, 6407, 6414, 6416, 6421, 6424, 6426, 6429, 6436, 6437, 6440, 6441, 6447, 6448, 6461, 6466, 6468, 6471, 6472, 6473, 6475, 6477, 6479, 6481, 6482, 6489, 6497, 6505, 6510, 6511, 6513, 6515, 6516, 6520, 6522, 6525, 6526, 6527, 6535, 6537, 6546, 6552, 6553, 6557, 6558, 6563, 6569, 6570, 6574, 6576, 6578, 6580, 6581, 6582, 6583, 6588, 6598, 6604, 6605, 6609, 6624, 6625, 6628, 6630, 6649, 6652, 6653, 6657, 6661, 6670, 6673, 6682, 6685, 6686, 6687, 6688, 6690, 6691, 6692, 6693, 6695, 6700, 6703, 6704, 6706, 6708, 6712, 6713, 6715, 6718, 6720, 6722, 6729, 6730, 6732, 6733, 6735, 6739, 6741, 6745, 6746, 6749, 6755, 6758, 6760, 6761, 6770, 6772, 6773, 6783, 6797, 6799, 6800, 6802, 6803, 6806, 6809, 6810, 6817, 6823, 6825, 6828, 6830, 6834, 6845, 6847, 6854, 6856, 6862, 6863, 6867, 6868, 6871, 6873, 6874, 6875, 6876, 6877, 6880, 6881, 6883, 6890, 6891, 6894, 6898, 6901, 6903, 6904, 6906, 6908, 6910, 6914, 6916, 6917, 6918, 6920, 6924, 6927, 6928, 6930, 6938, 6940, 6942, 6950, 6951, 6952, 6953, 6958, 6959, 6973, 6979, 6982, 6983, 6984, 6986, 6989, 6999, 7001, 7002, 7008, 7010, 7015, 7016, 7023, 7024, 7030, 7031, 7033, 7036, 7038, 7042, 7045, 7046, 7049, 7050, 7056, 7060, 7062, 7063, 7064, 7065, 7068, 7075, 7077, 7080, 7084, 7086, 7087, 7094, 7095, 7097, 7101, 7102, 7103, 7105, 7110, 7112, 7115, 7118, 7121, 7123, 7125, 7133, 7134, 7138, 7139, 7142, 7144, 7147, 7148, 7151, 7152, 7155, 7159, 7164, 7167, 7171, 7172, 7173, 7177, 7178, 7182, 7183, 7184, 7187, 7188, 7189, 7190, 7192, 7197, 7201, 7209, 7212, 7213, 7214, 7216, 7217, 7221, 7224, 7227, 7228, 7231, 7235, 7246, 7247, 7248, 7254, 7255, 7258, 7259, 7260, 7265, 7267, 7272, 7276, 7281, 7282, 7283, 7284, 7287, 7291, 7292, 7294, 7296, 7297, 7304, 7309, 7314, 7316, 7319, 7323, 7326, 7327, 7333, 7334, 7335, 7336, 7338, 7339, 7340, 7352, 7356, 7357, 7363, 7365, 7368, 7371, 7375, 7379, 7387, 7388, 7390, 7391, 7394, 7396, 7397, 7400, 7401, 7402, 7405, 7406, 7414, 7415, 7420, 7422, 7427, 7432, 7433, 7438, 7440, 7442, 7454, 7455, 7463, 7464, 7470, 7472, 7473, 7475, 7479, 7481, 7488, 7489, 7490, 7493, 7494, 7499, 7507, 7514, 7516, 7519, 7521, 7525, 7532, 7533, 7536, 7537, 7539, 7543, 7549, 7565, 7567, 7570, 7571, 7572, 7573, 7580, 7583, 7584, 7586, 7589, 7595, 7596, 7599, 7600, 7602, 7603, 7605, 7606, 7615, 7621, 7628, 7630, 7632, 7636, 7640, 7641, 7652, 7654, 7656, 7659, 7664, 7665, 7668, 7669, 7671, 7672, 7673, 7675, 7681, 7693, 7694, 7697, 7698, 7700, 7703, 7705, 7708, 7709, 7710, 7711, 7724, 7728, 7731, 7735, 7738, 7742, 7744, 7749, 7753, 7755, 7758, 7763, 7774, 7775, 7781, 7782, 7784, 7795, 7801, 7804, 7816, 7817, 7818, 7825, 7826, 7828, 7831, 7840, 7843, 7848, 7853, 7855, 7856, 7874, 7878, 7882, 7883, 7887, 7891, 7894, 7897, 7900, 7901, 7904, 7909, 7910, 7913, 7915, 7920, 7921, 7923, 7925, 7928, 7948, 7952, 7958, 7964, 7966, 7968, 7973, 7977, 7979, 7987, 7989, 7992, 8001, 8008, 8010, 8013, 8016, 8018, 8020, 8023, 8025, 8028, 8034, 8036, 8040, 8047, 8050, 8051, 8054, 8062, 8063, 8066, 8067, 8070, 8072, 8076, 8081, 8084, 8095, 8096, 8097, 8099, 8103, 8104, 8105, 8107, 8109, 8110, 8114, 8116, 8118, 8120, 8121, 8122, 8127, 8128, 8134, 8138, 8141, 8142, 8143, 8145, 8152, 8153, 8154, 8163, 8170, 8172, 8173, 8183, 8185, 8188, 8195, 8196, 8200, 8201, 8203, 8205, 8206, 8210, 8213, 8214, 8215, 8216, 8221, 8227, 8232, 8237, 8243, 8244, 8249, 8259, 8271, 8272, 8274, 8276, 8278, 8282, 8285, 8286, 8288, 8290, 8291, 8296, 8297, 8298, 8303, 8311, 8312, 8313, 8317, 8318, 8322, 8332, 8333, 8336, 8337, 8340, 8342, 8343, 8344, 8346, 8347, 8348, 8359, 8363, 8364, 8366, 8369, 8371, 8377, 8380, 8409, 8410, 8415, 8416, 8418, 8419, 8422, 8424, 8427, 8428, 8432, 8439, 8440, 8443, 8445, 8446, 8447, 8452, 8458, 8459, 8463, 8467, 8474, 8477, 8481, 8482, 8483, 8486, 8488, 8489, 8492, 8494, 8498, 8499, 8501, 8502, 8503, 8504, 8505, 8506, 8512, 8513, 8516, 8518, 8519, 8525, 8526, 8532, 8534, 8541, 8542, 8543, 8545, 8549, 8550, 8554, 8557, 8561, 8563, 8567, 8570, 8571, 8573, 8575, 8576, 8579, 8580, 8581, 8587, 8591, 8597, 8605, 8609, 8616, 8619, 8622, 8629, 8636, 8645, 8649, 8654, 8656, 8660, 8661, 8662, 8663, 8665, 8666, 8674, 8676, 8677, 8678, 8679, 8686, 8687, 8690, 8692, 8697, 8698, 8701, 8703, 8705, 8709, 8714, 8719, 8721, 8724, 8727, 8730, 8734, 8740, 8746, 8747, 8749, 8753, 8757, 8758, 8762, 8765, 8767, 8769, 8773, 8774, 8776, 8777, 8781, 8784, 8789, 8790, 8791, 8793, 8794, 8796, 8798, 8799, 8806, 8810, 8811, 8812, 8813, 8817, 8818, 8820, 8822, 8823, 8825, 8828, 8830, 8831, 8833, 8841, 8846, 8848, 8857, 8859, 8861, 8866, 8869, 8870, 8872, 8873, 8879, 8882, 8888, 8889, 8890, 8891, 8894, 8896, 8899, 8911, 8916, 8917, 8918, 8921, 8926, 8928, 8929, 8931, 8941, 8942, 8943, 8949, 8952, 8959, 8961, 8962, 8963, 8965, 8968, 8969, 8977, 8981, 8985, 8986, 8987, 8990, 8991, 8996, 8998, 8999, 9001, 9007, 9012, 9013, 9016, 9019, 9026, 9027, 9032, 9034, 9038, 9045, 9053, 9056, 9057, 9061, 9062, 9063, 9064, 9068, 9072, 9075, 9076, 9078, 9086, 9088, 9091, 9094, 9097, 9100, 9104, 9117, 9119, 9127, 9129, 9141, 9143, 9144, 9146, 9152, 9157, 9158, 9160, 9161, 9162, 9163, 9165, 9168, 9175, 9177, 9190, 9194, 9195, 9200, 9201, 9202, 9204, 9213, 9215, 9216, 9225, 9226, 9231, 9232, 9233, 9236, 9240, 9246, 9251, 9252, 9253, 9258, 9259, 9260, 9262, 9263, 9266, 9268, 9269, 9271, 9272, 9273, 9277, 9279, 9281, 9294, 9297, 9299, 9302, 9303, 9309, 9310, 9312, 9313, 9316, 9319, 9321, 9325, 9331, 9335, 9338, 9342, 9354, 9356, 9359, 9363, 9366, 9370, 9376, 9377, 9384, 9389, 9393, 9396, 9397, 9402, 9407, 9412, 9413, 9415, 9419, 9423, 9424, 9434, 9437, 9444, 9459, 9460, 9461, 9462, 9466, 9473, 9475, 9478, 9480, 9482, 9484, 9486, 9490, 9493, 9494, 9498, 9503, 9505, 9508, 9517, 9518, 9521, 9523, 9526, 9533, 9538, 9539, 9549, 9552, 9553, 9555, 9561, 9562, 9566, 9569, 9576, 9579, 9580, 9584, 9586, 9594, 9597, 9599, 9600, 9602, 9604, 9605, 9607, 9611, 9615, 9616, 9619, 9620, 9622, 9628, 9639, 9640, 9644, 9647, 9661, 9662, 9665, 9667, 9669, 9670, 9672, 9674, 9677, 9680, 9685, 9691, 9696, 9705, 9708, 9710, 9712, 9713, 9714, 9715, 9722, 9725, 9726, 9727, 9729, 9730, 9736, 9737, 9739, 9741, 9744, 9747, 9752, 9753, 9754, 9763, 9765, 9768, 9771, 9784, 9787, 9788, 9798, 9799, 9801, 9802, 9803, 9804, 9805, 9809, 9810, 9812, 9818, 9819, 9825, 9826, 9828, 9829, 9832, 9833, 9835, 9836, 9842, 9844, 9846, 9847, 9852, 9857, 9863, 9865, 9870, 9871, 9873, 9876, 9877, 9882, 9883, 9885, 9886, 9887, 9889, 9891, 9892, 9895, 9896, 9900, 9901, 9905, 9910, 9913, 9915, 9921, 9923, 9924, 9933, 9936, 9937, 9942, 9943, 9944, 9950, 9951, 9952, 9954, 9958, 9960, 9965, 9968, 9970, 9972, 9973, 9974, 9980, 9983, 9984, 9987, 9991, 9994, 10006, 10007, 10010, 10012, 10015, 10017, 10019, 10022, 10026, 10027, 10029, 10030, 10032, 10035, 10036, 10038, 10040, 10042, 10043, 10044, 10045, 10046, 10049, 10050, 10063, 10065, 10075, 10077, 10080, 10085, 10088, 10089, 10097, 10099, 10102, 10105, 10106, 10110, 10115, 10117, 10122, 10123, 10130, 10131, 10136, 10140, 10144, 10149, 10150, 10153, 10154, 10155, 10160, 10165, 10167, 10171, 10173, 10174, 10177, 10179, 10180, 10184, 10188, 10204, 10207, 10222, 10224, 10231, 10234, 10235, 10241, 10243, 10248, 10250, 10254, 10255, 10264, 10266, 10272, 10277, 10278, 10281, 10286, 10287, 10289, 10292, 10294, 10302, 10304, 10313, 10320, 10322, 10324, 10325, 10326, 10327, 10332, 10334, 10337, 10339, 10348, 10352, 10355, 10357, 10359, 10360, 10364, 10368, 10369, 10370, 10374, 10379, 10385, 10390, 10392, 10394, 10397, 10400, 10414, 10420, 10422, 10423, 10427, 10428, 10432, 10434, 10440, 10443, 10449, 10453, 10455, 10464, 10467, 10478, 10482, 10484, 10496, 10501, 10502, 10505, 10506, 10509, 10510, 10512, 10513, 10518, 10527, 10529, 10531, 10547, 10559, 10561, 10564, 10565, 10567, 10568, 10586, 10600, 10601, 10602, 10607, 10609, 10615, 10616, 10617, 10618, 10623, 10624, 10625, 10633, 10639, 10646, 10649, 10650, 10651, 10652, 10653, 10654, 10656, 10658, 10659, 10662, 10664, 10665, 10666, 10667, 10668, 10669, 10670, 10674, 10675, 10677, 10681, 10686, 10692, 10693, 10695, 10696, 10705, 10710, 10714, 10717, 10738, 10741, 10742, 10745, 10748, 10749, 10750, 10751, 10758, 10765, 10771, 10776, 10779, 10780, 10783, 10784, 10785, 10799, 10800, 10804, 10806, 10807, 10808, 10809, 10811, 10814, 10817, 10818, 10822, 10823, 10829, 10830, 10833, 10834, 10839, 10842, 10843, 10847, 10849, 10856, 10859, 10861, 10874, 10880, 10884, 10889, 10890, 10893, 10898, 10899, 10901, 10906, 10909, 10911, 10912, 10920, 10924, 10928, 10932, 10933, 10937, 10941, 10948, 10951, 10954, 10956, 10957, 10963, 10965, 10967, 10969, 10971, 10972, 10975, 10976, 10978, 10980, 10981, 10983, 10985, 10987, 10989, 10990, 10997, 10999, 11003, 11012, 11013, 11018, 11019, 11020, 11021, 11023, 11027, 11028, 11030, 11032, 11036, 11037, 11040, 11047, 11049, 11050, 11055, 11056, 11059, 11063, 11067, 11074, 11078, 11080, 11081, 11082, 11090, 11091, 11092, 11095, 11096, 11112, 11116, 11122, 11123, 11133, 11134, 11139, 11142, 11143, 11149, 11150, 11155, 11162, 11167, 11172, 11177, 11181, 11183, 11189, 11194, 11197, 11199, 11202, 11204, 11205, 11207, 11210, 11212, 11214, 11220, 11226, 11230, 11232, 11233, 11235, 11236, 11242, 11247, 11255, 11262, 11264, 11265, 11269, 11270, 11275, 11279, 11282, 11286, 11292, 11294, 11295, 11300, 11305, 11311, 11312, 11315, 11318, 11322, 11327, 11328, 11330, 11335, 11336, 11338, 11339, 11340, 11346, 11347, 11348, 11349, 11350, 11354, 11356, 11358, 11362, 11369, 11371, 11372, 11375, 11381, 11382, 11384, 11404, 11406, 11408, 11409, 11412, 11413, 11423, 11426, 11427, 11431, 11433, 11437, 11438, 11440, 11442, 11448, 11451, 11454, 11455, 11456, 11460, 11461, 11467, 11470, 11472, 11476, 11477, 11478, 11479, 11483, 11484, 11486, 11490, 11498, 11503, 11516, 11517, 11518, 11523, 11524, 11526, 11529, 11533, 11535, 11536, 11542, 11544, 11550, 11552, 11557, 11559, 11561, 11563, 11565, 11566, 11567, 11568, 11569, 11575, 11577, 11579, 11580, 11581, 11583, 11585, 11587, 11590, 11592, 11593, 11603, 11604, 11609, 11614, 11617, 11623, 11624, 11626, 11634, 11635, 11640, 11641, 11643, 11644, 11646, 11647, 11656, 11659, 11663, 11664, 11667, 11675, 11680, 11683, 11684, 11686, 11687, 11688, 11689, 11697, 11700, 11701, 11706, 11707, 11710, 11712, 11714, 11717, 11718, 11719, 11723, 11725, 11728, 11729, 11732, 11737, 11740, 11744, 11745, 11747, 11748, 11752, 11753, 11757, 11758, 11759, 11763, 11770, 11771, 11778, 11782, 11784, 11785, 11787, 11797, 11798, 11800, 11802, 11803, 11805, 11808, 11813, 11817, 11818, 11820, 11829, 11837, 11842, 11844, 11849, 11850, 11853, 11855, 11858, 11863, 11867, 11869, 11870, 11871, 11877, 11880, 11885, 11890, 11891, 11892, 11897, 11899, 11901, 11905, 11907, 11908, 11916, 11917, 11918, 11920, 11926, 11927, 11932, 11938, 11941, 11944, 11945, 11947, 11948, 11951, 11952, 11959, 11962, 11971, 11976, 11978, 11982, 11985, 11991, 11995, 11996, 11997, 11999, 12001, 12003, 12005, 12008, 12011, 12012, 12013, 12017, 12020, 12021, 12025, 12032, 12040, 12045, 12050, 12056, 12058, 12061, 12063, 12064, 12065, 12068, 12070, 12075, 12077, 12078, 12082, 12085, 12086, 12087, 12089, 12093, 12094, 12095, 12103, 12110, 12115, 12116, 12119, 12120, 12124, 12125, 12130, 12131, 12136, 12138, 12140, 12141, 12142, 12143, 12145, 12146, 12151, 12152, 12153, 12156, 12161, 12164, 12167, 12169, 12170, 12173, 12175, 12177, 12178, 12179, 12182, 12183, 12184, 12185, 12186, 12188, 12189, 12192, 12207, 12215, 12216, 12218, 12219, 12221, 12222, 12223, 12226, 12228, 12233, 12234, 12235, 12241, 12242, 12243, 12244, 12246, 12249, 12250, 12251, 12252, 12253, 12254, 12257, 12258, 12259, 12261, 12265, 12267, 12268, 12269, 12271, 12274, 12277, 12278, 12281, 12282, 12284, 12287, 12289, 12290, 12294, 12295, 12302, 12305, 12306, 12307, 12310, 12314, 12320, 12324, 12327, 12329, 12330, 12337, 12342, 12344, 12345, 12348, 12351, 12355, 12367, 12371, 12372, 12373, 12376, 12377, 12379, 12380, 12381, 12387, 12388, 12392, 12395, 12397, 12398, 12400, 12401, 12402, 12407, 12410, 12412, 12413, 12423, 12425, 12432, 12434, 12435, 12438, 12442, 12445, 12446, 12448, 12450, 12454, 12457, 12461, 12467, 12471, 12472, 12474, 12476, 12479, 12480, 12481, 12482, 12483, 12489, 12492, 12496, 12498, 12501, 12511, 12517, 12518, 12519, 12521, 12522, 12524, 12530, 12531, 12532, 12536, 12537, 12540, 12546, 12553, 12561, 12565, 12566, 12572, 12575, 12584, 12585, 12588, 12589, 12592, 12594, 12595, 12599, 12605, 12606, 12611, 12618, 12622, 12623, 12625, 12626, 12627, 12628, 12633, 12634, 12635, 12637, 12639, 12643, 12648, 12657, 12659, 12660, 12661, 12663, 12664, 12665, 12675, 12685, 12692, 12695, 12704, 12708, 12712, 12715, 12718, 12724, 12726, 12732, 12736, 12737, 12740, 12741, 12744, 12746, 12748, 12752, 12753, 12759, 12760, 12761, 12762, 12767, 12769, 12770, 12776, 12777, 12779, 12780, 12784, 12788, 12797, 12803, 12807, 12809, 12810, 12812, 12819, 12823, 12824, 12826, 12828, 12830, 12833, 12834, 12839, 12840, 12841, 12847, 12856, 12865, 12868, 12869, 12870, 12871, 12872, 12875, 12876, 12878, 12880, 12882, 12883, 12896, 12899, 12901, 12906, 12907, 12908, 12915, 12916, 12921, 12923, 12927, 12933, 12941, 12942, 12946, 12948, 12955, 12957, 12958, 12964, 12965, 12968, 12970, 12980, 12982, 12983, 12990, 12991, 12993, 12995, 13002, 13004, 13005, 13007, 13014, 13018, 13020, 13021, 13027, 13029, 13035, 13036, 13038, 13041, 13049, 13052, 13055, 13057, 13061, 13064, 13069, 13071, 13074, 13076, 13078, 13079, 13080, 13082, 13084, 13086, 13091, 13095, 13098, 13099, 13100, 13101, 13109, 13111, 13116, 13124, 13125, 13127, 13133, 13136, 13137, 13138, 13140, 13145, 13146, 13153, 13161, 13165, 13167, 13169, 13171, 13174, 13177, 13179, 13183, 13185, 13186, 13190, 13195, 13200, 13207, 13212, 13214, 13220, 13226, 13229, 13231, 13236, 13238, 13241, 13242, 13244, 13249, 13250, 13252, 13258, 13259, 13267, 13268, 13272, 13274, 13276, 13281, 13286, 13288, 13289, 13301, 13303, 13305, 13306, 13308, 13314, 13321, 13323, 13327, 13329, 13330, 13333, 13340, 13353, 13354, 13357, 13359, 13360, 13361, 13362, 13364, 13367, 13376, 13378, 13379, 13382, 13385, 13391, 13395, 13401, 13403, 13406, 13417, 13418, 13419, 13420, 13421, 13422, 13428, 13431, 13436, 13438, 13439, 13441, 13445, 13452, 13459, 13462, 13463, 13464, 13465, 13469, 13470, 13475, 13478, 13489, 13490, 13493, 13494, 13495, 13500, 13502, 13505, 13507, 13508, 13515, 13523, 13530, 13532, 13536, 13541, 13542, 13548, 13552, 13554, 13556, 13559, 13562, 13564, 13565, 13566, 13574, 13575, 13579, 13582, 13587, 13589, 13597, 13598, 13600, 13601, 13606, 13607, 13610, 13618, 13620, 13622, 13623, 13624, 13627, 13628, 13633, 13635, 13637, 13642, 13644, 13647, 13648, 13653, 13661, 13675, 13677, 13682, 13683, 13689, 13690, 13693, 13695, 13699, 13711, 13714, 13716, 13718, 13720, 13732, 13733, 13735, 13736, 13742, 13745, 13748, 13751, 13753, 13754, 13755, 13757, 13759, 13765, 13772, 13782, 13787, 13788, 13792, 13795, 13800, 13809, 13812, 13813, 13815, 13817, 13825, 13835, 13836, 13837, 13838, 13841, 13842, 13844, 13845, 13847, 13848, 13850, 13852, 13853, 13857, 13864, 13866, 13877, 13881, 13882, 13884, 13888, 13895, 13905, 13906, 13912, 13919, 13920, 13922, 13926, 13927, 13930, 13931, 13932, 13934, 13935, 13936, 13938, 13941, 13946, 13947, 13949, 13950, 13951, 13953, 13956, 13958, 13961, 13969, 13976, 13978, 13979, 13980, 13983, 13985, 13986, 13988, 13993, 13995, 14002, 14003, 14005, 14012, 14014, 14016, 14025, 14026, 14035, 14038, 14041, 14042, 14044, 14047, 14049, 14050, 14054, 14057, 14058, 14059, 14060, 14061, 14063, 14065, 14069, 14071, 14073, 14078, 14082, 14083, 14084, 14087, 14089, 14093, 14100, 14104, 14116, 14118, 14126, 14129, 14130, 14140, 14143, 14149, 14152, 14154, 14156, 14157, 14159, 14160, 14165, 14170, 14173, 14177, 14184, 14185, 14186, 14189, 14190, 14196, 14197, 14202, 14203, 14209, 14211, 14217, 14218, 14219, 14223, 14227, 14228, 14229, 14230, 14233, 14238, 14240, 14241, 14245, 14256, 14259, 14263, 14268, 14269, 14271, 14279, 14282, 14285, 14286, 14293, 14294, 14298, 14300, 14301, 14304, 14309, 14310, 14311, 14314, 14315, 14319, 14320, 14322, 14323, 14325, 14329, 14334, 14337, 14338, 14345, 14346, 14347, 14348, 14352, 14354, 14357, 14358, 14366, 14370, 14379, 14380, 14385, 14387, 14389, 14391, 14393, 14402, 14404, 14405, 14407, 14409, 14413, 14415, 14420, 14432, 14434, 14435, 14440, 14441, 14445, 14448, 14449, 14450, 14465, 14466, 14467, 14477, 14480, 14482, 14484, 14492, 14495, 14497, 14507, 14511, 14514, 14515, 14517, 14520, 14522, 14524, 14531, 14535, 14539, 14543, 14545, 14550, 14555, 14558, 14561, 14563, 14564, 14568, 14571, 14572, 14573, 14574, 14578, 14579, 14583, 14585, 14587, 14592, 14593, 14607, 14611, 14614, 14615, 14623, 14624, 14626, 14629, 14633, 14635, 14640, 14642, 14651, 14660, 14662, 14663, 14664, 14667, 14673, 14674, 14679, 14683, 14688, 14689, 14690, 14695, 14700, 14701, 14702, 14709, 14710, 14711, 14713, 14714, 14715, 14719, 14727, 14735, 14737, 14741, 14743, 14748, 14749, 14750, 14753, 14754, 14755, 14756, 14757, 14759, 14763, 14772, 14774, 14777, 14779, 14784, 14787, 14796, 14800, 14805, 14806, 14810, 14814, 14815, 14816, 14818, 14825, 14827, 14830, 14833, 14835, 14836, 14837, 14838, 14840, 14841, 14847, 14851, 14853, 14860, 14863, 14864, 14869, 14870, 14873, 14874, 14875, 14879, 14881, 14883, 14884, 14885, 14886, 14887, 14892, 14897, 14898, 14899, 14901, 14905, 14908, 14912, 14921, 14923, 14928, 14932, 14935, 14938, 14942, 14944, 14945, 14949, 14953, 14954, 14955, 14956, 14957, 14958, 14964, 14965, 14966, 14967, 14972, 14973, 14974, 14975, 14976, 14977, 14982, 14985, 14987, 14990, 14994, 14998, 14999, 15001, 15002, 15003, 15004, 15008, 15010, 15015, 15019, 15020, 15022, 15026, 15027, 15028, 15030, 15036, 15039, 15042, 15047, 15051, 15052, 15056, 15057, 15062, 15066, 15081, 15083, 15085, 15091, 15098, 15100, 15103, 15105, 15106, 15115, 15118, 15119, 15120, 15121, 15126, 15127, 15134, 15138, 15141, 15143, 15149, 15150, 15153, 15157, 15160, 15161, 15166, 15168, 15174, 15179, 15182, 15183, 15187, 15190, 15191, 15192, 15193, 15200, 15201, 15206, 15208, 15216, 15217, 15219, 15220, 15227, 15228, 15231, 15232, 15234, 15235, 15236, 15239, 15243, 15246, 15247, 15250, 15252, 15255, 15258, 15259, 15263, 15266, 15275, 15276, 15278, 15279, 15280, 15283, 15285, 15287, 15291, 15294, 15304, 15314, 15315, 15325, 15328, 15329, 15333, 15336, 15337, 15340, 15352, 15356, 15357, 15359, 15363, 15365, 15367, 15370, 15376, 15380, 15385, 15386, 15387, 15390, 15392, 15395, 15401, 15403, 15407, 15409, 15411, 15414, 15415, 15420, 15426, 15427, 15431, 15433, 15434, 15438, 15440, 15441, 15445, 15447, 15452, 15454, 15455, 15456, 15458, 15460, 15461, 15464, 15469, 15472, 15473, 15475, 15484, 15489, 15490, 15491, 15495, 15506, 15509, 15513, 15521, 15525, 15527, 15530, 15531, 15535, 15537, 15541, 15542, 15544, 15545, 15548, 15553, 15554, 15560, 15562, 15566, 15568, 15569, 15570, 15571, 15573, 15578, 15582, 15584, 15585, 15589, 15594, 15599, 15602, 15607, 15608, 15612, 15615, 15619, 15621, 15629, 15631, 15636, 15639, 15644, 15647, 15650, 15652, 15653, 15656, 15658, 15664, 15665, 15669, 15672, 15675, 15679, 15683, 15684, 15685, 15686, 15687, 15690, 15694, 15697, 15703, 15704, 15709, 15727, 15730, 15733, 15736, 15739, 15745, 15747, 15749, 15756, 15760, 15761, 15763, 15767, 15774, 15775, 15776, 15777, 15779, 15780, 15783, 15787, 15796, 15801, 15805, 15807, 15808, 15809, 15811, 15814, 15821, 15824, 15825, 15831, 15838, 15841, 15842, 15843, 15846, 15850, 15852, 15853, 15856, 15858, 15864, 15872, 15876, 15881, 15882, 15885, 15887, 15888, 15891, 15894, 15899, 15902, 15903, 15912, 15914, 15917, 15918, 15919, 15922, 15923, 15924, 15925, 15926, 15927, 15933, 15936, 15941, 15943, 15944, 15946, 15948, 15959, 15961, 15963, 15971, 15976, 15977, 15982, 15984, 15986, 15987, 15990, 15993, 15995, 15996, 15998, 16002, 16004, 16010, 16013, 16014, 16021, 16023, 16026, 16030, 16033, 16034, 16035, 16041, 16042, 16044, 16045, 16049, 16051, 16053, 16058, 16060, 16061, 16066, 16073, 16074, 16075, 16076, 16078, 16080, 16085, 16087, 16092, 16099, 16103, 16106, 16119, 16123, 16127, 16128, 16134, 16136, 16138, 16141, 16142, 16143, 16144, 16148, 16150, 16152, 16153, 16162, 16171, 16172, 16174, 16176, 16181, 16184, 16185, 16186, 16188, 16194, 16195, 16201, 16209, 16210, 16216, 16219, 16223, 16224, 16227, 16228, 16232, 16237, 16240, 16241, 16242, 16243, 16247, 16258, 16259, 16260, 16261, 16264, 16270, 16273, 16280, 16281, 16283, 16293, 16296, 16300, 16305, 16306, 16310, 16317, 16322, 16332, 16333, 16336, 16341, 16343, 16349, 16352, 16353, 16355, 16357, 16360, 16361, 16367, 16368, 16369, 16370, 16371, 16372, 16375, 16378, 16379, 16381, 16387, 16391, 16392, 16394, 16399, 16400, 16405, 16406, 16409, 16411, 16421, 16423, 16435, 16438, 16439, 16449, 16450, 16451, 16472, 16474, 16475, 16479, 16490, 16498, 16499, 16500, 16504, 16516, 16518, 16519, 16521, 16525, 16526, 16536, 16537, 16543, 16546, 16549, 16550, 16553, 16554, 16555, 16561, 16568, 16570, 16571, 16573, 16575, 16576, 16577, 16579, 16582, 16587, 16590, 16592, 16594, 16601, 16606, 16608, 16610, 16612, 16616, 16617, 16622, 16625, 16626, 16627, 16629, 16635, 16636, 16640, 16642, 16646, 16651, 16655, 16663, 16672, 16676, 16678, 16679, 16680, 16681, 16682, 16683, 16685, 16696, 16699, 16700, 16708, 16709, 16712, 16715, 16717, 16718, 16722, 16724, 16736, 16738, 16740, 16745, 16748, 16752, 16753, 16755, 16757, 16761, 16765, 16770, 16773, 16774, 16779, 16784, 16785, 16788, 16790, 16791, 16794, 16796, 16797, 16808, 16810, 16811, 16813, 16822, 16824, 16827, 16836, 16839, 16843, 16847, 16848, 16850, 16855, 16861, 16866, 16868, 16874, 16888, 16895, 16897, 16899, 16901, 16903, 16907, 16908, 16909, 16911, 16914, 16917, 16918, 16927, 16930, 16932, 16934, 16946, 16949, 16953, 16958, 16961, 16963, 16964, 16970, 16975, 16976, 16979, 16981, 16982, 16985, 16988, 16992, 16994, 16995, 16999, 17000, 17001, 17002, 17005, 17006, 17007, 17009, 17012, 17018, 17021, 17022, 17024, 17027, 17028, 17030, 17034, 17036, 17041, 17047, 17052, 17053, 17054, 17055, 17058, 17060, 17067, 17069, 17072, 17074, 17078, 17079, 17083, 17085, 17086, 17089, 17094, 17098, 17103, 17105, 17106, 17111, 17113, 17121, 17122, 17123, 17125, 17130, 17133, 17134, 17135, 17137, 17138, 17155, 17159, 17162, 17163, 17174, 17175, 17177, 17180, 17184, 17187, 17190, 17192, 17193, 17198, 17203, 17206, 17208, 17210, 17216, 17217, 17218, 17229, 17230, 17232, 17236, 17237, 17238, 17240, 17241, 17245, 17251, 17255, 17260, 17261, 17263, 17272, 17275, 17276, 17279, 17280, 17282, 17287, 17290, 17292, 17294, 17295, 17298, 17302, 17311, 17320, 17321, 17322, 17328, 17331, 17334, 17341, 17344, 17346, 17347, 17350, 17355, 17359, 17362, 17366, 17369, 17370, 17372, 17375, 17378, 17379, 17382, 17384, 17385, 17386, 17388, 17393, 17396, 17399, 17400, 17407, 17410, 17414, 17417, 17421, 17426, 17429, 17432, 17443, 17452, 17457, 17461, 17462, 17464, 17465, 17467, 17469, 17470, 17472, 17478, 17481, 17483, 17484, 17492, 17493, 17496, 17514, 17515, 17519, 17528, 17530, 17535, 17538, 17540, 17548, 17551, 17556, 17557, 17567, 17575, 17581, 17583, 17585, 17588, 17591, 17595, 17602, 17603, 17604, 17605, 17606, 17608, 17610, 17617, 17621, 17630, 17631, 17639, 17640, 17644, 17646, 17647, 17651, 17652, 17658, 17661, 17663, 17664, 17665, 17666, 17667, 17670, 17671, 17674, 17675, 17683, 17684, 17690, 17691, 17694, 17696, 17697, 17702, 17708, 17711, 17714, 17719, 17720, 17721, 17722, 17734, 17735, 17739, 17751, 17758, 17760, 17761, 17764, 17765, 17766, 17773, 17777, 17778, 17780, 17781, 17784, 17785, 17794, 17796, 17798, 17801, 17803, 17807, 17808, 17810, 17811, 17812, 17814, 17815, 17817, 17821, 17827, 17832, 17836, 17838, 17843, 17850, 17857, 17858, 17863, 17864, 17865, 17866, 17868, 17872, 17876, 17884, 17886, 17887, 17889, 17892, 17895, 17896, 17904, 17909, 17919, 17922, 17928, 17931, 17932, 17935, 17943, 17947, 17948, 17949, 17950, 17952, 17954, 17959, 17962, 17966, 17969, 17971, 17973, 17977, 17978, 17988, 17989, 17990, 17996, 17997, 18000, 18004, 18008, 18012, 18014, 18018, 18019, 18021, 18022, 18026, 18033, 18036, 18037, 18045, 18054, 18056, 18057, 18065, 18067, 18071, 18088, 18092, 18094, 18099, 18101, 18104, 18108, 18109, 18113, 18114, 18119, 18120, 18121, 18123, 18124, 18126, 18129, 18130, 18134, 18138, 18139, 18144, 18154, 18159, 18160, 18166, 18167, 18171, 18172, 18176, 18177, 18179, 18182, 18184, 18185, 18190, 18194, 18199, 18203, 18208, 18213, 18214, 18215, 18217, 18221, 18223, 18224, 18229, 18241, 18244, 18247, 18250, 18251, 18253, 18255, 18259, 18261, 18262, 18263, 18264, 18265, 18266, 18267, 18268, 18273, 18274, 18275, 18281, 18288, 18290, 18291, 18300, 18308, 18317, 18320, 18322, 18323, 18333, 18334, 18336, 18340, 18341, 18348, 18353, 18356, 18358, 18361, 18363, 18365, 18366, 18370, 18376, 18379, 18384, 18385, 18390, 18398, 18401, 18403, 18411, 18413, 18418, 18419, 18425, 18430, 18431, 18436, 18442, 18443, 18446, 18449, 18452, 18455, 18456, 18459, 18461, 18465, 18472, 18481, 18487, 18490, 18510, 18511, 18516, 18517, 18520, 18529, 18531, 18532, 18535, 18541, 18547, 18548, 18556, 18559, 18568, 18569, 18570, 18573, 18582, 18584, 18585, 18586, 18595, 18596, 18599, 18605, 18609, 18611, 18612, 18615, 18619, 18623, 18626, 18629, 18635, 18637, 18642, 18644, 18646, 18648, 18650, 18656, 18671, 18672, 18673, 18674, 18677, 18681, 18685, 18686, 18695, 18697, 18698, 18700, 18704, 18712, 18715, 18727, 18728, 18729, 18731, 18734, 18735, 18737, 18741, 18746, 18753, 18757, 18759, 18763, 18764, 18773, 18774, 18775, 18779, 18780, 18786, 18788, 18792, 18794, 18795, 18799, 18801, 18804, 18805, 18812, 18814, 18819, 18825, 18827, 18831, 18837, 18838, 18839, 18844, 18847, 18849, 18852, 18853, 18877, 18885, 18887, 18888, 18889, 18892, 18893, 18897, 18898, 18899, 18901, 18902, 18903, 18906, 18910, 18911, 18912, 18916, 18918, 18920, 18921, 18927, 18930, 18931, 18942, 18943, 18944, 18948, 18950, 18954, 18960, 18966, 18967, 18968, 18969, 18980, 18981, 18982, 18983, 18987, 18988, 18989, 18994, 18995, 18996, 18998, 18999, 19002, 19005, 19016, 19017, 19031, 19033, 19037, 19038, 19039, 19040, 19043, 19056, 19058, 19059, 19062, 19065, 19066, 19069, 19071, 19074, 19075, 19079, 19082, 19083, 19087, 19092, 19093, 19096, 19098, 19099, 19107, 19110, 19116, 19117, 19119, 19120, 19126, 19128, 19129, 19131, 19141, 19142, 19144, 19145, 19149, 19150, 19151, 19152, 19153, 19156, 19157, 19160, 19164, 19167, 19175, 19182, 19195, 19201, 19206, 19209, 19218, 19222, 19223, 19226, 19228, 19229, 19234, 19239, 19240, 19243, 19247, 19256, 19263, 19265, 19269, 19270, 19272, 19279, 19280, 19282, 19294, 19296, 19297, 19312, 19316, 19325, 19326, 19328, 19330, 19341, 19342, 19344, 19350, 19353, 19355, 19358, 19359, 19370, 19371, 19373, 19375, 19383, 19390, 19391, 19395, 19397, 19401, 19402, 19405, 19408, 19411, 19412, 19416, 19418, 19426, 19428, 19432, 19434, 19436, 19440, 19450, 19451, 19452, 19453, 19455, 19457, 19461, 19462, 19463, 19467, 19469, 19470, 19472, 19478, 19484, 19489, 19491, 19492, 19493, 19496, 19497, 19500, 19508, 19510, 19511, 19513, 19523, 19527, 19530, 19536, 19538, 19543, 19547, 19548, 19549, 19550, 19551, 19552, 19558, 19559, 19560, 19568, 19570, 19577, 19585, 19588, 19589, 19590, 19596, 19599, 19602, 19604, 19606, 19608, 19610, 19611, 19612, 19617, 19619, 19620, 19626, 19637, 19644, 19646, 19648, 19649, 19653, 19661, 19662, 19666, 19668, 19677, 19685, 19686, 19687, 19688, 19692, 19693, 19700, 19701, 19706, 19708, 19709, 19710, 19712, 19714, 19717, 19722, 19724, 19729, 19731, 19733, 19741, 19742, 19750, 19755, 19761, 19762, 19763, 19764, 19777, 19780, 19794, 19797, 19798, 19803, 19806, 19807, 19812, 19814, 19817, 19818, 19823, 19826, 19833, 19837, 19839, 19840, 19841, 19842, 19850, 19851, 19855, 19858, 19866, 19868, 19876, 19877, 19885, 19897, 19900, 19901, 19906, 19908, 19912, 19914, 19915, 19916, 19918, 19922, 19928, 19936, 19938, 19940, 19945, 19946, 19950, 19952, 19959, 19965, 19972, 19975, 19977, 19978, 19980, 19986, 19990, 19992, 19994, 19995, 19996, 20004, 20010, 20011, 20012, 20013, 20018, 20023, 20024, 20025, 20037, 20038, 20047, 20049, 20053, 20057, 20061, 20062, 20066, 20068, 20069, 20075, 20083, 20084, 20089, 20091, 20100, 20102, 20103, 20105, 20106, 20111, 20113, 20114, 20115, 20116, 20117, 20121, 20122, 20125, 20128, 20129, 20132, 20133, 20134, 20140, 20145, 20147, 20152, 20154, 20159, 20169, 20173, 20174, 20176, 20183, 20187, 20192, 20194, 20200, 20204, 20207, 20208, 20212, 20214, 20217, 20218, 20220, 20223, 20226, 20230, 20232, 20235, 20241, 20243, 20244, 20245, 20248, 20249, 20250, 20252, 20253, 20256, 20257, 20268, 20273, 20274, 20276, 20279, 20280, 20291, 20292, 20303, 20308, 20309, 20320, 20321, 20322, 20328, 20332, 20334, 20336, 20341, 20351, 20352, 20354, 20355, 20356, 20360, 20361, 20365, 20370, 20372, 20376, 20377, 20378, 20381, 20385, 20389, 20394, 20395, 20396, 20402, 20403, 20407, 20409, 20410, 20411, 20421, 20424, 20425, 20431, 20434, 20435, 20436, 20445, 20446, 20447, 20448, 20450, 20453, 20456, 20457, 20460, 20463, 20466, 20468, 20473, 20476, 20480, 20486, 20496, 20498, 20506, 20508, 20509, 20514, 20515, 20518, 20519, 20528, 20529, 20531, 20535, 20536, 20537, 20547, 20549, 20552, 20553, 20554, 20555, 20558, 20559, 20566, 20567, 20568, 20570, 20574, 20575, 20580, 20583, 20584, 20589, 20593, 20597, 20598, 20600, 20607, 20611, 20612, 20621, 20626, 20632, 20634, 20635, 20637, 20643, 20644, 20648, 20651, 20656, 20657, 20665, 20671, 20677, 20678, 20680, 20683, 20684, 20686, 20688, 20690, 20699, 20703, 20704, 20708, 20711, 20713, 20716, 20720, 20725, 20728, 20734, 20735, 20744, 20745, 20750, 20751, 20752, 20759, 20767, 20770, 20790, 20791, 20792, 20793, 20794, 20795, 20804, 20812, 20813, 20816, 20821, 20822, 20825, 20828, 20829, 20833, 20835, 20836, 20839, 20844, 20848, 20849, 20854, 20860, 20863, 20866, 20867, 20868, 20874, 20878, 20881, 20883, 20884, 20885, 20886, 20891, 20898, 20899, 20901, 20903, 20907, 20908, 20909, 20910, 20914, 20917, 20924, 20931, 20936, 20938, 20940, 20941, 20943, 20944, 20946, 20950, 20951, 20953, 20958, 20964, 20967, 20974, 20976, 20979, 20982, 20986, 20991, 20992, 20994, 20998, 21000, 21003, 21014, 21015, 21022, 21025, 21026, 21029, 21030, 21035, 21037, 21040, 21042, 21043, 21049, 21050, 21057, 21058, 21065, 21068, 21070, 21082, 21085, 21088, 21090, 21092, 21094, 21098, 21103, 21104, 21105, 21107, 21108, 21109, 21111, 21113, 21115, 21118, 21122, 21123, 21129, 21132, 21134, 21137, 21139, 21140, 21144, 21146, 21149, 21150, 21153, 21155, 21156, 21160, 21163, 21165, 21167, 21168, 21175, 21178, 21180, 21183, 21184, 21193, 21202, 21207, 21210, 21215, 21216, 21217, 21227, 21230, 21237, 21241, 21244, 21246, 21252, 21255, 21256, 21258, 21262, 21273, 21275, 21277, 21279, 21282, 21283, 21284, 21286, 21290, 21303, 21304, 21305, 21306, 21307, 21308, 21312, 21318, 21319, 21320, 21322, 21323, 21324, 21328, 21329, 21330, 21339, 21341, 21347, 21348, 21352, 21353, 21359, 21361, 21362, 21364, 21366, 21370, 21371, 21373, 21375, 21376, 21378, 21379, 21384, 21397, 21398, 21399, 21401, 21403, 21410, 21416, 21419, 21427, 21429, 21431, 21432, 21435, 21440, 21447, 21450, 21451, 21452, 21454, 21463, 21465, 21466, 21469, 21471, 21475, 21480, 21481, 21483, 21484, 21485, 21486, 21487, 21488, 21489, 21491, 21493, 21497, 21503, 21504, 21508, 21509, 21510, 21512, 21523, 21525, 21529, 21530, 21531, 21536, 21546, 21551, 21552, 21554, 21555, 21559, 21561, 21564, 21568, 21573, 21577, 21578, 21582, 21589, 21592, 21593, 21594, 21596, 21597, 21598, 21603, 21604, 21607, 21613, 21614, 21615, 21617, 21620, 21622, 21623, 21625, 21626, 21627, 21628, 21629, 21633, 21634, 21635, 21638, 21645, 21647, 21652, 21653, 21654, 21662, 21666, 21667, 21669, 21672, 21673, 21676, 21684, 21686, 21690, 21693, 21705, 21707, 21714, 21719, 21721, 21723, 21726, 21727, 21730, 21731, 21735, 21736, 21738, 21742, 21749, 21752, 21753, 21754, 21757, 21758, 21759, 21764, 21769, 21771, 21773, 21786, 21788, 21791, 21797, 21798, 21805, 21811, 21818, 21821, 21826, 21828, 21829, 21830, 21833, 21834, 21835, 21837, 21846, 21847, 21858, 21862, 21865, 21866, 21869, 21870, 21871, 21873, 21880, 21881, 21891, 21893, 21895, 21897, 21901, 21904, 21908, 21914, 21922, 21926, 21927, 21931, 21945, 21951, 21953, 21954, 21955, 21960, 21963, 21974, 21979, 21986, 21987, 21988, 21990, 21994, 21996, 22003, 22004, 22010, 22017, 22018, 22019, 22020, 22026, 22028, 22035, 22040, 22043, 22045, 22049, 22052, 22055, 22059, 22070, 22071, 22073, 22074, 22076, 22078, 22083, 22087, 22091, 22092, 22095, 22102, 22104, 22105, 22108, 22115, 22118, 22119, 22120, 22122, 22123, 22128, 22131, 22134, 22139, 22144, 22145, 22148, 22150, 22154, 22156, 22157, 22162, 22163, 22165, 22169, 22178, 22180, 22181, 22183, 22184, 22190, 22199, 22201, 22203, 22207, 22210, 22214, 22216, 22219, 22221, 22224, 22227, 22228, 22229, 22232, 22237, 22238, 22239, 22240, 22245, 22249, 22252, 22259, 22264, 22265, 22267, 22269, 22274, 22275, 22276, 22277, 22278, 22281, 22283, 22285, 22289, 22294, 22296, 22297, 22306, 22308, 22310, 22311, 22312, 22315, 22316, 22317, 22320, 22322, 22327, 22332, 22333, 22336, 22338, 22340, 22341, 22343, 22349, 22350, 22354, 22364, 22366, 22368, 22371, 22379, 22380, 22383, 22385, 22387, 22390, 22393, 22394, 22395, 22396, 22401, 22406, 22413, 22416, 22417, 22418, 22420, 22424, 22425, 22426, 22427, 22429, 22431, 22436, 22437, 22439, 22440, 22441, 22442, 22443, 22449, 22450, 22461, 22464, 22480, 22481, 22482, 22485, 22492, 22493, 22497, 22500, 22505, 22508, 22510, 22511, 22515, 22517, 22519, 22520, 22521, 22523, 22525, 22526, 22530, 22532, 22537, 22538, 22540, 22541, 22544, 22545, 22547, 22549, 22553, 22557, 22561, 22563, 22566, 22568, 22570, 22572, 22577, 22578, 22580, 22583, 22584, 22586, 22587, 22588, 22590, 22592, 22599, 22602, 22603, 22606, 22607, 22610, 22612, 22624, 22625, 22626, 22632, 22636, 22637, 22638, 22641, 22648, 22655, 22659, 22662, 22663, 22664, 22669, 22671, 22672, 22673, 22674, 22680, 22684, 22685, 22686, 22692, 22697, 22700, 22707, 22711, 22713, 22714, 22716, 22726, 22728, 22731, 22739, 22743, 22746, 22749, 22751, 22754, 22756, 22761, 22763, 22766, 22770, 22772, 22774, 22777, 22791, 22792, 22793, 22795, 22796, 22802, 22804, 22805, 22809, 22811, 22815, 22816, 22820, 22823, 22841, 22844, 22849, 22851, 22852, 22853, 22855, 22859, 22862, 22866, 22872, 22877, 22879, 22880, 22883, 22888, 22891, 22897, 22899, 22901, 22903, 22904, 22905, 22907, 22910, 22913, 22914, 22915, 22916, 22918, 22920, 22921, 22924, 22927, 22930, 22933, 22938, 22941, 22945, 22949, 22953, 22954, 22957, 22958, 22960, 22962, 22963, 22969, 22970, 22973, 22976, 22980, 22983, 22986, 22988, 22989, 22990, 22991, 22992, 22993, 22996, 23004, 23006, 23008, 23010, 23014, 23018, 23020, 23024, 23028, 23030, 23031, 23034, 23035, 23037, 23038, 23039, 23040, 23042, 23046, 23047, 23051, 23054, 23058, 23075, 23081, 23082, 23083, 23085, 23087, 23090, 23092, 23093, 23098, 23103, 23104, 23107, 23110, 23111, 23112, 23117, 23118, 23121, 23123, 23126, 23128, 23131, 23132, 23133, 23138, 23142, 23147, 23153, 23154, 23161, 23162, 23164, 23167, 23172, 23173, 23176, 23178, 23182, 23186, 23193, 23194, 23195, 23196, 23197, 23201, 23202, 23205, 23210, 23219, 23221, 23224, 23226, 23230, 23232, 23234, 23236, 23237, 23238, 23243, 23244, 23248, 23249, 23251, 23252, 23258, 23262, 23264, 23269, 23271, 23273, 23274, 23275, 23278, 23280, 23281, 23288, 23292, 23306, 23307, 23309, 23318, 23321, 23322, 23324, 23327, 23332, 23334, 23336, 23341, 23348, 23350, 23351, 23353, 23356, 23360, 23365, 23366, 23367, 23368, 23382, 23389, 23394, 23395, 23397, 23399, 23400, 23408, 23411, 23413, 23415, 23419, 23420, 23422, 23427, 23428, 23432, 23434, 23436, 23438, 23442, 23447, 23451, 23455, 23459, 23474, 23476, 23481, 23491, 23492, 23498, 23503, 23506, 23507, 23510, 23511, 23514, 23516, 23519, 23520, 23523, 23526, 23531, 23532, 23534, 23535, 23536, 23537, 23546, 23550, 23552, 23553, 23554, 23556, 23558, 23559, 23571, 23584, 23596, 23613, 23615, 23617, 23618, 23624, 23627, 23632, 23635, 23636, 23642, 23644, 23649, 23654, 23656, 23663, 23671, 23675, 23678, 23680, 23682, 23687, 23688, 23693, 23695, 23699, 23701, 23708, 23709, 23711, 23712, 23714, 23720, 23721, 23726, 23733, 23735, 23737, 23738, 23743, 23744, 23752, 23754, 23757, 23759, 23760, 23761, 23764, 23771, 23777, 23779, 23781, 23782, 23787, 23788, 23790, 23796, 23808, 23809, 23811, 23814, 23821, 23824, 23825, 23826, 23829, 23830, 23833, 23837, 23838, 23843, 23846, 23849, 23858, 23860, 23867, 23868, 23870, 23874, 23877, 23880, 23883, 23885, 23887, 23890, 23892, 23895, 23897, 23899, 23906, 23912, 23920, 23924, 23927, 23928, 23933, 23935, 23938, 23942, 23943, 23944, 23946, 23949, 23953, 23954, 23956, 23965, 23966, 23971, 23974, 23988, 23995, 23999, 24003, 24004, 24007, 24008, 24013, 24015, 24029, 24030, 24032, 24039, 24042, 24043, 24044, 24063, 24064, 24065, 24067, 24069, 24073, 24074, 24078, 24080, 24082, 24083, 24084, 24088, 24089, 24091, 24092, 24095, 24097, 24100, 24102, 24108, 24109, 24110, 24111, 24114, 24117, 24118, 24120, 24121, 24122, 24123, 24129, 24133, 24140, 24141, 24143, 24147, 24152, 24157, 24158, 24161, 24164, 24166, 24167, 24172, 24181, 24182, 24184, 24187, 24188, 24193, 24204, 24208, 24210, 24224, 24227, 24228, 24233, 24235, 24241, 24244, 24247, 24248, 24249, 24252, 24253, 24257, 24266, 24271, 24272, 24276, 24279, 24280, 24281, 24289, 24295, 24298, 24299, 24302, 24308, 24312, 24327, 24330, 24331, 24335, 24338, 24339, 24349, 24355, 24359, 24360, 24367, 24372, 24374, 24377, 24385, 24387, 24391, 24394, 24396, 24397, 24398, 24400, 24412, 24414, 24417, 24418, 24421, 24424, 24428, 24435, 24439, 24444, 24446, 24448, 24450, 24451, 24454, 24455, 24459, 24460, 24461, 24462, 24463, 24469, 24470, 24475, 24477, 24478, 24480, 24492, 24499, 24510, 24515, 24518, 24519, 24532, 24534, 24535, 24536, 24537, 24539, 24547, 24552, 24559, 24562, 24567, 24569, 24573, 24579, 24580, 24582, 24586, 24588, 24590, 24592, 24593, 24594, 24595, 24601, 24608, 24610, 24613, 24615, 24619, 24622, 24623, 24624, 24625, 24626, 24630, 24632, 24636, 24639, 24640, 24643, 24645, 24647, 24649, 24652, 24653, 24655, 24656, 24657, 24659, 24662, 24664, 24666, 24671, 24674, 24678, 24682, 24687, 24688, 24691, 24710, 24713, 24714, 24718, 24725, 24730, 24731, 24737, 24739, 24740, 24750, 24756, 24759, 24761, 24762, 24774, 24779, 24780, 24785, 24793, 24794, 24797, 24798, 24801, 24803, 24804, 24806, 24807, 24808, 24810, 24820, 24822, 24824, 24825, 24827, 24831, 24847, 24851, 24852, 24860, 24862, 24864, 24865, 24869, 24873, 24876, 24882, 24884, 24886, 24888, 24894, 24897, 24899, 24902, 24903, 24907, 24912, 24920, 24924, 24926, 24930, 24933, 24937, 24938, 24942, 24950, 24955, 24957, 24958, 24959, 24961, 24964, 24966, 24967, 24968, 24971, 24975, 24977, 24979, 24981, 24982, 24994, 24995, 25004, 25009, 25012, 25013, 25017, 25026, 25029, 25030, 25031, 25035, 25049, 25054, 25057, 25059, 25060, 25061, 25063, 25064, 25066, 25069, 25078, 25083, 25085, 25087, 25090, 25097, 25100, 25102, 25103, 25104, 25107, 25110, 25115, 25116, 25120, 25121, 25124, 25127, 25135, 25140, 25141, 25151, 25152, 25154, 25157, 25160, 25164, 25168, 25173, 25177, 25198, 25207, 25208, 25209, 25210, 25212, 25213, 25214, 25217, 25218, 25219, 25222, 25223, 25225, 25229, 25230, 25231, 25232, 25234, 25235, 25244, 25255, 25258, 25274, 25280, 25282, 25284, 25289, 25297, 25299, 25300, 25304, 25305, 25307, 25317, 25318, 25321, 25323, 25326, 25329, 25334, 25338, 25339, 25340, 25344, 25349, 25351, 25354, 25356, 25357, 25361, 25364, 25369, 25372, 25381, 25384, 25386, 25390, 25394, 25395, 25412, 25416, 25417, 25419, 25429, 25432, 25433, 25442, 25446, 25452, 25456, 25457, 25458, 25462, 25463, 25466, 25469, 25473, 25475, 25477, 25481, 25487, 25489, 25498, 25504, 25505, 25506, 25507, 25518, 25520, 25521, 25523, 25524, 25532, 25536, 25537, 25538, 25539, 25540, 25542, 25544, 25546, 25547, 25551, 25554, 25568, 25578, 25579, 25581, 25588, 25590, 25591, 25603, 25605, 25606, 25612, 25618, 25621, 25624, 25630, 25634, 25635, 25638, 25640, 25643, 25653, 25656, 25659, 25661, 25664, 25665, 25668, 25673, 25686, 25689, 25696, 25697, 25699, 25700, 25702, 25704, 25705, 25707, 25708, 25710, 25711, 25720, 25723, 25724, 25728, 25729, 25732, 25733, 25734, 25743, 25751, 25754, 25763, 25764, 25766, 25767, 25769, 25772, 25775, 25779, 25780, 25785, 25787, 25790, 25794, 25796, 25800, 25801, 25802, 25808, 25812, 25814, 25817, 25818, 25820, 25823, 25828, 25829, 25833, 25835, 25838, 25840, 25844, 25855, 25856, 25858, 25860, 25861, 25863, 25865, 25866, 25871, 25873, 25874, 25876, 25881, 25882, 25885, 25888, 25889, 25891, 25895, 25901, 25902, 25907, 25916, 25921, 25928, 25929, 25934, 25935, 25937, 25938, 25943, 25946, 25949, 25950, 25952, 25953, 25957, 25961, 25964, 25965, 25966, 25970, 25972, 25975, 25984, 25985, 25986, 25987, 25988, 25996, 25997, 25998, 25999, 26000, 26003, 26004, 26010, 26017, 26023, 26026, 26027, 26031, 26039, 26046, 26048, 26049, 26055, 26061, 26066, 26069, 26077, 26079, 26080, 26083, 26085, 26087, 26090, 26091, 26092, 26095, 26096, 26102, 26103, 26109, 26115, 26119, 26137, 26139, 26140, 26141, 26145, 26149, 26150, 26156, 26158, 26160, 26162, 26165, 26170, 26174, 26175, 26179, 26181, 26183, 26185, 26186, 26190, 26195, 26200, 26205, 26208, 26210, 26211, 26212, 26224, 26228, 26230, 26231, 26233, 26236, 26237, 26239, 26252, 26260, 26261, 26263, 26267, 26268, 26270, 26274, 26285, 26286, 26287, 26292, 26294, 26296, 26297, 26298, 26300, 26311, 26315, 26317, 26318, 26320, 26324, 26328, 26334, 26341, 26342, 26350, 26351, 26353, 26355, 26358, 26359, 26365, 26366, 26369, 26370, 26371, 26375, 26379, 26384, 26392, 26396, 26397, 26398, 26399, 26402, 26406, 26411, 26412, 26421, 26422, 26425, 26432, 26435, 26443, 26445, 26451, 26452, 26455, 26459, 26467, 26469, 26470, 26471, 26472, 26473, 26477, 26485, 26488, 26491, 26498, 26506, 26510, 26513, 26514, 26520, 26521, 26523, 26528, 26534, 26535, 26539, 26543, 26550, 26551, 26562, 26572, 26578, 26586, 26590, 26596, 26597, 26601, 26603, 26604, 26606, 26607, 26608, 26612, 26618, 26619, 26620, 26628, 26630, 26636, 26639, 26642, 26643, 26647, 26648, 26659, 26666, 26668, 26679, 26685, 26686, 26688, 26690, 26698, 26700, 26708, 26710, 26711, 26712, 26714, 26715, 26716, 26717, 26726, 26727, 26728, 26733, 26734, 26736, 26740, 26741, 26744, 26745, 26746, 26748, 26749, 26750, 26751, 26753, 26754, 26757, 26761, 26764, 26767, 26772, 26777, 26780, 26785, 26788, 26790, 26792, 26795, 26797, 26798, 26799, 26803, 26804, 26805, 26809, 26814, 26816, 26817, 26818, 26821, 26826, 26831, 26835, 26838, 26839, 26843, 26844, 26845, 26848, 26853, 26855, 26858, 26861, 26865, 26870, 26879, 26880, 26881, 26883, 26885, 26886, 26887, 26896, 26900, 26901, 26905, 26913, 26915, 26919, 26921, 26922, 26924, 26927, 26940, 26942, 26946, 26948, 26949, 26950, 26954, 26961, 26964, 26965, 26969, 26977, 26983, 26984, 26985, 26986, 26989, 26990, 26991, 26999, 27001, 27013, 27014, 27020, 27022, 27023, 27029, 27030, 27035, 27038, 27040, 27041, 27042, 27043, 27045, 27047, 27052, 27053, 27054, 27056, 27058, 27060, 27062, 27065, 27067, 27068, 27071, 27074, 27075, 27081, 27089, 27090, 27094, 27095, 27100, 27103, 27106, 27109, 27110, 27112, 27118, 27119, 27121, 27123, 27126, 27129, 27130, 27131, 27132, 27136, 27144, 27145, 27147, 27149, 27150, 27151, 27153, 27154, 27155, 27158, 27160, 27161, 27162, 27165, 27170, 27182, 27185, 27189, 27190, 27193, 27195, 27196, 27198, 27209, 27213, 27215, 27217, 27220, 27223, 27224, 27225, 27228, 27235, 27237, 27242, 27245, 27247, 27248, 27251, 27252, 27253, 27254, 27256, 27261, 27269, 27273, 27281, 27289, 27290, 27291, 27292, 27296, 27297, 27299, 27309, 27310, 27311, 27316, 27318, 27322, 27323, 27324, 27329, 27332, 27334, 27335, 27336, 27337, 27343, 27349, 27351, 27352, 27354, 27355, 27356, 27357, 27360, 27361, 27366, 27372, 27378, 27379, 27380, 27391, 27392, 27397, 27398, 27402, 27409, 27411, 27418, 27421, 27427, 27428, 27429, 27434, 27438, 27439, 27443, 27444, 27448, 27456, 27458, 27459, 27462, 27464, 27476, 27478, 27479, 27480, 27481, 27483, 27486, 27494, 27495, 27496, 27504, 27506, 27507, 27513, 27514, 27515, 27517, 27520, 27529, 27530, 27531, 27535, 27544, 27545, 27547, 27548, 27555, 27561, 27563, 27565, 27567, 27569, 27570, 27573, 27574, 27575, 27576, 27577, 27579, 27582, 27586, 27588, 27589, 27591, 27593, 27594, 27597, 27598, 27599, 27601, 27602, 27606, 27607, 27610, 27612, 27613, 27620, 27621, 27622, 27624, 27628, 27631, 27637, 27638, 27640, 27643, 27644, 27645, 27647, 27649, 27652, 27655, 27656, 27659, 27661, 27662, 27663, 27665, 27667, 27668, 27669, 27672, 27673, 27676, 27679, 27680, 27682, 27684, 27687, 27688, 27691, 27694, 27703, 27705, 27708, 27711, 27718, 27721, 27722, 27723, 27726, 27730, 27731, 27732, 27736, 27738, 27739, 27742, 27743, 27745, 27748, 27749, 27751, 27753, 27758, 27766, 27780, 27785, 27791, 27793, 27799, 27801, 27803, 27804, 27805, 27806, 27807, 27808, 27816, 27821, 27825, 27827, 27834, 27840, 27843, 27845, 27851, 27855, 27856, 27863, 27864, 27866, 27875, 27877, 27878, 27879, 27883, 27885, 27886, 27887, 27888, 27889, 27891, 27894, 27901, 27902, 27904, 27911, 27912, 27913, 27916, 27918, 27919, 27921, 27925, 27928, 27929, 27939, 27940, 27942, 27946, 27949, 27952, 27959, 27961, 27964, 27967, 27971, 27975, 27977, 27979, 27981, 27984, 27994, 27995, 27996, 27999, 28000, 28005, 28008, 28012, 28015, 28016, 28019, 28020, 28021, 28026, 28029, 28031, 28037, 28039, 28042, 28045, 28047, 28049, 28050, 28052, 28057, 28060, 28063, 28064, 28065, 28068, 28071, 28072, 28073, 28077, 28079, 28080, 28084, 28085, 28086, 28087, 28089, 28090, 28092, 28093, 28094, 28097, 28104, 28105, 28108, 28109, 28110, 28113, 28117, 28118, 28119, 28123, 28125, 28126, 28127, 28128, 28129, 28130, 28133, 28140, 28143, 28151, 28152, 28155, 28156, 28159, 28160, 28161, 28162, 28163, 28165, 28166, 28167, 28169, 28170, 28172, 28175, 28176, 28182, 28190, 28192, 28193, 28198, 28199, 28202, 28207, 28210, 28211, 28212, 28215, 28218, 28219, 28221, 28223, 28226, 28230, 28231, 28234, 28236, 28238, 28242, 28243, 28244, 28246, 28247, 28254, 28257, 28259, 28262, 28267, 28271, 28272, 28277, 28279, 28280, 28281, 28289, 28292, 28293, 28317, 28318, 28321, 28323, 28324, 28336, 28337, 28338, 28339, 28341, 28351, 28354, 28356, 28358, 28362, 28364, 28371, 28374, 28380, 28382, 28390, 28394, 28395, 28397, 28404, 28407, 28414, 28419, 28422, 28428, 28429, 28432, 28435, 28439, 28441, 28445, 28453, 28456, 28457, 28460, 28462, 28466, 28471, 28477, 28478, 28479, 28482, 28485, 28487, 28488, 28492, 28493, 28496, 28498, 28506, 28510, 28513, 28514, 28516, 28518, 28522, 28523, 28524, 28525, 28529, 28532, 28534, 28539, 28543, 28544, 28549, 28551, 28556, 28560, 28563, 28564, 28565, 28567, 28568, 28571, 28573, 28578, 28584, 28595, 28597, 28601, 28603, 28604, 28605, 28607, 28608, 28609, 28611, 28619, 28620, 28621, 28623, 28625, 28626, 28629, 28632, 28634, 28636, 28643, 28644, 28648, 28651, 28652, 28654, 28665, 28666, 28667, 28672, 28673, 28675, 28676, 28684, 28690, 28692, 28693, 28700, 28701, 28706, 28707, 28716, 28717, 28723, 28724, 28732, 28733, 28734, 28737, 28749, 28753, 28754, 28764, 28768, 28771, 28773, 28774, 28776, 28778, 28780, 28784, 28785, 28790, 28791, 28792, 28802, 28805, 28807, 28808, 28813, 28815, 28820, 28823, 28827, 28829, 28831, 28834, 28835, 28842, 28844, 28845, 28846, 28849, 28855, 28861, 28862, 28864, 28866, 28867, 28874, 28879, 28886, 28892, 28893, 28894, 28896, 28897, 28907, 28910, 28914, 28915, 28916, 28918, 28919, 28922, 28924, 28925, 28929, 28931, 28932, 28933, 28934, 28939, 28941, 28943, 28944, 28946, 28951, 28955, 28959, 28962, 28966, 28968, 28973, 28974, 28975, 28977, 28991, 28996, 28997, 28998, 29000, 29003, 29005, 29010, 29011, 29016, 29026, 29036, 29037, 29041, 29044, 29048, 29050, 29056, 29058, 29070, 29073, 29078, 29080, 29081, 29084, 29086, 29087, 29088, 29092, 29102, 29104, 29115, 29116, 29118, 29120, 29121, 29122, 29123, 29130, 29131, 29134, 29141, 29144, 29145, 29146, 29148, 29151, 29152, 29155, 29156, 29157, 29158, 29161, 29162, 29167, 29168, 29176, 29182, 29184, 29185, 29186, 29190, 29193, 29197, 29199, 29200, 29202, 29203, 29210, 29215, 29216, 29218, 29219, 29222, 29231, 29233, 29236, 29237, 29239, 29240, 29241, 29244, 29260, 29263, 29270, 29273, 29274, 29276, 29283, 29284, 29290, 29294, 29295, 29304, 29311, 29314, 29315, 29319, 29324, 29325, 29326, 29328, 29329, 29330, 29334, 29338, 29341, 29342, 29343, 29346, 29347, 29350, 29353, 29356, 29358, 29359, 29362, 29365, 29375, 29376, 29378, 29379, 29380, 29381, 29383, 29388, 29389, 29392, 29400, 29402, 29403, 29408, 29412, 29413, 29416, 29419, 29420, 29422, 29427, 29431, 29433, 29434, 29438, 29442, 29453, 29455, 29457, 29461, 29465, 29471, 29472, 29480, 29481, 29485, 29492, 29493, 29500, 29502, 29504, 29505, 29506, 29508, 29509, 29514, 29517, 29518, 29520, 29521, 29524, 29526, 29529, 29530, 29531, 29544, 29546, 29552, 29553, 29554, 29556, 29560, 29561, 29566, 29569, 29573, 29574, 29575, 29580, 29581, 29584, 29586, 29589, 29593, 29595, 29597, 29598, 29600, 29602, 29603, 29610, 29614, 29619, 29621, 29622, 29624, 29630, 29632, 29635, 29636, 29638, 29639, 29642, 29644, 29645, 29647, 29649, 29656, 29657, 29660, 29661, 29666, 29668, 29670, 29674, 29679, 29682, 29683, 29686, 29688, 29690, 29691, 29692, 29695, 29700, 29705, 29706, 29712, 29713, 29722, 29725, 29726, 29739, 29741, 29742, 29743, 29744, 29749, 29753, 29755, 29758, 29760, 29762, 29770, 29772, 29773, 29778, 29779, 29786, 29790, 29796, 29804, 29810, 29811, 29815, 29823, 29824, 29828, 29830, 29831, 29834, 29836, 29837, 29838, 29839, 29844, 29851, 29854, 29856, 29857, 29859, 29860, 29861, 29867, 29869, 29872, 29875, 29880, 29881, 29882, 29884, 29888, 29889, 29891, 29892, 29902, 29904, 29911, 29912, 29913, 29918, 29920, 29927, 29929, 29932, 29934, 29939, 29943, 29946, 29948, 29949, 29954, 29955, 29957, 29958, 29961, 29965, 29966, 29967, 29971, 29972, 29981, 29983, 29985, 29987, 29991, 29992, 29994, 29997, 29999, 30004, 30008, 30011, 30016, 30017, 30018, 30019, 30020, 30022, 30023, 30026, 30027, 30029, 30034, 30039, 30045, 30048, 30049, 30053, 30054, 30060, 30062, 30067, 30070, 30071, 30075, 30079, 30080, 30083, 30085, 30087, 30090, 30091, 30093, 30101, 30102, 30106, 30107, 30109, 30111, 30112, 30113, 30114, 30119, 30121, 30122, 30124, 30126, 30130, 30131, 30132, 30135, 30138, 30145, 30146, 30148, 30150, 30153, 30154, 30156, 30157, 30160, 30162, 30164, 30166, 30170, 30171, 30175, 30177, 30178, 30181, 30186, 30188, 30190, 30191, 30192, 30195, 30196, 30197, 30199, 30200, 30204, 30205, 30206, 30207, 30210, 30214, 30218, 30219, 30220, 30223, 30224, 30225, 30227, 30229, 30231, 30232, 30239, 30244, 30247, 30248, 30251, 30253, 30256, 30257, 30258, 30261, 30265, 30268, 30273, 30275, 30277, 30279, 30281, 30282, 30284, 30285, 30286, 30287, 30292, 30298, 30299, 30301, 30303, 30304, 30308, 30312, 30313, 30314, 30316, 30317, 30318, 30321, 30322, 30330, 30332, 30335, 30336, 30338, 30340, 30341, 30342, 30344, 30345, 30349, 30352, 30356, 30357, 30360, 30371, 30374, 30378, 30383, 30384, 30392, 30395, 30398, 30403, 30404, 30408, 30410, 30412, 30413, 30414, 30420, 30428, 30429, 30431, 30436, 30439, 30441, 30442, 30445, 30447, 30448, 30449, 30453, 30456, 30457, 30458, 30460, 30464, 30474, 30476, 30477, 30480, 30483, 30484, 30486, 30488, 30490, 30495, 30501, 30503, 30504, 30505, 30509, 30513, 30522, 30524, 30534, 30542, 30546, 30551, 30558, 30561, 30566, 30570, 30579, 30582, 30588, 30589, 30590, 30591, 30592, 30593, 30596, 30598, 30599, 30601, 30604, 30606, 30607, 30608, 30609, 30610, 30612, 30614, 30617, 30618, 30622, 30625, 30626, 30629, 30630, 30632, 30635, 30637, 30638, 30640, 30641, 30645, 30646, 30648, 30650, 30651, 30659, 30660, 30661, 30663, 30665, 30666, 30667, 30668, 30669, 30670, 30679, 30682, 30685, 30694, 30695, 30696, 30703, 30707, 30713, 30716, 30717, 30719, 30725, 30726, 30732, 30736, 30737, 30739, 30747, 30748, 30750, 30754, 30755, 30756, 30777, 30779, 30780, 30782, 30790, 30792, 30799, 30805, 30811, 30815, 30819, 30820, 30822, 30825, 30826, 30827, 30850, 30854, 30855, 30861, 30864, 30865, 30868, 30876, 30877, 30881, 30882, 30884, 30887, 30902, 30906, 30908, 30909, 30910, 30911, 30913, 30915, 30919, 30945, 30949, 30950, 30962, 30964, 30966, 30968, 30969, 30978, 30981, 30982, 30983, 30992, 30993, 30994, 30995, 30996, 31000, 31002, 31003, 31004, 31005, 31007, 31016, 31019, 31022, 31025, 31026, 31031, 31033, 31038, 31039, 31041, 31044, 31045, 31048, 31050, 31051, 31052, 31054, 31056, 31058, 31070, 31072, 31073, 31074, 31077, 31082, 31083, 31086, 31088, 31093, 31106, 31108, 31110, 31113, 31115, 31116, 31120, 31121, 31127, 31128, 31129, 31130, 31134, 31135, 31136, 31141, 31142, 31144, 31146, 31153, 31160, 31163, 31165, 31169, 31172, 31175, 31182, 31183, 31189, 31195, 31196, 31197, 31199, 31204, 31205, 31207, 31212, 31215, 31217, 31218, 31219, 31222, 31225, 31229, 31232, 31234, 31239, 31241, 31245, 31246, 31252, 31254, 31258, 31260, 31261, 31264, 31272, 31273, 31276, 31279, 31282, 31284, 31285, 31289, 31291, 31292, 31294, 31298, 31301, 31302, 31304, 31309, 31315, 31319, 31320, 31323, 31330, 31331, 31332, 31337, 31341, 31342, 31357, 31360, 31361, 31365, 31369, 31371, 31379, 31380, 31381, 31382, 31389, 31394, 31397, 31402, 31405, 31413, 31420, 31421, 31425, 31430, 31432, 31437, 31438, 31439, 31441, 31442, 31448, 31453, 31454, 31461, 31463, 31470, 31473, 31479, 31482, 31483, 31485, 31489, 31495, 31496, 31497, 31500, 31502, 31504, 31506, 31508, 31509, 31511, 31514, 31516, 31517, 31523, 31527, 31528, 31529, 31533, 31534, 31535, 31539, 31542, 31544, 31545, 31551, 31556, 31561, 31563, 31565, 31567, 31568, 31576, 31580, 31584, 31591, 31603, 31606, 31609, 31615, 31619, 31620, 31621, 31625, 31626, 31628, 31633, 31649, 31650, 31651, 31658, 31670, 31673, 31676, 31680, 31683, 31685, 31688, 31690, 31695, 31696, 31697, 31698, 31707, 31710, 31714, 31720, 31721, 31723, 31724, 31725, 31728, 31729, 31730, 31735, 31746, 31749, 31757, 31765, 31770, 31772, 31779, 31784, 31791, 31792, 31793, 31797, 31798, 31799, 31802, 31803, 31807, 31808, 31815, 31820, 31821, 31822, 31823, 31829, 31830, 31831, 31834, 31836, 31837, 31838, 31851, 31852, 31853, 31854, 31856, 31857, 31858, 31861, 31864, 31865, 31866, 31867, 31869, 31879, 31881, 31883, 31886, 31889, 31890, 31897, 31899, 31901, 31902, 31903, 31904, 31906, 31909, 31910, 31911, 31918, 31922, 31926, 31928, 31929, 31932, 31938, 31941, 31951, 31953, 31958, 31962, 31964, 31966, 31968, 31969, 31970, 31971, 31973, 31981, 31983, 31984, 31986, 31987, 31994, 32000, 32002, 32005, 32010, 32013, 32020, 32026, 32032, 32034, 32037, 32040, 32042, 32045, 32046, 32049, 32050, 32053, 32054, 32058, 32064, 32074, 32075, 32077, 32079, 32080, 32081, 32083, 32085, 32089, 32091, 32094, 32095, 32106, 32108, 32111, 32114, 32116, 32117, 32118, 32120, 32121, 32123, 32125, 32132, 32135, 32136, 32139, 32143, 32145, 32154, 32158, 32161, 32163, 32168, 32173, 32174, 32175, 32184, 32185, 32188, 32193, 32194, 32196, 32197, 32199, 32209, 32212, 32219, 32222, 32234, 32236, 32237, 32240, 32245, 32254, 32260, 32263, 32269, 32272, 32276, 32277, 32278, 32279, 32281, 32282, 32283, 32285, 32287, 32288, 32291, 32293, 32296, 32303, 32304, 32305, 32312, 32315, 32317, 32318, 32319, 32321, 32323, 32325, 32326, 32327, 32329, 32333, 32339, 32340, 32341, 32342, 32350, 32354, 32356, 32357, 32358, 32359, 32360, 32370, 32373, 32375, 32376, 32377, 32380, 32381, 32382, 32383, 32384, 32385, 32387, 32389, 32393, 32395, 32399, 32404, 32406, 32408, 32411, 32412, 32417, 32419, 32420, 32426, 32427, 32429, 32434, 32437, 32440, 32442, 32445, 32447, 32448, 32452, 32455, 32456, 32457, 32463, 32465, 32467, 32474, 32481, 32483, 32486, 32489, 32493, 32497, 32506, 32511, 32516, 32528, 32543, 32546, 32548, 32549, 32551, 32553, 32554, 32559, 32565, 32566, 32568, 32571, 32574, 32575, 32578, 32582, 32589, 32592, 32594, 32598, 32600, 32606, 32607, 32609, 32612, 32615, 32616, 32618, 32624, 32626, 32628, 32631, 32640, 32646, 32649, 32657, 32658, 32661, 32663, 32665, 32667, 32670, 32671, 32672, 32673, 32674, 32675, 32685, 32687, 32688, 32692, 32694, 32697, 32698, 32702, 32703, 32704, 32712, 32713, 32717, 32721, 32723, 32726, 32730, 32733, 32737, 32738, 32742, 32743, 32749, 32750, 32754, 32757, 32762, 32765, 32768, 32773, 32781, 32787, 32793, 32796, 32797, 32798, 32807, 40000, 40004, 40009, 40033, 40063, 40066, 40070, 40071, 40078, 40084, 40094, 40103, 40124, 40133, 40213, 40246, 40273, 40286, 40288, 40308, 40347, 40356, 40370, 40384, 40386, 40387, 40428, 40442, 40456, 40464, 40474, 40496, 40513, 40514, 40546, 40548, 40569, 40576, 40582, 40586, 40595, 40600, 40610, 40612, 40614, 40623, 40632, 40644, 40686, 40693, 40694, 40701, 40708, 40723, 40729, 40738, 40744, 40771, 40772, 40786, 40789, 40811, 40827, 40837, 40850, 40877, 40897, 40912, 40913, 40972, 40983, 40988, 40991, 40998, 40999, 41004, 41016, 41030, 41040, 41050, 41054, 41070, 41077, 41102, 41119, 41121, 41192, 41194, 41205, 41217, 41219, 41254, 41290, 41315, 41318, 41371, 41383, 41393, 41402, 41408, 41409, 41422, 41441, 41452, 41463, 41520, 41526, 41546, 41550, 41567, 41573, 41581, 41589, 41592, 41631, 41638, 41668, 41678, 41687, 41696, 41701, 41724, 41729, 41738, 41768, 41782, 41785, 41788, 41830, 41842, 41861, 41881, 41882, 41890, 41891, 41934, 41976, 41983, 41984, 42020, 42028, 42035, 42060, 42062, 42066, 42067, 42093, 42106, 42124, 42129, 42130, 42148, 42160, 42173, 42174, 42175, 42184, 42189, 42199, 42210, 42211, 42221, 42222, 42243, 42244, 42255, 42288, 42310, 42321, 42326, 42327, 42351, 42364, 42385, 42402, 42405, 42410, 42417, 42437, 42454, 42455, 42460, 42468, 42482, 42486, 42491, 42504, 42509, 42525, 42545, 42572, 42589, 42590, 42604, 42621, 42649, 42677, 42682, 42694, 42747, 42752, 42755, 42771, 42781, 42782, 42790, 42809, 42811, 42826, 42829, 42830, 42851, 42870, 42903, 42904, 42905, 42920, 42929, 42948, 42956, 42962, 42963, 42982, 42995, 43004, 43017, 43056, 43061, 43066, 43080, 43083, 43084, 43086, 43089, 43107, 43112, 43115, 43120, 43122, 43126, 43138, 43151, 43162, 43206, 43215, 43257, 43274, 43284, 43296, 43322, 43325, 43330, 43337, 43392, 43417, 43431, 43437, 43447, 43450, 43456, 43460, 43478, 43501, 43503, 43509, 43543, 43557, 43559, 43564, 43571, 43589, 43599, 43602, 43613, 43632, 43658, 43668, 43671, 43673, 43686, 43690, 43691, 43697, 43708, 43732, 43737, 43746, 43759, 43776, 43787, 43798, 43799, 43803, 43820, 43827, 43837, 43866, 43870, 43875, 43876, 43878, 43911, 43923, 43925, 43942, 43982, 43990, 44036, 44052, 44058, 44061, 44064, 44073, 44083, 44126, 44135, 44139, 44153, 44173, 44181, 44188, 44214, 44228, 44234, 44245, 44248, 44258, 44265, 44298, 44300, 44303, 44323, 44328, 44332, 44339, 44375, 44382, 44383, 44385, 44388, 44408, 44427, 44430, 44434, 44449, 44450, 44451, 44459, 44464, 44468, 44490, 44491, 44506, 44508, 44521, 44532, 44534, 44539, 44546, 44566, 44589, 44592, 44593, 44597, 44600, 44601, 44622, 44632, 44658, 44666, 44677, 44685, 44715, 44721, 44722, 44723, 44724, 44735, 44741, 44768, 44793, 44795, 44806, 44807, 44812, 44817, 44820, 44837, 44844, 44851, 44856, 44876, 44880, 44902, 44908, 44921, 44957, 44958, 44979, 44990, 45012, 45013, 45017, 45040, 45092, 45099, 45102, 45112, 45115, 45123, 45127, 45131, 45138, 45146, 45152, 45157, 45180, 45183, 45186, 45194, 45199, 45207, 45213, 45227, 45236, 45269, 45272, 45273, 45297, 45300, 45304, 45308, 45316, 45317, 45320, 45326, 45329, 45339, 45342, 45346, 45347, 45381, 45407, 45409, 45410, 45415, 45420, 45425, 45434, 45437, 45441, 45457, 45460, 45477, 45489, 45524, 45536, 45557, 45566, 45583, 45589, 45601, 45604, 45612, 45619, 45628, 45632, 45647, 45672, 45698, 45779, 45788, 45791, 45835, 45838, 45848, 45860, 45866, 45885, 45895, 45910, 45914, 45918, 45933, 45959, 45974, 46007, 46022, 46034, 46036, 46038, 46077, 46080, 46081, 46085, 46105, 46116, 46119, 46120, 46125, 46132, 46148, 46150, 46163, 46198, 46217, 46230, 46251, 46263, 46271, 46287, 46315, 46321, 46330, 46335, 46340, 46355, 46366, 46382, 46392, 46398, 46414, 46422, 46423, 46442, 46446, 46455, 46459, 46462, 46487, 46499, 46521, 46536, 46550, 46551, 46566, 46569, 46576, 46586, 46588, 46590, 46603, 46608, 46620, 46624, 46667, 46668, 46672, 46692, 46693, 46694, 46733, 46734, 46744, 46755, 46756, 46764, 46775, 46781, 46793, 46801, 46816, 46817, 46836, 46845, 46849, 46850, 46851, 46853, 46857, 46880, 46910, 46926, 46935, 46938, 46946, 46947, 46955, 46968, 46994, 47014, 47058, 47087, 47093, 47127, 47129, 47132, 47133, 47157, 47164, 47203, 47219, 47224, 47234, 47250, 47257, 47266, 47270, 47286, 47288, 47289, 47305, 47351, 47357, 47362, 47407, 47428, 47430, 47436, 47450, 47466, 47467, 47469, 47477, 47509, 47513, 47520, 47529, 47532, 47563, 47577, 47578, 47591, 47598, 47618, 47620, 47637, 47647, 47668, 47670, 47683, 47693, 47700, 47712, 47715, 47726, 47739, 47748, 47759, 47785, 47798, 47799, 47800, 47807, 47814, 47852, 47875, 47884, 47887, 47892, 47897, 47906, 47912, 47918, 47927, 47940, 47978, 47995, 48006, 48025, 48042, 48056, 48065, 48090, 48115, 48121, 48124, 48165, 48181, 48184, 48217, 48220, 48222, 48232, 48233, 48239, 48253, 48268, 48290, 48292, 48293, 48304, 48308, 48320, 48327, 48344, 48348, 48351, 48373, 48374, 48379, 48380, 48398, 48409, 48456, 48461, 48479, 48480, 48481, 48483, 48503, 48521, 48523, 48524, 48546, 48553, 48554, 48556, 48612, 48617, 48629, 48632, 48637, 48647, 48674, 48687, 48693, 48707, 48730, 48770, 48774, 48804, 48812, 48827, 48833, 48837, 48843, 48865, 48876, 48913, 48915, 48928, 48946, 48950, 48951, 48969, 48999, 49016, 49023, 49037, 49080, 49104, 49105, 49106, 49133, 49141, 49144, 49151, 49171, 49176, 49188, 49190, 49232, 49249, 49261, 49265, 49268, 49290, 49291, 49296, 49311, 49328, 49339, 49350, 49359, 49370, 49375, 49380, 49392, 49407, 49431, 49435, 49453, 49456, 49457, 49469, 49499, 49510, 49534, 49562, 49566, 49580, 49582, 49583, 49586, 49592, 49599, 49603, 49615, 49619, 49622, 49632, 49634, 49635, 49638, 49649, 49650, 49671, 49683, 49705, 49727, 49739, 49742, 49806, 49820, 49828, 49841, 49922, 49930, 49952, 49955, 49964, 49971, 49984, 49998, 49999, 50010, 50020, 50028, 50043, 50050, 50055, 50061, 50087, 50093, 50099, 50104, 50113, 50148, 50164, 50214, 50216, 50217, 50254, 50259, 50268, 50285, 50289, 50300, 50303, 50305, 50359, 50366, 50370, 50384, 50405, 50407, 50409, 50427, 50434, 50440, 50450, 50476, 50485, 50490, 50495, 50498, 50507, 50520, 50528, 50532, 50537, 50544, 50545, 50579, 50594, 50603, 50620, 50623, 50636, 50640, 50651, 50654, 50672, 50691, 50692, 50710, 50725, 50734, 50756, 50762, 50772, 50793, 50815, 50819, 50826, 50827, 50863, 50877, 50882, 50883, 50889, 50895, 50901, 50911, 50913, 50915, 50928, 50939, 50957, 50962, 50968, 50969, 50981, 50987, 50996, 50998, 51000, 51013, 51027, 51053, 51060, 51076, 51086, 51091, 51104, 51136, 51143, 51157, 51177, 51180, 51203, 51216, 51222, 51226, 51231, 51237, 51258, 51259, 51267, 51270, 51288, 51289, 51291, 51297, 51299, 51321, 51327, 51335, 51343, 51348, 51359, 51364, 51390, 51403, 51404, 51418, 51424, 51458, 51465, 51466, 51506, 51522, 51529, 51538, 51542, 51550, 51551, 51557, 51558, 51577, 51597, 51607, 51611, 51670, 51675, 51698, 51750, 51754, 51771, 51776, 51780, 51786, 51790, 51793, 51796, 51797, 51798, 51802, 51820, 51829, 51841, 51849, 51859, 51864, 51872, 51874, 51878, 51883, 51890, 51891, 51922, 51929, 51933, 51936, 51948, 51952, 51976, 51981, 51986, 51992, 52001, 52002, 52010, 52038, 52040, 52046, 52057, 52065, 52077, 52107, 52109, 52121, 52130, 52136, 52139, 52147, 52162, 52164, 52172, 52186, 52193, 52197, 52205, 52219, 52225, 52228, 52231, 52234, 52249, 52263, 52264, 52269, 52271, 52278, 52288, 52296, 52297, 52355, 52359, 52363, 52389, 52420, 52436, 52441, 52456, 52460, 52467, 52478, 52484, 52509, 52518, 52530, 52532, 52535, 52541, 52566, 52582, 52588, 52593, 52594, 52604, 52615, 52619, 52626, 52631, 52653, 52657, 52666, 52693, 52695, 52697, 52726, 52728, 52778, 52802, 52807, 52808, 52834, 52848, 52853, 52855, 52861, 52875, 52876, 52878, 52899, 52952, 52957, 52985, 52990, 53001, 53020, 53081, 53098, 53102, 53105, 53131, 53149, 53176, 53192, 53220, 53238, 53273, 53288, 53297, 53299, 53309, 53314, 53322, 53341, 53347, 53351, 53371, 53392, 53397, 53399, 53404, 53411, 53437, 53459, 53461, 53463, 53464, 53522, 53541, 53545, 53554, 53577, 53591, 53608, 53619, 53632, 53636, 53654, 53663, 53664, 53673, 53679, 53695, 53724, 53725, 53729, 53734, 53735, 53749, 53751, 53754, 53758, 53759, 53763, 53770, 53771, 53772, 53774, 53802, 53804, 53810, 53822, 53833, 53836, 53842, 53847, 53866, 53870, 53921, 53931, 53944, 53953, 53964, 53973, 53974, 54005, 54015, 54054, 54066, 54090, 54120, 54121, 54132, 54147, 54153, 54183, 54187, 54190, 54193, 54229, 54257, 54274, 54276, 54281, 54289, 54325, 54337, 54355, 54368, 54392, 54397, 54401, 54406, 54420, 54444, 54465, 54471, 54473, 54494, 54502, 54509, 54511, 54514, 54523, 54536, 54537, 54559, 54563, 54564, 54577, 54586, 54587, 54595, 54602, 54604, 54609, 54610, 54613, 54620, 54623, 54625, 54642, 54651, 54661, 54662, 54663, 54679, 54682, 54683, 54689, 54739, 54741, 54757, 54762, 54764, 54765, 54782, 54788, 54794, 54797, 54805, 54814, 54825, 54829, 54830, 54861, 54867, 54877, 54891, 54892, 54910, 54928, 54929, 54930, 54935, 54936, 54950, 54958, 54961, 54964, 54966, 54969, 54987, 54999, 55013, 55023, 55055, 55071, 55078, 55083, 55104, 55105, 55111, 55116, 55138, 55147, 55186, 55193, 55201, 55204, 55238, 55266, 55273, 55281, 55287, 55291, 55308, 55334, 55357, 55363, 55365, 55393, 55398, 55400, 55402, 55407, 55409, 55428, 55441, 55473, 55507, 55515, 55523, 55534, 55543, 55545, 55549, 55557, 55559, 55575, 55585, 55601, 55616, 55659, 55670, 55715, 55716, 55719, 55725, 55743, 55750, 55772, 55801, 55844, 55849, 55853, 55871, 55878, 55895, 55896, 55901, 55904, 55910, 55912, 55930, 55935, 55963, 55972, 55992, 56009, 56027, 56032, 56038, 56042, 56045, 56046, 56058, 56060, 56070, 56098, 56108, 56110, 56120, 56168, 56179, 56184, 56191, 56200, 56201, 56204, 56209, 56212, 56224, 56225, 56257, 56269, 56283, 56287, 56289, 56301, 56304, 56316, 56317, 56321, 56356, 56361, 56385, 56391, 56394, 56405, 56407, 56418, 56440, 56443, 56447, 56450, 56456, 56458, 56462, 56468, 56476, 56484, 56492, 56507, 56517, 56549, 56552, 56570, 56572, 56579, 56611, 56613, 56621, 56636, 56652, 56661, 56674, 56678, 56707, 56714, 56724, 56740, 56746, 56816, 56825, 56836, 56848, 56853, 56858, 56867, 56872, 56874, 56890, 56892, 56898, 56910, 56930, 56950, 56963, 56965, 56982, 57056, 57063, 57074, 57081, 57083, 57097, 57103, 57109, 57110, 57126, 57139, 57171, 57183, 57187, 57202, 57231, 57251, 57260, 57264, 57275, 57276, 57283, 57299, 57306, 57310, 57313, 57342, 57369, 57425, 57437, 57443, 57460, 57465, 57470, 57476, 57485, 57511, 57535, 57554, 57562, 57573, 57575, 57585, 57588, 57592, 57593, 57604, 57613, 57615, 57617, 57619, 57663, 57669, 57708, 57711, 57713, 57731, 57735, 57737, 57740, 57745, 57753, 57760, 57765, 57770, 57773, 57774, 57775, 57786, 57788, 57795, 57810, 57832, 57836, 57858, 57872, 57878, 57882, 57886, 57887, 57889, 57899, 57907, 57920, 57953, 57964, 57972, 57981, 57982, 57985, 57989, 57990, 57997, 58004, 58005, 58027, 58049, 58051, 58054, 58071, 58075, 58100, 58105, 58108, 58113, 58128, 58135, 58149, 58153, 58156, 58169, 58184, 58187, 58193, 58203, 58205, 58217, 58218, 58229, 58238, 58249, 58257, 58261, 58264, 58265, 58271, 58278, 58286, 58287, 58296, 58308, 58325, 58351, 58371, 58389, 58416, 58431, 58454, 58456, 58472, 58475, 58483, 58508, 58514, 58518, 58519, 58522, 58524, 58528, 58530, 58540, 58570, 58574, 58576, 58586, 58590, 58593, 58609, 58617, 58618, 58627, 58631, 58633, 58640, 58660, 58672, 58674, 58720, 58723, 58730, 58736, 58752, 58757, 58758, 58771, 58782, 58793, 58796, 58799, 58809, 58811, 58817, 58821, 58825, 58839, 58848, 58851, 58852, 58854, 58855, 58857, 58878, 58889, 58891, 58903, 58930, 58938, 58940, 58947, 58965, 58991, 58993, 59019, 59036, 59069, 59072, 59087, 59090, 59101, 59113, 59120, 59127, 59133, 59136, 59141, 59152, 59156, 59161, 59166, 59169, 59177, 59200, 59210, 59220, 59222, 59226, 59250, 59252, 59255, 59266, 59267, 59278, 59299, 59301, 59317, 59343, 59344, 59347, 59352, 59364, 59367, 59375, 59382, 59387, 59396, 59402, 59411, 59415, 59417, 59420, 59442, 59448, 59458, 59464, 59469, 59472, 59485, 59489, 59496, 59507, 59516, 59537, 59546, 59547, 59563, 59615, 59619, 59628, 59630, 59637, 59657, 59664, 59675, 59677, 59706, 59707, 59712, 59716, 59757, 59761, 59777, 59785, 59788, 59797, 59816, 59819, 59822, 59829, 59839, 59844, 59845, 59870, 59881, 59883, 59889, 59890, 59907, 59911, 59917, 59924, 59941, 59943, 59946, 59948, 59950, 59976, 59979, 59980, 59986, 59988, 59999, 60020, 60046, 60057, 60096, 60104, 60106, 60130, 60139, 60142, 60146, 60169, 60174, 60179, 60180, 60181, 60194, 60204, 60207, 60235, 60325, 60362, 60383, 60423, 60441, 60455, 60463, 60505, 60508, 60531, 60545, 60570, 60572, 60579, 60582, 60597, 60600, 60614, 60624, 60626, 60649, 60653, 60667, 60672, 60679, 60736, 60737, 60739, 60747, 60753, 60763, 60767, 60775, 60782, 60792, 60809, 60851, 60864, 60878, 60881, 60887, 60890, 60893, 60907, 60925, 60949, 60966, 60968, 60969, 60975, 60985, 61003, 61012, 61024, 61034, 61054, 61056, 61076, 61081, 61085, 61106, 61111, 61113, 61118, 61119, 61144, 61181, 61182, 61187, 61188, 61195, 61196, 61198, 61223, 61235, 61236, 61259, 61276, 61282, 61296, 61298, 61316, 61355, 61377, 61393, 61413, 61415, 61417, 61421, 61434, 61441, 61452, 61458, 61462, 61472, 61473, 61474, 61475, 61502, 61517, 61519, 61521, 61539, 61546, 61562, 61569, 61574, 61581, 61585, 61587, 61597, 61620, 61622, 61630, 61638, 61663, 61673, 61676, 61688, 61711, 61733, 61735, 61740, 61749, 61764, 61771, 61783, 61802, 61871, 61886, 61904, 61932, 61948, 61959, 61991, 61998, 62004, 62007, 62028, 62042, 62087, 62157, 62169, 62181, 62190, 62210, 62212, 62227, 62242, 62261, 62271, 62296, 62308, 62316, 62343, 62345, 62346, 62383, 62389, 62393, 62402, 62412, 62415, 62421, 62456, 62466, 62476, 62479, 62480, 62488, 62497, 62498, 62505, 62506, 62518, 62522, 62539, 62543, 62547, 62559, 62561, 62576, 62586, 62603, 62606, 62639, 62647, 62650, 62654, 62669, 62684, 62698, 62734, 62735, 62761, 62764, 62795, 62813, 62837, 62841, 62854, 62858, 62884, 62909, 62914, 62927, 62930, 62933, 62937, 62946, 62950, 62958, 62974, 62980, 62983, 62995, 63000, 63007, 63009, 63058, 63059, 63063, 63074, 63088, 63098, 63109, 63139, 63163, 63173, 63185, 63200, 63201, 63218, 63220, 63234, 63238, 63249, 63253, 63280, 63290, 63298, 63320, 63327, 63329, 63360, 63390, 63402, 63405, 63409, 63415, 63430, 63456, 63459, 63461, 63481, 63489, 63492, 63494, 63496, 63509, 63559, 63560, 63563, 63567, 63579, 63581, 63582, 63616, 63628, 63646, 63652, 63676, 63692, 63693, 63695, 63697, 63701, 63710, 63740, 63745, 63746, 63761, 63771, 63778, 63785, 63833, 63845, 63852, 63866, 63875, 63898, 63922, 63943, 63958, 63961, 63992, 63993, 64004, 64008, 64014, 64021, 64026, 64027, 64037, 64041, 64093, 64099, 64100, 64104, 64123, 64145, 64154, 64168, 64182, 64188, 64191, 64195, 64197, 64227, 64232, 64248, 64260, 64262, 64270, 64282, 64292, 64295, 64298, 64311, 64357, 64370, 64432, 64465, 64472, 64485, 64495, 64514, 64519, 64550, 64558, 64570, 64579, 64581, 64597, 64601, 64619, 64652, 64655, 64671, 64689, 64694, 64701, 64714, 64719, 64721, 64740, 64752, 64753, 64766, 64780, 64785, 64796, 64825, 64839, 64846, 64874, 64881, 64891, 64893, 64904, 64906, 64921, 64925, 64927, 64944, 64952, 64969, 64970, 64980, 64983, 64994, 64997, 64999, 65003, 65007, 65025, 65049, 65052, 65056, 65082, 65090, 65113, 65124, 65130, 65147, 65161, 65176, 65219, 65226, 65247, 65268, 65310, 65341, 65342, 65359, 65360, 65370, 65374, 65375, 65393, 65421, 65426, 65427, 65431, 65435, 65442, 65463, 65465, 65476, 65490, 65502, 65516, 65523, 65527, 65535, 65538, 65541, 65544, 65547, 65556, 65559, 65565, 65611, 65620, 65623, 65630, 65636, 65646, 65678, 65703, 65706, 65723, 65733, 65741, 65760, 65779, 65793, 65810, 65815, 65824, 65827, 65833, 65835, 65855, 65887, 65893, 65894, 65895, 65946, 65950, 65959, 65962, 65970, 65975, 65988, 65994, 65999, 66015, 66037, 66054, 66061, 66069, 66084, 66093, 66094, 66130, 66133, 66144, 66152, 66157, 66172, 66190, 66193, 66217, 66218, 66221, 66228, 66246, 66256, 66264, 66283, 66288, 66296, 66322, 66373, 66383, 66395, 66405, 66411, 66437, 66463, 66496, 66505, 66507, 66532, 66555, 66560, 66572, 66574, 66580, 66595, 66596, 66629, 66641, 66657, 66683, 66690, 66696, 66730, 66736, 66745, 66753, 66761, 66768, 66772, 66807, 66825, 66827, 66831, 66850, 66851, 66878, 66880, 66892, 66900, 66903, 66919, 66936, 66953, 66955, 66959, 66974, 66988, 67017, 67041, 67042, 67067, 67070, 67072, 67085, 67089, 67134, 67139, 67140, 67144, 67158, 67175, 67188, 67213, 67227, 67239, 67241, 67281, 67301, 67321, 67343, 67365, 67390, 67408, 67409, 67421, 67423, 67461, 67477, 67480, 67481, 67505, 67512, 67520, 67527, 67533, 67548, 67559, 67568, 67576, 67603, 67617, 67619, 67620, 67623, 67629, 67635, 67636, 67639, 67652, 67653, 67716, 67722, 67739, 67740, 67744, 67771, 67772, 67774, 67788, 67792, 67800, 67814, 67831, 67835, 67843, 67853, 67887, 67902, 67920, 67922, 67926, 67937, 67976, 67985, 67987, 68006, 68007, 68024, 68028, 68075, 68082, 68089, 68094, 68095, 68109, 68116, 68126, 68128, 68132, 68145, 68162, 68173, 68176, 68186, 68192, 68201, 68208, 68209, 68218, 68221, 68223, 68231, 68234, 68251, 68272, 68300, 68319, 68350, 68355, 68356, 68381, 68391, 68392, 68396, 68416, 68420, 68437, 68457, 68460, 68464, 68491, 68505, 68513, 68530, 68543, 68546, 68579, 68591, 68623, 68624, 68635, 68645, 68673, 68687, 68702, 68738, 68759, 68764, 68765, 68780, 68784, 68791, 68797, 68827, 68832, 68849, 68850, 68857, 68860, 68863, 68865, 68870, 68878, 68884, 68887, 68900, 68902, 68907, 68909, 68915, 68926, 68939, 68941, 68956, 68989, 68991, 69000, 69006, 69015, 69022, 69047, 69079, 69110, 69131, 69158, 69162, 69167, 69168, 69182, 69194, 69248, 69265, 69272, 69274, 69280, 69282, 69289, 69295, 69296, 69299, 69322, 69341, 69342, 69344, 69359, 69370, 69388, 69398, 69399, 69402, 69406, 69411, 69416, 69438, 69480, 69483, 69487, 69507, 69518, 69528, 69546, 69548, 69567, 69574, 69578, 69585, 69596, 69604, 69620, 69626, 69639, 69650, 69672, 69678, 69679, 69682, 69684, 69690, 69698, 69711, 69713, 69719, 69739, 69763, 69778, 69781, 69797, 69799, 69805, 69811, 69822, 69825, 69890, 69896, 69898, 69904, 69917, 69934, 69976, 69981, 69992, 70003, 70023, 70026, 70080, 70083, 70099, 70123, 70146, 70156, 70164, 70169, 70182, 70184, 70206, 70217, 70221, 70222, 70226, 70234, 70239, 70252, 70259, 70267, 70278, 70323, 70329, 70337, 70368, 70373, 70380, 70389, 70396, 70420, 70441, 70458, 70463, 70469, 70473, 70478, 70485, 70491, 70492, 70511, 70517, 70520, 70543, 70550, 70561, 70571, 70572, 70576, 70592, 70609, 70612, 70623, 70628, 70645, 70651, 70655, 70675, 70682, 70698, 70699, 70709, 70714, 70717, 70722, 70723, 70728, 70736, 70740, 70772, 70784, 70807, 70822, 70832, 70851, 70854, 70864, 70874, 70890, 70899, 70911, 70937, 70954, 70957, 70971, 70974, 70989, 71005, 71006, 71070, 71072, 71089, 71091, 71093, 71103, 71119, 71127, 71129, 71143, 71175, 71184, 71192, 71194, 71200, 71233, 71243, 71262, 71280, 71296, 71309, 71327, 71328, 71336, 71339, 71341, 71353, 71364, 71365, 71377, 71382, 71386, 71397, 71412, 71413, 71414, 71433, 71445, 71477, 71479, 71507, 71513, 71525, 71532, 71536, 71564, 71571, 71576, 71577, 71580, 71596, 71617, 71645, 71652, 71660, 71665, 71689, 71704, 71722, 71728, 71739, 71743, 71760, 71788, 71797, 71800, 71812, 71821, 71837, 71857, 71862, 71869, 71871, 71878, 71889, 71921, 71923, 71927, 71929, 71945, 71961, 71998, 72031, 72036, 72043, 72048, 72054, 72073, 72079, 72091, 72102, 72107, 72116, 72119, 72120, 72126, 72143, 72146, 72164, 72173, 72197, 72202, 72207, 72225, 72229, 72231, 72233, 72236, 72279, 72287, 72290, 72300, 72309, 72317, 72324, 72329, 72353, 72355, 72358, 72378, 72387, 72408, 72412, 72417, 72421, 72447, 72454, 72461, 72511, 72520, 72536, 72540, 72554, 72557, 72562, 72582, 72608, 72633, 72634, 72647, 72667, 72671, 72673, 72690, 72725, 72727, 72763, 72775, 72778, 72783, 72790, 72827, 72844, 72849, 72851, 72860, 72885, 72897, 72907, 72930, 72932, 72942, 72943, 72969, 72978, 72988, 72999, 73015, 73020, 73038, 73055, 73061, 73063, 73074, 73077, 73090, 73110, 73113, 73126, 73129, 73155, 73175, 73186, 73198, 73223, 73231, 73234, 73243, 73265, 73280, 73289, 73313, 73316, 73363, 73375, 73376, 73384, 73401, 73429, 73433, 73440, 73444, 73460, 73463, 73465, 73473, 73477, 73498, 73499, 73509, 73512, 73521, 73526, 73530, 73537, 73540, 73557, 73559, 73565, 73575, 73578, 73583, 73612, 73639, 73648, 73661, 73682, 73693, 73755, 73756, 73765, 73776, 73790, 73808, 73811, 73819, 73822, 73832, 73834, 73859, 73863, 73868, 73886, 73887, 73888, 73896, 73953, 73961, 73970, 74002, 74010, 74022, 74034, 74038, 74039, 74046, 74081, 74092, 74116, 74195, 74201, 74211, 74215, 74217, 74229, 74230, 74232, 74237, 74269, 74282, 74291, 74332, 74346, 74348, 74353, 74369, 74373, 74376, 74388, 74394, 74404, 74406, 74409, 74444, 74456, 74486, 74493, 74502, 74503, 74505, 74546, 74548, 74556, 74562, 74575, 74585, 74608, 74610, 74632, 74639, 74640, 74673, 74674, 74679, 74680, 74702, 74716, 74725, 74737, 74755, 74763, 74764, 74771, 74786, 74794, 74798, 74805, 74823, 74830, 74851, 74857, 74860, 74880, 74888, 74889, 74891, 74899, 74907, 74926, 74932, 74945, 74950, 74975, 74976, 74993, 74999, 75001, 75026, 75029, 75034, 75054, 75061, 75100, 75101, 75107, 75114, 75117, 75155, 75159, 75170, 75181, 75230, 75240, 75249, 75281, 75305, 75314, 75320, 75335, 75347, 75353, 75360, 75395, 75396, 75401, 75424, 75430, 75431, 75444, 75446, 75454, 75493, 75509, 75510, 75514, 75517, 75526, 75536, 75607, 75640, 75650, 75658, 75688, 75696, 75715, 75722, 75737, 75759, 75772, 75775, 75800, 75819, 75824, 75828, 75829, 75843, 75856, 75865, 75867, 75882, 75889, 75890, 75891, 75898, 75899, 75941, 75950, 75960, 75990, 75994, 76005, 76010, 76030, 76034, 76074, 76078, 76097, 76115, 76118, 76126, 76143, 76180, 76186, 76253, 76261, 76262, 76265, 76275, 76300, 76318, 76319, 76328, 76329, 76333, 76392, 76410, 76414, 76418, 76437, 76439, 76457, 76476, 76479, 76480, 76508, 76529, 76541, 76544, 76558, 76562, 76571, 76575, 76597, 76600, 76602, 76612, 76633, 76637, 76641, 76658, 76659, 76665, 76667, 76670, 76674, 76707, 76716, 76717, 76741, 76761, 76812, 76826, 76843, 76873, 76880, 76886, 76890, 76912, 76920, 76921, 76923, 76930, 76945, 76952, 76955, 76974, 76987, 76988, 76994, 77010, 77013, 77014, 77026, 77028, 77034, 77037, 77041, 77045, 77053, 77078, 77081, 77083, 77084, 77115, 77135, 77149, 77163, 77189, 77192, 77206, 77218, 77223, 77241, 77265, 77301, 77303, 77331, 77341, 77349, 77416, 77443, 77450, 77471, 77472, 77503, 77511, 77520, 77537, 77552, 77575, 77576, 77579, 77586, 77599, 77600, 77606, 77609, 77618, 77630, 77665, 77689, 77690, 77691, 77696, 77697, 77707, 77731, 77732, 77746, 77764, 77781, 77787, 77801, 77804, 77826, 77828, 77829, 77850, 77875, 77882, 77900, 77901, 77912, 77913, 77922, 77947, 77948, 77949, 78000, 78009, 78023, 78086, 78097, 78100, 78108, 78117, 78149, 78152, 78155, 78158, 78171, 78204, 78215, 78219, 78222, 78226, 78230, 78231, 78234, 78248, 78288, 78298, 78303, 78318, 78319, 78322, 78325, 78336, 78337, 78354, 78365, 78373, 78380, 78388, 78410, 78447, 78454, 78474, 78494, 78495, 78505, 78506, 78532, 78536, 78551, 78560, 78568, 78570, 78597, 78600, 78615, 78647, 78658, 78666, 78678, 78685, 78693, 78701, 78708, 78716, 78722, 78729, 78739, 78745, 78756, 78797, 78804, 78814, 78828, 78840, 78859, 78864, 78867, 78873, 78879, 78891, 78895, 78898, 78902, 78904, 78911, 78914, 78946, 78959, 78983, 78996, 79051, 79053, 79060, 79089, 79103, 79126, 79132, 79154, 79166, 79168, 79177, 79188, 79224, 79229, 79252, 79283, 79288, 79294, 79308, 79337, 79348, 79349, 79355, 79404, 79418, 79422, 79426, 79427, 79441, 79466, 79501, 79511, 79532, 79538, 79548, 79565, 79578, 79584, 79585, 79589, 79596, 79602, 79603, 79655, 79667, 79673, 79677, 79690, 79737, 79751, 79754, 79804, 79813, 79826, 79831, 79836, 79862, 79875, 79877, 79909, 79919, 79921, 79923, 79945, 79962, 79987, 79991, 79998, 80018, 80020, 80030, 80042, 80053, 80081, 80106, 80108, 80110, 80111, 80117, 80132, 80136, 80158, 80160, 80190, 80204, 80220, 80228, 80237, 80239, 80245, 80254, 80260, 80262, 80267, 80274, 80299, 80305, 80308, 80317, 80319, 80320, 80326, 80335, 80344, 80345, 80347, 80360, 80375, 80400, 80410, 80423, 80429, 80436, 80442, 80447, 80470, 80472, 80475, 80490, 80494, 80504, 80511, 80519, 80521, 80523, 80534, 80539, 80547, 80559, 80580, 80586, 80587, 80606, 80625, 80629, 80632, 80649, 80653, 80656, 80678, 80696, 80729, 80742, 80745, 80751, 80757, 80767, 80790, 80791, 80810, 80826, 80844, 80849, 80856, 80861, 80862, 80880, 80885, 80891, 80914, 80935, 80942, 80956, 80985, 80987, 80989, 80993, 80999, 81004, 81006, 81007, 81012, 81025, 81032, 81037, 81045, 81049, 81053, 81057, 81069, 81087, 81099, 81107, 81195, 81209, 81212, 81223, 81235, 81236, 81237, 81242, 81247, 81267, 81274, 81280, 81285, 81295, 81335, 81342, 81349, 81359, 81363, 81376, 81385, 81416, 81425, 81427, 81431, 81438, 81441, 81449, 81464, 81478, 81480, 81491, 81534, 81548, 81556, 81561, 81583, 81601, 81614, 81633, 81651, 81675, 81679, 81686, 81691, 81692, 81715, 81721, 81728, 81755, 81783, 81797, 81807, 81810, 81818, 81827, 81844, 81849, 81850, 81864, 81865, 81876, 81881, 81891, 81904, 81918, 81926, 81927, 81958, 81978, 81983, 81992, 81997, 81998, 82003, 82021, 82030, 82036, 82042, 82055, 82057, 82072, 82075, 82091, 82100, 82111, 82122, 82130, 82132, 82138, 82148, 82150, 82157, 82177, 82178, 82195, 82217, 82235, 82238, 82245, 82258, 82279, 82290, 82293, 82309, 82326, 82328, 82360, 82362, 82363, 82393, 82433, 82459, 82466, 82482, 82490, 82505, 82514, 82518, 82563, 82565, 82594, 82602, 82605, 82619, 82627, 82637, 82641, 82642, 82646, 82655, 82713, 82736, 82746, 82769, 82799, 82802, 82826, 82828, 82836, 82843, 82845, 82847, 82864, 82881, 82915, 82929, 82939, 82950, 82970, 82973, 83010, 83013, 83065, 83079, 83085, 83091, 83099, 83122, 83128, 83143, 83169, 83180, 83202, 83203, 83210, 83212, 83228, 83235, 83248, 83258, 83263, 83278, 83292, 83317, 83335, 83342, 83345, 83361, 83372, 83375, 83382, 83389, 83422, 83427, 83435, 83464, 83466, 83469, 83496, 83500, 83509, 83514, 83524, 83532, 83545, 83561, 83564, 83592, 83594, 83596, 83607, 83617, 83629, 83662, 83668, 83681, 83690, 83692, 83697, 83699, 83700, 83702, 83709, 83723, 83751, 83766, 83768, 83773, 83776, 83792, 83802, 83818, 83826, 83865, 83869, 83879, 83892, 83899, 83901, 83908, 83914, 83915, 83922, 83924, 83932, 83947, 83957, 83960, 83975, 83976, 83981, 83988, 83991, 84001, 84020, 84021, 84033, 84036, 84039, 84061, 84081, 84095, 84105, 84117, 84120, 84128, 84129, 84142, 84172, 84198, 84208, 84223, 84247, 84266, 84286, 84302, 84303, 84306, 84318, 84319, 84332, 84346, 84347, 84359, 84362, 84382, 84388, 84392, 84394, 84402, 84420, 84427, 84450, 84454, 84457, 84458, 84461, 84463, 84473, 84476, 84478, 84479, 84488, 84489, 84495, 84516, 84519, 84523, 84534, 84598, 84615, 84624, 84632, 84638, 84640, 84647, 84669, 84681, 84694, 84711, 84737, 84742, 84745, 84758, 84764, 84766, 84798, 84802, 84822, 84838, 84875, 84881, 84886, 84891, 84896, 84904, 84909, 84934, 84938, 84952, 84958, 84964, 84979, 84983, 85017, 85019, 85023, 85033, 85039, 85042, 85056, 85062, 85076, 85079, 85085, 85089, 85095, 85134, 85138, 85143, 85147, 85152, 85163, 85171, 85205, 85212, 85257, 85258, 85264, 85272, 85361, 85370, 85375, 85417, 85441, 85455, 85459, 85490, 85492, 85493, 85501, 85508, 85516, 85533, 85535, 85552, 85560, 85562, 85566, 85575, 85583, 85607, 85608, 85638, 85645, 85647, 85665, 85669, 85685, 85689, 85698, 85700, 85720, 85723, 85730, 85747, 85748, 85757, 85769, 85775, 85780, 85781, 85784, 85828, 85842, 85851, 85853, 85860, 85866, 85870, 85885, 85889, 85899, 85907, 85932, 85938, 85962, 85974, 85983, 86007, 86024, 86026, 86036, 86041, 86042, 86078, 86086, 86087, 86123, 86129, 86137, 86144, 86176, 86193, 86199, 86220, 86233, 86238, 86239, 86251, 86270, 86295, 86300, 86306, 86323, 86325, 86326, 86355, 86356, 86368, 86379, 86382, 86387, 86411, 86413, 86429, 86450, 86485, 86502, 86505, 86516, 86539, 86546, 86550, 86561, 86570, 86577, 86580, 86583, 86585, 86586, 86587, 86590, 86603, 86611, 86616, 86618, 86621, 86678, 86692, 86702, 86712, 86717, 86745, 86749, 86752, 86754, 86762, 86766, 86773, 86807, 86810, 86821, 86824, 86832, 86841, 86846, 86848, 86880, 86883, 86888, 86894, 86897, 86907, 86915, 86918, 86919, 86921, 86976, 87007, 87029, 87035, 87056, 87082, 87085, 87108, 87118, 87135, 87157, 87160, 87185, 87187, 87188, 87197, 87206, 87209, 87216, 87232, 87236, 87245, 87252, 87253, 87254, 87259, 87263, 87275, 87279, 87283, 87284, 87291, 87320, 87325, 87336, 87344, 87347, 87361, 87375, 87376, 87400, 87421, 87424, 87450, 87461, 87474, 87484, 87497, 87506, 87532, 87533, 87565, 87572, 87585, 87595, 87605, 87608, 87628, 87631, 87642, 87646, 87651, 87659, 87660, 87704, 87706, 87708, 87711, 87721, 87733, 87734, 87754, 87758, 87769, 87783, 87818, 87846, 87858, 87880, 87887, 87926, 87932, 87936, 87948, 87949, 87957, 87963, 87969, 87986, 87992, 87994, 87999, 88000, 88006, 88008, 88009, 88012, 88021, 88040, 88079, 88089, 88112, 88154, 88163, 88165, 88175, 88180, 88206, 88211, 88214, 88220, 88224, 88243, 88254, 88258, 88269, 88291, 88296, 88303, 88312, 88315, 88316, 88345, 88350, 88360, 88407, 88409, 88422, 88429, 88432, 88433, 88434, 88438, 88449, 88471, 88476, 88486, 88514, 88529, 88531, 88539, 88560, 88565, 88571, 88584, 88594, 88602, 88624, 88626, 88632, 88635, 88649, 88663, 88665, 88695, 88696, 88734, 88738, 88747, 88764, 88773, 88778, 88790, 88795, 88824, 88844, 88851, 88882, 88883, 88888, 88912, 88921, 88951, 88961, 88991, 89021, 89050, 89104, 89119, 89124, 89126, 89132, 89157, 89176, 89193, 89205, 89252, 89265, 89268, 89285, 89290, 89292, 89294, 89324, 89334, 89336, 89355, 89363, 89368, 89369, 89379, 89398, 89400, 89416, 89419, 89446, 89448, 89451, 89481, 89485, 89493, 89502, 89520, 89536, 89544, 89563, 89579, 89584, 89597, 89600, 89607, 89616, 89617, 89634, 89643, 89654, 89672, 89686, 89719, 89735, 89736, 89742, 89755, 89760, 89797, 89798, 89817, 89849, 89895, 89901, 89906, 89914, 89917, 89927, 89929, 89934, 89950, 89952, 89956, 89957, 89984, 89996, 89997, 90008, 90021, 90028, 90036, 90051, 90057, 90070, 90078, 90106, 90120, 90150, 90151, 90158, 90165, 90176, 90195, 90208, 90233, 90238, 90259, 90261, 90270, 90279, 90302, 90310, 90327, 90369, 90389, 90392, 90418, 90427, 90441, 90452, 90455, 90478, 90488, 90508, 90521, 90533, 90538, 90541, 90544, 90549, 90559, 90560, 90609, 90639, 90657, 90663, 90672, 90686, 90699, 90704, 90708, 90720, 90722, 90727, 90739, 90755, 90764, 90768, 90776, 90780, 90789, 90795, 90798, 90802, 90805, 90814, 90830, 90834, 90846, 90863, 90874, 90884, 90887, 90889, 90890, 90898, 90901, 90903, 90905, 90910, 90917, 90937, 90954, 90990, 91000, 91001, 91008, 91046, 91051, 91053, 91074, 91076, 91086, 91098, 91101, 91150, 91167, 91197, 91200, 91219, 91223, 91245, 91249, 91285, 91296, 91333, 91342, 91350, 91351, 91419, 91428, 91437, 91458, 91460, 91461, 91463, 91469, 91472, 91493, 91519, 91525, 91531, 91534, 91548, 91557, 91568, 91572, 91583, 91586, 91588, 91601, 91603, 91614, 91635, 91682, 91705, 91712, 91733, 91744, 91763, 91782, 91783, 91788, 91790, 91798, 91802, 91814, 91832, 91842, 91853, 91855, 91883, 91913, 91915, 91925, 91926, 91934, 91948, 91954, 91965, 91989, 91992, 91996, 92025, 92036, 92041, 92063, 92066, 92094, 92105, 92129, 92136, 92170, 92201, 92212, 92235, 92239, 92253, 92278, 92287, 92288, 92291, 92314, 92323, 92331, 92346, 92347, 92353, 92382, 92410, 92438, 92452, 92454, 92458, 92464, 92487, 92516, 92554, 92580, 92585, 92606, 92613, 92615, 92636, 92668, 92676, 92684, 92686, 92695, 92704, 92718, 92725, 92767, 92775, 92777, 92787, 92793, 92796, 92799, 92800, 92861, 92865, 92919, 92933, 92934, 92941, 92954, 92955, 92969, 92974, 92999, 93011, 93033, 93056, 93062, 93084, 93088, 93104, 93113, 93117, 93119, 93122, 93139, 93142, 93155, 93159, 93191, 93194, 93207, 93209, 93219, 93233, 93280, 93284, 93299, 93301, 93315, 93320, 93321, 93325, 93357, 93365, 93378, 93379, 93388, 93390, 93392, 93394, 93398, 93401, 93411, 93422, 93462, 93472, 93479, 93494, 93496, 93507, 93541, 93556, 93560, 93566, 93567, 93588, 93593, 93601, 93602, 93648, 93659, 93662, 93701, 93710, 93721, 93739, 93784, 93788, 93807, 93814, 93829, 93833, 93834, 93838, 93840, 93847, 93887, 93894, 93905, 93920, 93923, 93924, 93932, 93945, 93950, 93952, 93956, 93966, 93970, 93974, 93983, 93987, 94005, 94007, 94008, 94016, 94025, 94029, 94030, 94032, 94072, 94081, 94084, 94085, 94104, 94105, 94113, 94120, 94126, 94152, 94162, 94166, 94167, 94184, 94192, 94195, 94196, 94197, 94213, 94232, 94240, 94260, 94264, 94297, 94319, 94335, 94351, 94404, 94422, 94437, 94447, 94484, 94538, 94539, 94546, 94550, 94560, 94564, 94581, 94592, 94597, 94609, 94611, 94642, 94661, 94663, 94665, 94669, 94685, 94689, 94696, 94733, 94734, 94753, 94763, 94765, 94767, 94768, 94777, 94786, 94799, 94805, 94817, 94821, 94828, 94837, 94863, 94864, 94872, 94906, 94912, 94933, 94944, 94954, 94956, 94959, 94962, 94966, 94979, 94982, 94987, 94997, 95000, 95004, 95011, 95030, 95039, 95045, 95052, 95057, 95058, 95076, 95077, 95084, 95090, 95105, 95111, 95115, 95126, 95143, 95155, 95157, 95170, 95177, 95227, 95241, 95251, 95271, 95316, 95324, 95335, 95340, 95351, 95372, 95380, 95408, 95410, 95424, 95427, 95435, 95440, 95465, 95469, 95508, 95512, 95517, 95540, 95555, 95561, 95574, 95609, 95611, 95621, 95628, 95631, 95632, 95637, 95641, 95659, 95672, 95674, 95707, 95721, 95725, 95736, 95760, 95763, 95765, 95782, 95787, 95798, 95803, 95810, 95818, 95821, 95830, 95834, 95841, 95863, 95864, 95868, 95878, 95887, 95889, 95892, 95893, 95895, 95907, 95909, 95951, 95968, 95977, 96004, 96017, 96023, 96025, 96040, 96046, 96071, 96098, 96100, 96104, 96115, 96120, 96125, 96126, 96137, 96140, 96171, 96176, 96187, 96218, 96234, 96247, 96260, 96261, 96284, 96323, 96324, 96333, 96336, 96346, 96347, 96350, 96365, 96370, 96377, 96378, 96389, 96391, 96402, 96404, 96410, 96430, 96435, 96442, 96445, 96446, 96456, 96458, 96468, 96477, 96479, 96482, 96519, 96540, 96553, 96574, 96575, 96579, 96581, 96582, 96588, 96610, 96621, 96624, 96637, 96645, 96659, 96666, 96670, 96677, 96683, 96695, 96699, 96709, 96719, 96731, 96737, 96759, 96761, 96772, 96785, 96808, 96813, 96815, 96825, 96843, 96848, 96864, 96869, 96872, 96877, 96888, 96920, 96922, 96923, 96930, 96947, 96960, 96962, 96974, 96984, 96997, 97007, 97008, 97022, 97023, 97028, 97037, 97048, 97061, 97069, 97079, 97102, 97121, 97132, 97143, 97151, 97156, 97172, 97178, 97206, 97229, 97232, 97263, 97314, 97333, 97339, 97351, 97395, 97399, 97429, 97437, 97441, 97443, 97449, 97460, 97484, 97497, 97524, 97529, 97531, 97532, 97537, 97539, 97560, 97564, 97566, 97589, 97593, 97598, 97603, 97625, 97637, 97646, 97679, 97680, 97681, 97683, 97706, 97714, 97716, 97735, 97762, 97768, 97771, 97781, 97783, 97795, 97799, 97833, 97834, 97841, 97848, 97864, 97876, 97898, 97916, 97933, 97937, 97942, 97947, 97971, 97974, 97976, 97978, 97981, 97984, 98001, 98040, 98046, 98048, 98050, 98057, 98130, 98162, 98176, 98182, 98185, 98188, 98195, 98196, 98198, 98204, 98220, 98228, 98229, 98235, 98256, 98258, 98268, 98279, 98283, 98284, 98303, 98309, 98310, 98318, 98335, 98342, 98347, 98359, 98383, 98390, 98400, 98402, 98413, 98417, 98420, 98448, 98484, 98511, 98517, 98525, 98530, 98554, 98558, 98564, 98584, 98586, 98588, 98589, 98601, 98622, 98642, 98647, 98649, 98664, 98665, 98669, 98674, 98685, 98698, 98710, 98734, 98751, 98759, 98794, 98805, 98813, 98814, 98831, 98833, 98834, 98879, 98883, 98899, 98905, 98919, 98931, 98939, 98969, 98973, 98991, 98999, 99023, 99078, 99085, 99098, 99111, 99135, 99141, 99166, 99178, 99205, 99208, 99213, 99218, 99231, 99247, 99255, 99256, 99258, 99282, 99283, 99286, 99293, 99312, 99319, 99322, 99333, 99339, 99344, 99356, 99411, 99412, 99430, 99439, 99440, 99458, 99464, 99467, 99469, 99474, 99485, 99492, 99495, 99509, 99528, 99538, 99539, 99545, 99556, 99560, 99561, 99562, 99572, 99598, 99599, 99611, 99629, 99637, 99645, 99647, 99650, 99666, 99674, 99691, 99693, 99721, 99726, 99740, 99759, 99762, 99768, 99781, 99791, 99797, 99806, 99810, 99817, 99819, 99823, 99836, 99837, 99847, 99864, 99868, 99873, 99880, 99881, 99883, 99901, 99913, 99934, 99936, 99939, 99944, 99955, 99957, 99965, 99991, 99992, 99995]\n","dev_ids =  [11, 32, 33, 43, 98, 150, 151, 161, 172, 188, 243, 266, 276, 317, 325, 328, 359, 368, 372, 376, 388, 426, 456, 493, 495, 501, 509, 527, 548, 551, 585, 588, 589, 591, 592, 595, 606, 622, 625, 627, 629, 636, 670, 709, 734, 746, 751, 798, 803, 810, 827, 852, 856, 905, 915, 932, 936, 947, 956, 1029, 1034, 1069, 1103, 1104, 1147, 1184, 1191, 1206, 1213, 1290, 1323, 1369, 1371, 1398, 1467, 1494, 1539, 1590, 1593, 1597, 1641, 1693, 1696, 1708, 1725, 1753, 1758, 1792, 1853, 1862, 1928, 1964, 1974, 1986, 1997, 2036, 2067, 2071, 2080, 2102, 2105, 2156, 2223, 2245, 2257, 2266, 2270, 2314, 2317, 2334, 2379, 2385, 2436, 2460, 2466, 2467, 2480, 2502, 2506, 2537, 2550, 2569, 2636, 2689, 2711, 2736, 2760, 2783, 2813, 2831, 2849, 2862, 2881, 2961, 2962, 2967, 3023, 3039, 3080, 3134, 3142, 3145, 3183, 3231, 3241, 3242, 3297, 3313, 3324, 3325, 3342, 3351, 3354, 3404, 3432, 3439, 3465, 3470, 3565, 3595, 3597, 3598, 3628, 3631, 3646, 3663, 3675, 3688, 3767, 3778, 3787, 3862, 3892, 3899, 3903, 3947, 3979, 3983, 3985, 4007, 4059, 4074, 4084, 4092, 4100, 4130, 4169, 4202, 4209, 4224, 4225, 4243, 4276, 4326, 4338, 4371, 4414, 4431, 4433, 4462, 4485, 4527, 4562, 4565, 4576, 4626, 4649, 4673, 4674, 4708, 4722, 4732, 4743, 4777, 4813, 4826, 4838, 4839, 4860, 4863, 4868, 4871, 4877, 4903, 4926, 4939, 4969, 4974, 4988, 5003, 5009, 5027, 5057, 5060, 5099, 5199, 5270, 5272, 5304, 5312, 5331, 5349, 5355, 5362, 5381, 5415, 5453, 5455, 5506, 5521, 5536, 5551, 5555, 5557, 5573, 5579, 5585, 5586, 5622, 5626, 5650, 5683, 5686, 5715, 5731, 5762, 5817, 5830, 5833, 5834, 5864, 5905, 5913, 5987, 6000, 6010, 6022, 6077, 6078, 6083, 6085, 6118, 6126, 6127, 6134, 6137, 6202, 6213, 6229, 6234, 6246, 6322, 6353, 6391, 6478, 6495, 6536, 6540, 6545, 6555, 6600, 6621, 6623, 6632, 6643, 6647, 6669, 6694, 6707, 6723, 6736, 6821, 6838, 6865, 6878, 6957, 7009, 7052, 7073, 7163, 7180, 7204, 7230, 7242, 7263, 7315, 7320, 7321, 7328, 7385, 7392, 7410, 7461, 7496, 7505, 7512, 7538, 7569, 7597, 7604, 7648, 7651, 7663, 7715, 7757, 7761, 7766, 7778, 7792, 7797, 7821, 7822, 7861, 7866, 7881, 7886, 7946, 7955, 7969, 7971, 7999, 8043, 8073, 8117, 8151, 8224, 8225, 8264, 8281, 8389, 8408, 8464, 8471, 8493, 8535, 8537, 8546, 8559, 8618, 8635, 8691, 8710, 8741, 8764, 8770, 8803, 8816, 8845, 8852, 8875, 8904, 8927, 8936, 8956, 9101, 9124, 9137, 9138, 9155, 9186, 9191, 9192, 9283, 9284, 9336, 9348, 9408, 9416, 9427, 9443, 9501, 9514, 9545, 9646, 9663, 9678, 9693, 9749, 9767, 9776, 9838, 9841, 9866, 9897, 9949, 9977, 9992, 9998, 10003, 10059, 10119, 10145, 10147, 10193, 10199, 10238, 10315, 10316, 10317, 10331, 10363, 10401, 10402, 10412, 10439, 10445, 10461, 10490, 10497, 10515, 10523, 10538, 10585, 10589, 10608, 10707, 10712, 10725, 10729, 10744, 10746, 10760, 10763, 10768, 10769, 10792, 10805, 10820, 10831, 10850, 10873, 10908, 10945, 10958, 11008, 11058, 11098, 11184, 11191, 11193, 11200, 11217, 11228, 11229, 11238, 11244, 11256, 11307, 11321, 11325, 11359, 11378, 11383, 11386, 11388, 11395, 11416, 11421, 11453, 11471, 11492, 11549, 11564, 11578, 11595, 11605, 11671, 11673, 11694, 11702, 11773, 11806, 11807, 11866, 11922, 11928, 11934, 11943, 11956, 12009, 12018, 12055, 12097, 12098, 12099, 12109, 12114, 12117, 12171, 12198, 12238, 12270, 12326, 12360, 12375, 12399, 12406, 12487, 12510, 12528, 12542, 12550, 12560, 12571, 12579, 12688, 12693, 12694, 12702, 12733, 12783, 12811, 12832, 12860, 12978, 13010, 13013, 13026, 13032, 13039, 13188, 13191, 13193, 13201, 13210, 13227, 13253, 13263, 13264, 13271, 13282, 13293, 13318, 13366, 13374, 13375, 13414, 13416, 13458, 13519, 13538, 13546, 13555, 13561, 13596, 13602, 13614, 13646, 13649, 13660, 13672, 13680, 13702, 13705, 13783, 13790, 13791, 13810, 13818, 13843, 13870, 13890, 13909, 13929, 13967, 13989, 14030, 14036, 14072, 14114, 14117, 14122, 14138, 14144, 14146, 14167, 14169, 14244, 14264, 14272, 14291, 14297, 14312, 14328, 14373, 14390, 14394, 14398, 14408, 14439, 14453, 14474, 14489, 14493, 14513, 14551, 14553, 14566, 14603, 14616, 14645, 14685, 14696, 14761, 14798, 14802, 14822, 14845, 14857, 14950, 14962, 15009, 15013, 15017, 15025, 15061, 15079, 15117, 15122, 15125, 15128, 15159, 15178, 15203, 15209, 15254, 15295, 15305, 15330, 15351, 15416, 15470, 15477, 15496, 15551, 15595, 15626, 15627, 15654, 15691, 15713, 15725, 15773, 15883, 15898, 15907, 15992, 16000, 16003, 16011, 16037, 16040, 16081, 16177, 16179, 16205, 16284, 16295, 16334, 16344, 16458, 16459, 16469, 16478, 16483, 16565, 16607, 16637, 16714, 16721, 16728, 16750, 16793, 16818, 16840, 16853, 16867, 16881, 16884, 16902, 16921, 16960, 16968, 16973, 16997, 17026, 17031, 17043, 17061, 17127, 17239, 17268, 17274, 17308, 17339, 17411, 17413, 17442, 17451, 17468, 17505, 17513, 17521, 17533, 17547, 17586, 17589, 17609, 17614, 17623, 17686, 17693, 17698, 17709, 17745, 17759, 17800, 17813, 17841, 17902, 17929, 17957, 17998, 18013, 18023, 18060, 18061, 18082, 18089, 18111, 18122, 18153, 18180, 18216, 18257, 18299, 18331, 18371, 18408, 18426, 18457, 18473, 18483, 18489, 18509, 18513, 18525, 18543, 18572, 18589, 18590, 18597, 18600, 18630, 18655, 18678, 18679, 18690, 18719, 18745, 18766, 18781, 18857, 18860, 18900, 18908, 18934, 18962, 18975, 19013, 19044, 19057, 19070, 19076, 19081, 19105, 19125, 19147, 19172, 19205, 19230, 19267, 19305, 19306, 19338, 19367, 19392, 19421, 19487, 19504, 19520, 19553, 19613, 19614, 19618, 19673, 19675, 19723, 19728, 19746, 19792, 19793, 19828, 19845, 19892, 19899, 19927, 19941, 19981, 20001, 20064, 20130, 20210, 20236, 20251, 20255, 20259, 20262, 20284, 20286, 20315, 20316, 20368, 20383, 20400, 20414, 20428, 20459, 20471, 20511, 20513, 20540, 20543, 20545, 20561, 20564, 20578, 20579, 20616, 20633, 20664, 20718, 20760, 20763, 20796, 20801, 20805, 20877, 20920, 20929, 20957, 20981, 20984, 21004, 21017, 21021, 21052, 21074, 21084, 21091, 21095, 21173, 21181, 21206, 21242, 21263, 21298, 21334, 21349, 21357, 21372, 21380, 21382, 21428, 21434, 21453, 21462, 21479, 21501, 21507, 21548, 21601, 21618, 21658, 21687, 21750, 21765, 21781, 21789, 21799, 21820, 21827, 21853, 21864, 21867, 21888, 21905, 21920, 21946, 22025, 22047, 22051, 22085, 22143, 22191, 22200, 22226, 22235, 22339, 22414, 22462, 22469, 22528, 22552, 22631, 22715, 22757, 22771, 22890, 22896, 22979, 23022, 23023, 23055, 23063, 23088, 23105, 23115, 23120, 23152, 23159, 23171, 23211, 23229, 23250, 23303, 23352, 23359, 23370, 23401, 23478, 23497, 23524, 23592, 23600, 23604, 23607, 23659, 23674, 23703, 23719, 23741, 23755, 23789, 23795, 23803, 23804, 23827, 23861, 23905, 23940, 23948, 23977, 23997, 24052, 24066, 24071, 24119, 24134, 24135, 24160, 24212, 24263, 24268, 24283, 24307, 24314, 24317, 24322, 24324, 24356, 24388, 24466, 24493, 24546, 24561, 24600, 24650, 24663, 24675, 24711, 24763, 24777, 24800, 24823, 24840, 24856, 24858, 24881, 24892, 24986, 24991, 24992, 25008, 25027, 25034, 25043, 25084, 25118, 25171, 25185, 25201, 25206, 25224, 25228, 25245, 25251, 25306, 25325, 25350, 25378, 25411, 25413, 25482, 25549, 25550, 25556, 25639, 25644, 25678, 25731, 25741, 25770, 25776, 25869, 25969, 25993, 26006, 26013, 26018, 26054, 26063, 26072, 26125, 26169, 26176, 26184, 26192, 26214, 26220, 26241, 26244, 26255, 26339, 26374, 26419, 26458, 26475, 26479, 26483, 26502, 26516, 26549, 26560, 26569, 26595, 26610, 26673, 26695, 26696, 26732, 26776, 26787, 26796, 26800, 26820, 26833, 26841, 26851, 26911, 26914, 26968, 27000, 27046, 27049, 27083, 27084, 27092, 27096, 27108, 27125, 27138, 27146, 27163, 27171, 27243, 27263, 27272, 27275, 27279, 27300, 27301, 27345, 27359, 27370, 27387, 27389, 27403, 27440, 27473, 27493, 27511, 27523, 27566, 27584, 27596, 27600, 27605, 27634, 27689, 27692, 27710, 27754, 27767, 27795, 27800, 27826, 27836, 27926, 27953, 27955, 27969, 27978, 27993, 28028, 28032, 28035, 28043, 28091, 28098, 28103, 28137, 28195, 28213, 28224, 28241, 28258, 28268, 28283, 28360, 28377, 28385, 28409, 28423, 28517, 28531, 28540, 28550, 28617, 28633, 28641, 28655, 28669, 28670, 28677, 28686, 28726, 28729, 28750, 28799, 28828, 28856, 28883, 28911, 28936, 28985, 29028, 29061, 29069, 29075, 29089, 29127, 29139, 29170, 29220, 29221, 29224, 29251, 29254, 29261, 29333, 29344, 29418, 29429, 29447, 29473, 29477, 29490, 29495, 29527, 29536, 29565, 29571, 29592, 29617, 29618, 29620, 29651, 29664, 29676, 29685, 29702, 29711, 29752, 29774, 29825, 29866, 29894, 29941, 29959, 29969, 29986, 29995, 30015, 30038, 30040, 30105, 30184, 30241, 30393, 30409, 30437, 30467, 30475, 30481, 30493, 30497, 30528, 30538, 30539, 30642, 30662, 30674, 30677, 30692, 30740, 30800, 30833, 30846, 30924, 30940, 30954, 30971, 30975, 30979, 30984, 30998, 31036, 31140, 31161, 31187, 31191, 31216, 31221, 31238, 31293, 31305, 31310, 31312, 31359, 31367, 31376, 31377, 31445, 31452, 31507, 31510, 31513, 31519, 31541, 31570, 31589, 31664, 31671, 31716, 31717, 31727, 31756, 31777, 31817, 31872, 31877, 31916, 31930, 31937, 31942, 31950, 31956, 31977, 32001, 32015, 32024, 32025, 32036, 32059, 32060, 32065, 32070, 32073, 32078, 32088, 32092, 32093, 32115, 32126, 32128, 32153, 32157, 32166, 32183, 32195, 32231, 32267, 32368, 32372, 32396, 32403, 32422, 32439, 32444, 32450, 32460, 32480, 32525, 32526, 32531, 32532, 32542, 32550, 32584, 32605, 32608, 32629, 32639, 32645, 32664, 32695, 32696, 32701, 32718, 32779, 32800, 40008, 40138, 40236, 40251, 40269, 40299, 40385, 40406, 40433, 40707, 40775, 40797, 40826, 40851, 40995, 41031, 41098, 41132, 41266, 41286, 41385, 41398, 41430, 41439, 41457, 41468, 41565, 41603, 41634, 41661, 41693, 41841, 42071, 42073, 42268, 42307, 42336, 42411, 42591, 42606, 42696, 42728, 42748, 42763, 42800, 43099, 43149, 43305, 43452, 43461, 43584, 43637, 43729, 43741, 43969, 44002, 44023, 44190, 44318, 44342, 44494, 44630, 44672, 44787, 44910, 44963, 44969, 44971, 45141, 45184, 45281, 45391, 45395, 45458, 45598, 45646, 45736, 45812, 45893, 45996, 46058, 46060, 46088, 46243, 46246, 46257, 46278, 46303, 46338, 46429, 46441, 46449, 46474, 46504, 46528, 46676, 46911, 47013, 47022, 47071, 47091, 47216, 47263, 47312, 47324, 47342, 47429, 47492, 47543, 47582, 47787, 47788, 47862, 47919, 47956, 47963, 48044, 48100, 48145, 48164, 48215, 48267, 48372, 48425, 48536, 48580, 48606, 48636, 48666, 48677, 48734, 48743, 48771, 48780, 48806, 48863, 48944, 49031, 49036, 49079, 49093, 49225, 49367, 49369, 49520, 49527, 49881, 49995, 50178, 50189, 50190, 50415, 50432, 50514, 50575, 50751, 50767, 50822, 50832, 50857, 50906, 50991, 51017, 51020, 51038, 51082, 51094, 51174, 51275, 51307, 51482, 51507, 51833, 51909, 51914, 51971, 52011, 52026, 52261, 52343, 52482, 52515, 52553, 52568, 52602, 52743, 52846, 52910, 53093, 53156, 53194, 53249, 53280, 53377, 53456, 53556, 53707, 53738, 53806, 53897, 53979, 54047, 54083, 54084, 54348, 54438, 54527, 54638, 54641, 54655, 54811, 55001, 55260, 55369, 55423, 55514, 55629, 55703, 55793, 55817, 55873, 56025, 56089, 56134, 56195, 56229, 56340, 56446, 56470, 56545, 56565, 56772, 56790, 56796, 56850, 57023, 57138, 57449, 57468, 57645, 57767, 58008, 58016, 58031, 58155, 58270, 58312, 58319, 58356, 58357, 58422, 58433, 58588, 58668, 58679, 58706, 58794, 58888, 58899, 58948, 58984, 59208, 59260, 59276, 59281, 59403, 59490, 59585, 59701, 59710, 59731, 59903, 60063, 60234, 60341, 60355, 60399, 60408, 60534, 60548, 60735, 60783, 60825, 60826, 61030, 61157, 61339, 61465, 61500, 61586, 61590, 61856, 61939, 62034, 62150, 62239, 62380, 62395, 62430, 62450, 62458, 62534, 62600, 62613, 62681, 62707, 62736, 62776, 62798, 62954, 63024, 63028, 63043, 63177, 63206, 63467, 63515, 63621, 63687, 63878, 64025, 64055, 64150, 64160, 64208, 64280, 64354, 64516, 64687, 64808, 64819, 64911, 64974, 65091, 65175, 65190, 65237, 65240, 65255, 65368, 65382, 65394, 65395, 65399, 65504, 65558, 65589, 65610, 65627, 65753, 65786, 65871, 65951, 65973, 66001, 66068, 66143, 66307, 66362, 66483, 66557, 66694, 66724, 66859, 66891, 67061, 67101, 67150, 67375, 67404, 67543, 67621, 67651, 67673, 67684, 67939, 68065, 68068, 68102, 68175, 68299, 68307, 68308, 68368, 68425, 68611, 68621, 68674, 68807, 68816, 68964, 69027, 69118, 69176, 69186, 69207, 69208, 69243, 69251, 69395, 69630, 69764, 69791, 69941, 70084, 70359, 70462, 70518, 70620, 70842, 70926, 71146, 71215, 71286, 71330, 71555, 71647, 71676, 71698, 71735, 71872, 71880, 71962, 72033, 72154, 72470, 72488, 72555, 72656, 72658, 72739, 72807, 72891, 72909, 72924, 72956, 73058, 73059, 73089, 73270, 73389, 73582, 73833, 73867, 73946, 73955, 74016, 74147, 74174, 74252, 74289, 74354, 74433, 74448, 74468, 74515, 74525, 74642, 74686, 74954, 75023, 75031, 75200, 75251, 75414, 75576, 75626, 75632, 75663, 75782, 75844, 75883, 75938, 75970, 76009, 76021, 76071, 76134, 76219, 76231, 76546, 76644, 76709, 76726, 76780, 76801, 76803, 76975, 76990, 77094, 77101, 77261, 77347, 77360, 77436, 77500, 77578, 77625, 77676, 77807, 78168, 78214, 78237, 78366, 78375, 78557, 78759, 78892, 79049, 79222, 79240, 79275, 79280, 79285, 79407, 79450, 79477, 79553, 79557, 79564, 79648, 79697, 79808, 79838, 79878, 80161, 80411, 80555, 80602, 80616, 80628, 80789, 80895, 80920, 81083, 81130, 81558, 81567, 81579, 81660, 81701, 81729, 81745, 81883, 81888, 81902, 81980, 82000, 82004, 82006, 82051, 82068, 82147, 82154, 82231, 82291, 82299, 82381, 82520, 82541, 82559, 82649, 82669, 82820, 82904, 82910, 82919, 82921, 82960, 83016, 83038, 83093, 83171, 83224, 83381, 83419, 83421, 83468, 83547, 83550, 83609, 83641, 83653, 83714, 83808, 83815, 83817, 83823, 83845, 83979, 84042, 84257, 84329, 84629, 84722, 84816, 84826, 85002, 85025, 85083, 85144, 85235, 85489, 85531, 85536, 85594, 85637, 85711, 85862, 85929, 85958, 86191, 86291, 86622, 86780, 86939, 86993, 87144, 87172, 87184, 87225, 87514, 87630, 87779, 87782, 87794, 87868, 87897, 87905, 88003, 88146, 88202, 88242, 88484, 88499, 88521, 88573, 88612, 88655, 88674, 88726, 88733, 88816, 88971, 88977, 89171, 89180, 89309, 89332, 89405, 89483, 89565, 89717, 89766, 89894, 89900, 90044, 90061, 90115, 90121, 90143, 90237, 90325, 90330, 90333, 90363, 90388, 90393, 90398, 90514, 90540, 90605, 90746, 90800, 90926, 91044, 91067, 91313, 91520, 91536, 91613, 91631, 91841, 91907, 92002, 92007, 92244, 92247, 92272, 92283, 92393, 92551, 92590, 92625, 92645, 92685, 92700, 92721, 92779, 92903, 93052, 93208, 93211, 93235, 93245, 93290, 93366, 93391, 93505, 93517, 93550, 93799, 94075, 94293, 94387, 94503, 94737, 94974, 94977, 95136, 95147, 95323, 95377, 95413, 95503, 95515, 95806, 95925, 95948, 96142, 96151, 96310, 96356, 96388, 96427, 96643, 96669, 96701, 96791, 96821, 96903, 96932, 96951, 97004, 97418, 97663, 97666, 97769, 97852, 97907, 98006, 98038, 98103, 98118, 98174, 98266, 98434, 98488, 98552, 98636, 98720, 98724, 98952, 99184, 99230, 99354, 99384, 99389, 99441, 99444, 99894, 99973]\n","test_ids =  [4, 6, 26, 42, 44, 53, 59, 73, 79, 117, 142, 145, 157, 162, 179, 199, 236, 240, 241, 294, 322, 333, 342, 384, 386, 408, 414, 425, 433, 443, 454, 461, 463, 480, 494, 511, 521, 546, 570, 571, 584, 587, 596, 618, 619, 628, 631, 651, 668, 682, 697, 702, 735, 738, 754, 768, 780, 782, 785, 792, 824, 863, 887, 890, 908, 919, 927, 929, 937, 940, 952, 954, 981, 985, 1005, 1008, 1018, 1020, 1044, 1045, 1047, 1056, 1085, 1094, 1098, 1105, 1107, 1112, 1114, 1115, 1118, 1123, 1133, 1139, 1152, 1169, 1171, 1174, 1194, 1233, 1234, 1236, 1260, 1269, 1271, 1279, 1281, 1284, 1287, 1316, 1322, 1327, 1363, 1368, 1380, 1386, 1390, 1409, 1422, 1428, 1440, 1441, 1453, 1458, 1477, 1487, 1488, 1526, 1551, 1552, 1556, 1561, 1570, 1578, 1579, 1580, 1598, 1620, 1621, 1631, 1636, 1637, 1647, 1675, 1684, 1721, 1732, 1742, 1744, 1757, 1767, 1783, 1787, 1790, 1793, 1811, 1818, 1854, 1881, 1893, 1912, 1923, 1924, 1956, 1967, 1987, 1992, 2005, 2014, 2021, 2042, 2052, 2064, 2066, 2167, 2184, 2188, 2201, 2211, 2216, 2219, 2230, 2231, 2243, 2246, 2251, 2258, 2272, 2279, 2297, 2332, 2336, 2361, 2363, 2381, 2386, 2388, 2414, 2429, 2433, 2444, 2473, 2487, 2508, 2515, 2539, 2547, 2570, 2574, 2589, 2602, 2630, 2647, 2664, 2667, 2668, 2701, 2732, 2739, 2747, 2755, 2762, 2765, 2766, 2771, 2777, 2788, 2794, 2799, 2814, 2830, 2834, 2835, 2836, 2856, 2876, 2885, 2892, 2899, 2900, 2907, 2927, 2949, 2964, 2966, 2981, 2984, 2997, 3008, 3011, 3016, 3019, 3022, 3046, 3056, 3057, 3105, 3115, 3120, 3122, 3125, 3127, 3140, 3169, 3175, 3179, 3184, 3204, 3210, 3222, 3240, 3258, 3261, 3267, 3290, 3295, 3300, 3310, 3319, 3334, 3340, 3365, 3384, 3389, 3394, 3396, 3397, 3421, 3424, 3425, 3431, 3433, 3441, 3442, 3462, 3481, 3488, 3512, 3516, 3550, 3554, 3561, 3563, 3567, 3594, 3616, 3617, 3639, 3647, 3685, 3703, 3708, 3710, 3725, 3742, 3748, 3775, 3788, 3807, 3808, 3813, 3823, 3834, 3863, 3880, 3906, 3911, 3914, 3920, 3921, 3937, 3956, 3970, 4012, 4015, 4020, 4034, 4044, 4045, 4076, 4078, 4085, 4090, 4103, 4105, 4123, 4126, 4161, 4168, 4180, 4216, 4217, 4260, 4267, 4269, 4270, 4300, 4303, 4308, 4334, 4377, 4378, 4390, 4393, 4410, 4413, 4419, 4454, 4482, 4494, 4507, 4512, 4516, 4533, 4534, 4539, 4543, 4547, 4556, 4564, 4583, 4603, 4625, 4628, 4641, 4655, 4665, 4676, 4678, 4696, 4718, 4727, 4749, 4758, 4770, 4778, 4781, 4787, 4800, 4816, 4817, 4837, 4841, 4844, 4846, 4855, 4859, 4864, 4870, 4884, 4885, 4895, 4905, 4911, 4917, 4931, 4964, 4970, 4972, 4978, 4992, 4995, 5002, 5014, 5047, 5049, 5069, 5076, 5078, 5095, 5104, 5113, 5118, 5134, 5142, 5158, 5166, 5180, 5194, 5197, 5198, 5213, 5224, 5226, 5231, 5262, 5271, 5278, 5281, 5330, 5342, 5354, 5365, 5370, 5384, 5392, 5394, 5398, 5419, 5458, 5496, 5498, 5508, 5513, 5525, 5535, 5543, 5545, 5549, 5556, 5558, 5559, 5569, 5589, 5593, 5596, 5619, 5628, 5638, 5642, 5646, 5647, 5662, 5673, 5680, 5693, 5695, 5709, 5725, 5734, 5749, 5752, 5764, 5766, 5768, 5771, 5786, 5790, 5797, 5815, 5829, 5838, 5852, 5860, 5882, 5942, 5948, 5954, 5957, 5989, 5991, 6003, 6006, 6016, 6017, 6026, 6028, 6029, 6055, 6060, 6094, 6105, 6110, 6112, 6116, 6128, 6143, 6147, 6153, 6156, 6173, 6174, 6186, 6187, 6194, 6203, 6206, 6222, 6244, 6253, 6262, 6280, 6285, 6288, 6303, 6310, 6327, 6335, 6344, 6359, 6374, 6378, 6400, 6423, 6428, 6450, 6452, 6453, 6454, 6457, 6474, 6480, 6491, 6518, 6528, 6533, 6548, 6550, 6554, 6561, 6590, 6615, 6626, 6627, 6633, 6645, 6651, 6655, 6658, 6662, 6676, 6689, 6696, 6699, 6702, 6705, 6725, 6734, 6756, 6776, 6811, 6846, 6849, 6855, 6870, 6892, 6895, 6911, 6921, 6923, 6933, 6939, 6946, 6955, 6978, 6981, 6990, 7012, 7022, 7053, 7067, 7069, 7149, 7158, 7181, 7219, 7241, 7253, 7266, 7270, 7301, 7303, 7308, 7347, 7350, 7373, 7374, 7386, 7423, 7447, 7456, 7460, 7466, 7468, 7504, 7508, 7517, 7535, 7544, 7561, 7577, 7616, 7638, 7647, 7666, 7691, 7695, 7702, 7704, 7717, 7729, 7737, 7752, 7769, 7773, 7786, 7798, 7799, 7815, 7839, 7841, 7849, 7860, 7864, 7880, 7918, 7945, 7949, 7960, 7965, 8006, 8046, 8049, 8055, 8057, 8060, 8068, 8086, 8098, 8115, 8124, 8125, 8131, 8132, 8167, 8169, 8184, 8186, 8202, 8208, 8234, 8238, 8245, 8250, 8258, 8275, 8280, 8287, 8292, 8306, 8309, 8314, 8316, 8331, 8358, 8362, 8373, 8374, 8384, 8388, 8412, 8423, 8431, 8450, 8451, 8457, 8465, 8485, 8508, 8515, 8517, 8522, 8524, 8551, 8586, 8594, 8608, 8612, 8634, 8641, 8652, 8685, 8708, 8717, 8722, 8731, 8772, 8775, 8779, 8814, 8829, 8844, 8850, 8876, 8880, 8895, 8905, 8924, 8934, 8946, 8947, 8966, 8973, 8988, 8994, 9004, 9005, 9008, 9030, 9031, 9043, 9051, 9052, 9059, 9069, 9081, 9087, 9090, 9096, 9110, 9112, 9115, 9118, 9126, 9130, 9132, 9148, 9172, 9176, 9178, 9182, 9183, 9185, 9188, 9210, 9237, 9238, 9241, 9247, 9248, 9256, 9261, 9278, 9296, 9298, 9304, 9311, 9330, 9333, 9357, 9368, 9369, 9378, 9392, 9395, 9418, 9426, 9438, 9440, 9445, 9477, 9481, 9488, 9497, 9504, 9509, 9534, 9537, 9564, 9568, 9589, 9609, 9613, 9637, 9642, 9643, 9666, 9671, 9686, 9688, 9702, 9704, 9706, 9719, 9734, 9742, 9770, 9779, 9782, 9783, 9791, 9794, 9795, 9797, 9811, 9813, 9822, 9823, 9834, 9839, 9855, 9867, 9893, 9899, 9906, 9907, 9908, 9912, 9929, 9932, 9963, 9967, 9978, 9988, 10000, 10013, 10076, 10083, 10094, 10112, 10114, 10124, 10134, 10163, 10190, 10197, 10198, 10211, 10214, 10217, 10230, 10233, 10237, 10274, 10307, 10310, 10311, 10314, 10323, 10328, 10335, 10338, 10381, 10384, 10386, 10387, 10399, 10413, 10415, 10430, 10444, 10456, 10463, 10471, 10475, 10514, 10525, 10539, 10542, 10550, 10569, 10580, 10595, 10604, 10611, 10612, 10628, 10630, 10631, 10642, 10644, 10660, 10661, 10701, 10702, 10715, 10743, 10757, 10759, 10761, 10767, 10782, 10813, 10857, 10864, 10875, 10891, 10904, 10917, 10947, 10950, 10959, 10973, 10979, 10993, 11006, 11026, 11035, 11041, 11060, 11064, 11065, 11071, 11072, 11073, 11079, 11085, 11100, 11101, 11107, 11137, 11140, 11144, 11148, 11163, 11165, 11168, 11176, 11215, 11216, 11218, 11261, 11283, 11289, 11317, 11331, 11341, 11364, 11389, 11401, 11417, 11424, 11441, 11444, 11445, 11449, 11473, 11493, 11506, 11509, 11512, 11519, 11537, 11538, 11543, 11555, 11558, 11582, 11611, 11618, 11619, 11631, 11638, 11657, 11666, 11668, 11681, 11691, 11704, 11721, 11722, 11724, 11767, 11788, 11789, 11796, 11804, 11809, 11812, 11824, 11827, 11838, 11846, 11861, 11864, 11865, 11872, 11906, 11919, 11931, 11965, 11993, 12000, 12002, 12051, 12074, 12076, 12081, 12088, 12104, 12123, 12135, 12139, 12144, 12147, 12166, 12191, 12231, 12240, 12260, 12263, 12272, 12279, 12293, 12303, 12312, 12319, 12323, 12339, 12356, 12357, 12362, 12365, 12396, 12403, 12404, 12414, 12426, 12429, 12433, 12439, 12459, 12543, 12568, 12577, 12607, 12620, 12629, 12651, 12653, 12655, 12666, 12676, 12686, 12690, 12707, 12709, 12711, 12720, 12738, 12739, 12743, 12763, 12771, 12781, 12791, 12800, 12804, 12806, 12815, 12829, 12831, 12849, 12866, 12873, 12894, 12912, 12920, 12925, 12937, 12940, 12943, 12951, 12952, 12959, 12961, 12987, 13033, 13054, 13068, 13070, 13096, 13108, 13114, 13131, 13139, 13143, 13149, 13152, 13175, 13176, 13180, 13181, 13187, 13213, 13219, 13262, 13265, 13294, 13302, 13335, 13347, 13351, 13355, 13377, 13386, 13394, 13408, 13409, 13427, 13435, 13437, 13440, 13457, 13479, 13480, 13485, 13501, 13506, 13526, 13529, 13540, 13557, 13593, 13594, 13608, 13619, 13629, 13631, 13638, 13641, 13681, 13687, 13700, 13703, 13715, 13719, 13723, 13725, 13734, 13739, 13743, 13747, 13778, 13802, 13816, 13887, 13891, 13899, 13901, 13913, 13933, 13942, 13944, 13957, 13970, 13977, 13981, 13984, 13991, 13994, 14021, 14037, 14039, 14048, 14070, 14076, 14077, 14101, 14106, 14107, 14108, 14109, 14123, 14127, 14158, 14161, 14180, 14210, 14248, 14253, 14255, 14266, 14276, 14299, 14302, 14330, 14332, 14372, 14376, 14397, 14411, 14412, 14419, 14423, 14425, 14429, 14438, 14452, 14458, 14460, 14461, 14463, 14475, 14500, 14502, 14503, 14516, 14521, 14542, 14577, 14602, 14618, 14622, 14628, 14646, 14648, 14654, 14655, 14687, 14699, 14703, 14720, 14725, 14728, 14730, 14747, 14762, 14764, 14773, 14785, 14790, 14808, 14813, 14821, 14849, 14854, 14859, 14865, 14911, 14918, 14929, 14930, 14934, 14946, 14960, 14995, 15012, 15021, 15068, 15071, 15082, 15144, 15194, 15198, 15205, 15221, 15223, 15226, 15253, 15270, 15272, 15274, 15284, 15292, 15303, 15311, 15355, 15374, 15377, 15394, 15396, 15417, 15428, 15430, 15450, 15466, 15480, 15481, 15486, 15487, 15501, 15503, 15546, 15567, 15596, 15610, 15640, 15641, 15645, 15646, 15648, 15655, 15662, 15674, 15693, 15701, 15717, 15718, 15719, 15723, 15724, 15726, 15728, 15734, 15751, 15753, 15758, 15770, 15782, 15817, 15819, 15829, 15832, 15854, 15861, 15869, 15871, 15873, 15893, 15895, 15904, 15929, 15932, 15964, 15967, 15969, 16024, 16031, 16071, 16084, 16088, 16093, 16096, 16105, 16109, 16115, 16117, 16122, 16133, 16139, 16145, 16149, 16165, 16166, 16178, 16180, 16196, 16199, 16236, 16248, 16249, 16269, 16271, 16275, 16288, 16298, 16307, 16308, 16329, 16337, 16373, 16396, 16404, 16407, 16412, 16436, 16443, 16455, 16457, 16460, 16463, 16476, 16492, 16493, 16523, 16534, 16540, 16560, 16567, 16619, 16630, 16633, 16657, 16660, 16669, 16670, 16690, 16695, 16697, 16720, 16727, 16732, 16744, 16751, 16792, 16800, 16802, 16809, 16815, 16817, 16821, 16823, 16832, 16856, 16858, 16860, 16876, 16877, 16879, 16892, 16905, 16916, 16920, 16943, 16948, 16954, 16965, 16978, 17003, 17010, 17025, 17065, 17102, 17114, 17116, 17124, 17128, 17131, 17132, 17139, 17145, 17150, 17164, 17171, 17172, 17191, 17212, 17234, 17259, 17267, 17278, 17310, 17318, 17324, 17368, 17374, 17389, 17412, 17419, 17439, 17440, 17456, 17510, 17512, 17518, 17526, 17531, 17532, 17543, 17546, 17559, 17582, 17596, 17598, 17600, 17622, 17628, 17634, 17669, 17677, 17681, 17703, 17712, 17717, 17736, 17738, 17743, 17748, 17756, 17774, 17775, 17786, 17788, 17791, 17793, 17804, 17819, 17820, 17831, 17835, 17839, 17844, 17860, 17873, 17882, 17891, 17894, 17905, 17907, 17912, 17920, 17923, 17926, 17955, 17956, 18032, 18035, 18044, 18055, 18059, 18068, 18076, 18078, 18103, 18140, 18169, 18181, 18183, 18186, 18193, 18200, 18205, 18211, 18227, 18233, 18234, 18239, 18254, 18280, 18287, 18293, 18307, 18309, 18321, 18342, 18351, 18357, 18367, 18377, 18393, 18416, 18434, 18435, 18447, 18469, 18471, 18475, 18484, 18498, 18524, 18527, 18564, 18565, 18594, 18598, 18614, 18618, 18620, 18621, 18625, 18659, 18665, 18684, 18688, 18699, 18708, 18721, 18724, 18733, 18736, 18738, 18752, 18754, 18762, 18768, 18778, 18782, 18802, 18807, 18818, 18836, 18846, 18922, 18936, 18961, 18971, 18972, 18978, 18985, 19000, 19012, 19018, 19050, 19067, 19101, 19102, 19106, 19127, 19159, 19168, 19173, 19183, 19184, 19212, 19213, 19278, 19286, 19292, 19293, 19314, 19317, 19333, 19345, 19347, 19372, 19382, 19444, 19446, 19473, 19475, 19483, 19506, 19518, 19529, 19541, 19546, 19561, 19580, 19593, 19594, 19607, 19623, 19627, 19631, 19641, 19642, 19667, 19678, 19690, 19705, 19726, 19734, 19736, 19738, 19749, 19754, 19765, 19781, 19785, 19786, 19810, 19819, 19827, 19830, 19836, 19847, 19848, 19859, 19870, 19926, 19932, 19942, 19947, 19983, 19998, 20000, 20009, 20040, 20072, 20077, 20107, 20126, 20135, 20138, 20149, 20171, 20182, 20197, 20199, 20215, 20219, 20225, 20237, 20242, 20246, 20247, 20263, 20288, 20304, 20310, 20312, 20333, 20335, 20338, 20340, 20359, 20386, 20388, 20412, 20441, 20452, 20462, 20465, 20499, 20503, 20521, 20538, 20550, 20603, 20605, 20620, 20646, 20654, 20691, 20693, 20714, 20724, 20731, 20742, 20746, 20748, 20754, 20758, 20766, 20777, 20779, 20789, 20824, 20827, 20830, 20856, 20879, 20895, 20900, 20906, 20918, 20922, 20942, 20952, 20955, 20968, 20970, 20978, 20988, 20990, 20996, 21005, 21055, 21056, 21071, 21079, 21124, 21130, 21141, 21148, 21159, 21176, 21192, 21195, 21197, 21209, 21218, 21220, 21223, 21229, 21233, 21238, 21247, 21259, 21267, 21274, 21301, 21302, 21325, 21346, 21350, 21354, 21358, 21374, 21377, 21385, 21391, 21395, 21402, 21414, 21420, 21426, 21442, 21444, 21456, 21458, 21467, 21477, 21515, 21533, 21538, 21547, 21569, 21572, 21575, 21581, 21586, 21599, 21606, 21611, 21640, 21656, 21663, 21668, 21677, 21681, 21683, 21700, 21709, 21710, 21737, 21740, 21745, 21766, 21784, 21793, 21809, 21859, 21882, 21886, 21896, 21910, 21925, 21929, 21930, 21934, 21935, 21937, 21957, 21965, 21970, 21977, 22014, 22029, 22039, 22050, 22056, 22064, 22065, 22068, 22079, 22094, 22096, 22107, 22132, 22137, 22138, 22140, 22152, 22160, 22177, 22186, 22187, 22213, 22217, 22230, 22243, 22266, 22280, 22298, 22304, 22335, 22337, 22359, 22361, 22391, 22400, 22403, 22434, 22446, 22453, 22460, 22465, 22476, 22490, 22499, 22507, 22512, 22518, 22548, 22550, 22560, 22562, 22564, 22567, 22571, 22585, 22596, 22616, 22618, 22623, 22642, 22658, 22660, 22668, 22677, 22681, 22682, 22704, 22706, 22722, 22723, 22727, 22732, 22735, 22784, 22794, 22846, 22847, 22856, 22865, 22871, 22878, 22885, 22912, 22944, 22951, 22972, 22997, 23001, 23005, 23017, 23021, 23041, 23048, 23053, 23057, 23059, 23061, 23078, 23089, 23108, 23122, 23141, 23150, 23175, 23231, 23290, 23294, 23299, 23308, 23312, 23320, 23325, 23329, 23339, 23363, 23418, 23450, 23458, 23470, 23475, 23483, 23486, 23517, 23530, 23538, 23539, 23548, 23568, 23575, 23581, 23583, 23591, 23603, 23619, 23620, 23637, 23647, 23669, 23681, 23691, 23697, 23698, 23715, 23725, 23748, 23749, 23756, 23770, 23785, 23786, 23799, 23840, 23847, 23869, 23873, 23884, 23896, 23904, 23930, 23936, 23983, 23984, 23985, 23986, 24001, 24019, 24021, 24022, 24031, 24049, 24053, 24056, 24076, 24077, 24086, 24126, 24128, 24136, 24149, 24150, 24168, 24170, 24185, 24190, 24221, 24223, 24225, 24234, 24255, 24262, 24264, 24296, 24325, 24326, 24336, 24373, 24376, 24383, 24401, 24407, 24409, 24431, 24432, 24447, 24457, 24476, 24489, 24496, 24504, 24523, 24524, 24528, 24553, 24556, 24571, 24575, 24603, 24614, 24631, 24638, 24641, 24644, 24660, 24689, 24690, 24692, 24694, 24716, 24747, 24749, 24754, 24766, 24771, 24773, 24776, 24783, 24788, 24790, 24792, 24845, 24863, 24866, 24880, 24893, 24895, 24896, 24909, 24921, 24951, 24963, 24988, 25001, 25056, 25065, 25070, 25073, 25093, 25095, 25105, 25106, 25111, 25112, 25131, 25133, 25142, 25147, 25150, 25166, 25172, 25174, 25178, 25179, 25180, 25184, 25188, 25196, 25216, 25256, 25257, 25264, 25285, 25286, 25290, 25302, 25303, 25313, 25328, 25332, 25367, 25374, 25391, 25405, 25410, 25436, 25454, 25484, 25492, 25497, 25509, 25515, 25516, 25517, 25522, 25533, 25534, 25553, 25555, 25557, 25558, 25562, 25582, 25585, 25596, 25599, 25622, 25647, 25658, 25662, 25683, 25690, 25692, 25727, 25739, 25740, 25757, 25782, 25788, 25811, 25836, 25837, 25859, 25884, 25886, 25894, 25905, 25915, 25917, 25919, 25941, 25955, 25963, 25967, 25989, 26001, 26002, 26012, 26014, 26019, 26029, 26041, 26045, 26051, 26052, 26062, 26067, 26073, 26074, 26086, 26089, 26101, 26108, 26117, 26130, 26134, 26136, 26142, 26143, 26151, 26155, 26167, 26191, 26201, 26203, 26206, 26227, 26234, 26262, 26265, 26310, 26316, 26322, 26325, 26337, 26344, 26356, 26368, 26372, 26376, 26380, 26388, 26390, 26401, 26413, 26418, 26441, 26450, 26462, 26484, 26489, 26490, 26497, 26499, 26501, 26515, 26527, 26532, 26538, 26568, 26583, 26593, 26594, 26602, 26626, 26655, 26658, 26661, 26676, 26693, 26704, 26719, 26720, 26747, 26759, 26763, 26770, 26783, 26836, 26856, 26864, 26866, 26869, 26884, 26897, 26917, 26925, 26936, 26937, 26945, 27003, 27021, 27024, 27036, 27039, 27044, 27059, 27063, 27066, 27069, 27072, 27097, 27098, 27117, 27122, 27133, 27135, 27137, 27142, 27183, 27202, 27204, 27229, 27230, 27239, 27266, 27267, 27271, 27278, 27282, 27286, 27293, 27294, 27295, 27327, 27328, 27331, 27350, 27369, 27375, 27388, 27400, 27404, 27419, 27423, 27424, 27431, 27436, 27442, 27451, 27455, 27463, 27466, 27468, 27477, 27490, 27491, 27498, 27499, 27500, 27505, 27532, 27537, 27541, 27562, 27572, 27587, 27603, 27617, 27619, 27650, 27658, 27664, 27675, 27677, 27696, 27701, 27712, 27725, 27744, 27759, 27773, 27777, 27783, 27797, 27823, 27829, 27831, 27842, 27853, 27860, 27861, 27865, 27890, 27933, 27934, 27935, 27937, 27944, 27945, 27970, 28004, 28011, 28017, 28018, 28036, 28044, 28048, 28054, 28082, 28100, 28112, 28115, 28135, 28154, 28168, 28171, 28197, 28200, 28206, 28217, 28256, 28264, 28270, 28278, 28302, 28304, 28305, 28326, 28335, 28343, 28348, 28357, 28361, 28376, 28386, 28401, 28410, 28412, 28413, 28436, 28440, 28450, 28455, 28458, 28464, 28473, 28474, 28476, 28484, 28503, 28526, 28527, 28559, 28576, 28588, 28591, 28592, 28613, 28631, 28639, 28646, 28650, 28660, 28679, 28698, 28712, 28713, 28720, 28735, 28741, 28742, 28745, 28756, 28765, 28775, 28793, 28797, 28801, 28811, 28832, 28836, 28847, 28857, 28859, 28869, 28875, 28902, 28913, 28937, 28949, 28960, 28992, 29006, 29007, 29012, 29018, 29031, 29034, 29045, 29051, 29057, 29077, 29079, 29083, 29090, 29091, 29110, 29125, 29129, 29147, 29153, 29154, 29178, 29191, 29194, 29198, 29208, 29232, 29247, 29248, 29252, 29256, 29264, 29278, 29292, 29300, 29307, 29309, 29313, 29317, 29320, 29336, 29345, 29368, 29372, 29382, 29390, 29398, 29415, 29425, 29444, 29445, 29450, 29456, 29464, 29488, 29498, 29501, 29503, 29507, 29515, 29539, 29540, 29541, 29543, 29549, 29572, 29576, 29585, 29590, 29612, 29615, 29616, 29625, 29626, 29637, 29641, 29652, 29669, 29680, 29699, 29703, 29721, 29723, 29724, 29731, 29736, 29751, 29775, 29795, 29805, 29817, 29829, 29840, 29841, 29862, 29863, 29868, 29905, 29906, 29919, 29951, 29988, 29989, 29998, 30041, 30044, 30046, 30055, 30068, 30078, 30095, 30116, 30143, 30144, 30165, 30193, 30211, 30217, 30236, 30238, 30240, 30246, 30290, 30293, 30296, 30307, 30331, 30365, 30376, 30388, 30419, 30434, 30461, 30469, 30482, 30491, 30494, 30496, 30536, 30547, 30548, 30552, 30576, 30581, 30615, 30616, 30633, 30644, 30678, 30689, 30690, 30693, 30699, 30730, 30733, 30738, 30746, 30770, 30816, 30836, 30839, 30870, 30875, 30912, 30930, 30934, 30943, 30955, 30956, 30977, 30985, 30988, 30999, 31013, 31024, 31037, 31061, 31067, 31075, 31080, 31117, 31156, 31171, 31200, 31202, 31208, 31211, 31226, 31236, 31237, 31243, 31247, 31263, 31275, 31307, 31317, 31336, 31391, 31393, 31404, 31407, 31434, 31455, 31462, 31464, 31472, 31486, 31488, 31499, 31501, 31505, 31515, 31532, 31552, 31559, 31560, 31572, 31581, 31583, 31592, 31610, 31611, 31636, 31638, 31645, 31648, 31657, 31661, 31700, 31709, 31712, 31732, 31751, 31758, 31760, 31766, 31775, 31780, 31783, 31801, 31839, 31841, 31845, 31868, 31882, 31894, 31895, 31934, 31935, 31972, 31982, 31985, 31993, 32012, 32023, 32029, 32072, 32082, 32084, 32096, 32098, 32113, 32122, 32129, 32172, 32191, 32214, 32221, 32239, 32241, 32249, 32250, 32286, 32302, 32332, 32347, 32371, 32413, 32435, 32459, 32471, 32484, 32498, 32502, 32504, 32513, 32527, 32573, 32622, 32623, 32625, 32637, 32643, 32678, 32716, 32720, 32734, 32736, 32740, 32746, 32756, 32759, 32766, 32774, 32790, 40123, 40187, 40227, 40287, 40337, 40435, 40485, 40510, 40519, 40560, 40597, 40601, 40622, 40684, 40687, 40695, 40761, 40788, 40819, 40832, 40861, 40871, 40878, 40882, 40923, 40940, 40976, 41014, 41022, 41024, 41061, 41144, 41150, 41156, 41180, 41195, 41234, 41251, 41289, 41308, 41312, 41350, 41384, 41405, 41432, 41448, 41517, 41525, 41621, 41639, 41640, 41704, 41714, 41733, 41875, 41897, 41929, 41956, 42009, 42031, 42054, 42055, 42180, 42188, 42274, 42281, 42390, 42397, 42400, 42412, 42430, 42444, 42479, 42501, 42510, 42515, 42519, 42668, 42697, 42725, 42795, 42843, 42857, 42872, 42885, 42892, 42924, 42971, 43043, 43067, 43074, 43116, 43147, 43175, 43209, 43220, 43258, 43426, 43439, 43481, 43540, 43610, 43656, 43725, 43748, 43881, 43893, 43907, 43917, 43927, 43932, 43943, 43961, 44082, 44128, 44158, 44222, 44225, 44305, 44319, 44337, 44416, 44514, 44527, 44545, 44553, 44644, 44656, 44784, 44788, 44823, 44894, 44929, 44956, 44973, 44996, 45050, 45071, 45132, 45160, 45210, 45233, 45307, 45309, 45380, 45455, 45492, 45505, 45580, 45585, 45650, 45684, 45688, 45753, 45761, 45767, 45775, 45851, 45936, 45979, 45981, 45994, 46011, 46039, 46093, 46108, 46114, 46127, 46178, 46223, 46297, 46399, 46473, 46480, 46519, 46615, 46641, 46642, 46695, 46740, 46763, 46796, 46815, 46820, 46904, 46943, 46959, 47003, 47100, 47183, 47194, 47247, 47287, 47306, 47326, 47385, 47409, 47420, 47448, 47483, 47522, 47634, 47660, 47673, 47684, 47721, 47816, 47821, 47853, 47858, 47874, 47909, 47921, 47953, 47974, 47989, 47993, 48010, 48064, 48153, 48159, 48231, 48237, 48314, 48346, 48358, 48370, 48383, 48418, 48422, 48439, 48542, 48657, 48667, 48672, 48701, 48706, 48718, 48732, 48777, 48996, 49015, 49019, 49024, 49028, 49038, 49191, 49202, 49276, 49281, 49322, 49327, 49341, 49443, 49446, 49480, 49514, 49525, 49565, 49594, 49604, 49623, 49687, 49873, 49879, 49925, 50039, 50079, 50137, 50182, 50191, 50231, 50257, 50312, 50379, 50424, 50447, 50618, 50629, 50643, 50664, 50738, 50757, 50761, 50816, 50828, 50855, 50879, 50890, 50899, 50923, 51004, 51025, 51078, 51178, 51200, 51210, 51230, 51238, 51301, 51320, 51384, 51387, 51413, 51515, 51545, 51582, 51591, 51613, 51615, 51635, 51658, 51682, 51684, 51735, 51746, 51795, 51823, 51836, 51856, 51951, 51964, 51998, 52021, 52094, 52183, 52232, 52252, 52254, 52307, 52344, 52370, 52409, 52494, 52533, 52537, 52620, 52641, 52647, 52663, 52676, 52732, 52766, 52826, 52831, 52897, 52904, 53019, 53024, 53070, 53247, 53269, 53271, 53294, 53310, 53342, 53425, 53474, 53479, 53492, 53534, 53549, 53578, 53600, 53609, 53676, 53683, 53714, 53782, 53832, 53861, 53864, 53884, 53939, 53991, 54031, 54082, 54088, 54096, 54130, 54203, 54221, 54254, 54340, 54364, 54381, 54393, 54398, 54506, 54535, 54540, 54600, 54636, 54639, 54681, 54724, 54750, 54817, 54826, 54832, 54878, 54883, 54934, 54945, 54993, 54994, 55005, 55012, 55036, 55049, 55115, 55141, 55163, 55180, 55232, 55245, 55276, 55360, 55370, 55413, 55440, 55642, 55646, 55713, 55753, 55778, 55810, 55880, 55925, 55934, 56001, 56052, 56097, 56112, 56115, 56149, 56175, 56353, 56378, 56409, 56427, 56472, 56478, 56490, 56529, 56562, 56582, 56593, 56646, 56651, 56689, 56703, 56757, 56784, 56849, 56855, 56873, 57158, 57168, 57169, 57180, 57190, 57233, 57293, 57490, 57579, 57594, 57632, 57697, 57738, 57763, 57806, 57817, 57848, 57905, 57908, 57923, 57955, 58010, 58019, 58055, 58097, 58102, 58116, 58134, 58154, 58157, 58167, 58199, 58305, 58324, 58337, 58414, 58441, 58451, 58466, 58510, 58562, 58597, 58643, 58649, 58700, 58763, 58836, 58868, 58945, 58957, 59004, 59049, 59102, 59124, 59135, 59186, 59188, 59273, 59374, 59462, 59736, 59789, 59825, 59833, 59918, 59922, 59964, 60014, 60032, 60037, 60054, 60115, 60170, 60176, 60219, 60262, 60294, 60303, 60306, 60403, 60552, 60641, 60660, 60666, 60720, 60776, 60952, 61005, 61007, 61041, 61068, 61073, 61121, 61132, 61155, 61179, 61180, 61183, 61194, 61207, 61215, 61406, 61526, 61606, 61665, 61670, 61729, 61739, 61748, 61791, 61794, 61823, 61825, 61833, 61852, 61855, 61857, 61913, 61940, 62018, 62072, 62135, 62141, 62183, 62186, 62237, 62238, 62323, 62413, 62416, 62447, 62487, 62495, 62528, 62536, 62562, 62608, 62626, 62637, 62653, 62710, 62733, 62762, 62782, 62828, 62829, 62845, 62855, 62860, 62921, 62994, 63003, 63039, 63041, 63066, 63079, 63131, 63145, 63240, 63245, 63292, 63307, 63311, 63351, 63407, 63431, 63439, 63473, 63477, 63499, 63512, 63536, 63541, 63601, 63659, 63685, 63733, 63741, 63749, 63755, 63769, 63834, 63849, 63867, 63921, 63926, 63932, 63936, 63955, 64063, 64067, 64153, 64255, 64286, 64296, 64315, 64332, 64336, 64407, 64416, 64421, 64450, 64695, 64709, 64739, 64772, 64845, 64884, 64916, 64935, 64992, 64995, 65006, 65013, 65015, 65030, 65055, 65089, 65129, 65144, 65152, 65196, 65217, 65250, 65263, 65328, 65353, 65412, 65454, 65469, 65515, 65555, 65570, 65594, 65609, 65654, 65675, 65710, 65843, 65878, 65906, 65915, 65924, 65949, 65991, 66016, 66086, 66115, 66165, 66184, 66189, 66206, 66337, 66389, 66399, 66542, 66549, 66598, 66631, 66643, 66654, 66656, 66664, 66671, 66688, 66712, 66714, 66727, 66770, 66786, 66787, 66822, 67037, 67050, 67069, 67104, 67112, 67154, 67177, 67195, 67209, 67216, 67248, 67260, 67272, 67306, 67388, 67395, 67397, 67446, 67449, 67468, 67473, 67511, 67583, 67648, 67657, 67710, 67760, 67823, 67877, 67938, 67996, 68036, 68104, 68177, 68184, 68204, 68217, 68310, 68344, 68377, 68402, 68409, 68426, 68433, 68450, 68454, 68542, 68607, 68642, 68664, 68676, 68691, 68709, 68753, 68796, 68812, 68813, 68875, 68890, 68923, 68958, 68965, 68998, 69141, 69225, 69267, 69281, 69339, 69464, 69569, 69611, 69676, 69685, 69702, 69786, 69851, 69858, 69891, 69900, 69903, 69932, 70004, 70016, 70017, 70025, 70048, 70072, 70104, 70108, 70115, 70119, 70178, 70188, 70223, 70301, 70303, 70313, 70340, 70363, 70427, 70476, 70516, 70521, 70622, 70694, 70753, 70755, 70794, 70916, 70944, 70990, 71011, 71021, 71054, 71083, 71130, 71211, 71219, 71293, 71297, 71320, 71322, 71332, 71369, 71461, 71464, 71467, 71483, 71487, 71545, 71559, 71615, 71618, 71702, 71713, 71808, 71851, 71884, 71924, 71955, 71974, 71988, 72067, 72095, 72209, 72219, 72260, 72284, 72323, 72335, 72354, 72357, 72439, 72483, 72522, 72592, 72688, 72819, 72854, 72867, 72886, 72931, 72940, 72960, 72993, 73008, 73037, 73039, 73124, 73143, 73150, 73156, 73242, 73292, 73295, 73303, 73322, 73339, 73417, 73425, 73488, 73504, 73536, 73539, 73553, 73594, 73608, 73645, 73652, 73758, 73837, 73843, 73902, 73917, 73971, 74098, 74129, 74159, 74164, 74188, 74258, 74286, 74410, 74422, 74443, 74463, 74509, 74529, 74586, 74599, 74683, 74793, 74852, 74869, 74883, 74913, 74924, 74967, 75071, 75099, 75134, 75193, 75194, 75201, 75244, 75248, 75369, 75432, 75488, 75503, 75586, 75631, 75677, 75685, 75752, 75762, 75808, 75869, 75886, 75894, 75972, 75993, 76096, 76116, 76154, 76173, 76178, 76257, 76315, 76327, 76386, 76397, 76630, 76683, 76698, 76736, 76739, 76751, 76782, 76867, 76915, 76957, 77031, 77046, 77131, 77132, 77148, 77203, 77217, 77259, 77282, 77370, 77439, 77469, 77478, 77484, 77524, 77526, 77543, 77565, 77589, 77617, 77654, 77703, 77711, 77716, 77734, 77738, 77852, 77924, 77926, 77980, 77992, 78012, 78038, 78102, 78127, 78182, 78290, 78309, 78342, 78357, 78415, 78473, 78515, 78672, 78778, 78801, 78824, 78839, 78855, 78910, 78956, 79017, 79069, 79072, 79084, 79090, 79115, 79117, 79118, 79172, 79262, 79272, 79344, 79352, 79365, 79372, 79594, 79709, 79876, 79900, 79976, 80024, 80041, 80046, 80059, 80119, 80121, 80134, 80142, 80154, 80259, 80439, 80482, 80536, 80551, 80594, 80596, 80759, 80779, 80803, 80813, 80860, 80878, 80883, 80905, 80963, 81020, 81041, 81085, 81111, 81157, 81179, 81187, 81268, 81317, 81354, 81371, 81378, 81456, 81461, 81532, 81543, 81546, 81560, 81597, 81671, 81700, 81770, 81773, 81817, 81846, 81866, 81938, 81975, 82015, 82048, 82118, 82139, 82160, 82202, 82207, 82229, 82257, 82329, 82380, 82408, 82451, 82454, 82465, 82529, 82534, 82544, 82554, 82562, 82564, 82625, 82633, 82656, 82702, 82765, 82784, 82794, 82851, 82986, 83022, 83034, 83222, 83288, 83321, 83326, 83332, 83358, 83365, 83395, 83406, 83430, 83537, 83603, 83682, 83691, 83789, 83857, 83894, 83963, 83968, 84082, 84089, 84116, 84130, 84153, 84165, 84232, 84297, 84433, 84437, 84445, 84474, 84501, 84606, 84687, 84708, 84749, 84849, 84941, 84966, 85050, 85169, 85175, 85255, 85278, 85281, 85350, 85444, 85464, 85572, 85644, 85699, 85714, 85749, 85753, 85776, 85802, 85901, 85987, 85994, 86018, 86068, 86102, 86108, 86122, 86143, 86146, 86148, 86165, 86254, 86259, 86276, 86318, 86340, 86377, 86383, 86392, 86402, 86410, 86487, 86498, 86531, 86544, 86556, 86596, 86628, 86666, 86711, 86764, 86765, 86866, 86879, 86913, 86965, 86969, 86984, 86997, 87043, 87049, 87055, 87081, 87111, 87257, 87308, 87331, 87350, 87352, 87365, 87425, 87459, 87468, 87470, 87481, 87526, 87530, 87547, 87601, 87640, 87657, 87803, 87867, 87869, 87896, 87959, 88025, 88078, 88106, 88157, 88265, 88266, 88277, 88294, 88308, 88309, 88526, 88532, 88591, 88595, 88702, 88731, 88801, 88804, 88805, 88826, 88857, 88866, 88907, 88978, 88985, 89026, 89045, 89064, 89091, 89187, 89297, 89328, 89374, 89394, 89459, 89503, 89553, 89575, 89633, 89711, 89734, 89752, 89765, 89816, 89840, 89867, 89971, 89973, 90040, 90046, 90096, 90135, 90213, 90242, 90296, 90303, 90365, 90373, 90479, 90484, 90585, 90618, 90688, 90756, 90788, 90794, 90854, 90891, 90899, 90959, 90972, 90992, 91062, 91092, 91151, 91152, 91258, 91336, 91361, 91438, 91453, 91462, 91470, 91549, 91554, 91580, 91581, 91665, 91673, 91720, 91752, 91819, 91867, 91881, 91904, 91975, 91983, 92064, 92092, 92135, 92145, 92200, 92281, 92292, 92387, 92415, 92420, 92425, 92446, 92473, 92475, 92640, 92644, 92651, 92652, 92752, 92764, 92772, 92839, 92841, 92864, 92984, 93018, 93021, 93026, 93031, 93077, 93093, 93134, 93196, 93227, 93229, 93272, 93318, 93437, 93458, 93518, 93521, 93610, 93631, 93632, 93633, 93653, 93671, 93679, 93704, 93810, 93831, 94049, 94050, 94064, 94079, 94135, 94147, 94221, 94229, 94312, 94327, 94407, 94491, 94537, 94677, 94759, 94782, 94889, 94903, 94932, 94950, 94993, 95013, 95071, 95088, 95107, 95200, 95210, 95238, 95273, 95312, 95390, 95495, 95523, 95530, 95634, 95726, 95750, 95771, 95772, 95924, 95933, 95952, 96057, 96108, 96111, 96174, 96199, 96225, 96238, 96244, 96252, 96305, 96369, 96429, 96491, 96591, 96686, 96793, 96838, 96924, 97013, 97091, 97149, 97316, 97407, 97421, 97442, 97525, 97543, 97545, 97578, 97581, 97585, 97649, 97733, 97786, 97849, 97890, 97924, 97927, 98009, 98028, 98043, 98070, 98139, 98177, 98242, 98254, 98297, 98362, 98582, 98604, 98713, 98744, 98753, 98829, 98887, 98948, 99008, 99018, 99038, 99063, 99096, 99100, 99102, 99287, 99346, 99366, 99374, 99423, 99454, 99461, 99573, 99613, 99862, 99865, 99938]\n"]}],"source":["type_of_ner = \"new\"\n","\n","x_train_lstm = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/\"+type_of_ner+\"_x_train_los.pkl\")\n","x_dev_lstm = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/\"+type_of_ner+\"_x_dev_los.pkl\")\n","x_test_lstm = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/\"+type_of_ner+\"_x_test_los.pkl\")\n","\n","y_train = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/\"+type_of_ner+\"_y_train_los.pkl\")\n","y_dev = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/\"+type_of_ner+\"_y_dev_los.pkl\")\n","y_test = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/\"+type_of_ner+\"_y_test_los.pkl\")\n","\n","ner_word2vec = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/new_ner_word2vec_limited_dict_los.pkl\")\n","ner_fasttext = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/new_ner_fasttext_limited_dict_los.pkl\")\n","ner_concat = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/new_ner_combined_limited_dict_los.pkl\")\n","\n","new_keys = set(ner_word2vec.keys())\n","train_ids = sorted(all_train_ids.intersection(new_keys))\n","dev_ids = sorted(all_dev_ids.intersection(new_keys))\n","test_ids = sorted(all_test_ids.intersection(new_keys))\n","\n","#train_ids = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/\"+type_of_ner+\"_train_ids.pkl\")\n","#dev_ids = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/\"+type_of_ner+\"_dev_ids.pkl\")\n","#test_ids = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/\"+type_of_ner+\"_test_ids.pkl\")\n","\n","print(\"train_ids = \", train_ids)\n","print(\"dev_ids = \", dev_ids)\n","print(\"test_ids = \", test_ids)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ihm-zPxBdtUF","outputId":"73d14b6e-82b3-406d-e5ce-06ccb7265c05","executionInfo":{"status":"ok","timestamp":1651188587005,"user_tz":300,"elapsed":150352,"user":{"displayName":"Suraj Bisht","userId":"14494261012766270308"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Layer:  GRU\n","Hidden unit:  128\n","Embedding:  word2vec\n","=============================\n","Iteration number:  1\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2890 - acc: 0.9033\n","Epoch 1: val_loss improved from inf to 0.25383, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2888 - acc: 0.9035 - val_loss: 0.2538 - val_acc: 0.9099\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2394 - acc: 0.9137\n","Epoch 2: val_loss improved from 0.25383 to 0.23085, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2401 - acc: 0.9134 - val_loss: 0.2309 - val_acc: 0.9145\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2220 - acc: 0.9199\n","Epoch 3: val_loss improved from 0.23085 to 0.22995, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2224 - acc: 0.9199 - val_loss: 0.2300 - val_acc: 0.9094\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2115 - acc: 0.9225\n","Epoch 4: val_loss did not improve from 0.22995\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2115 - acc: 0.9225 - val_loss: 0.2382 - val_acc: 0.9159\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1983 - acc: 0.9268\n","Epoch 5: val_loss did not improve from 0.22995\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1981 - acc: 0.9269 - val_loss: 0.2402 - val_acc: 0.9034\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1831 - acc: 0.9331\n","Epoch 6: val_loss did not improve from 0.22995\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1830 - acc: 0.9330 - val_loss: 0.2502 - val_acc: 0.9117\n","0.8731375011014186 0.5735515285398531 0.9139834406623735 0.49184782608695654\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2178 - acc: 0.9342\n","Epoch 1: val_loss improved from inf to 0.17729, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.2173 - acc: 0.9344 - val_loss: 0.1773 - val_acc: 0.9418\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1753 - acc: 0.9419\n","Epoch 2: val_loss improved from 0.17729 to 0.17002, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1756 - acc: 0.9417 - val_loss: 0.1700 - val_acc: 0.9381\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1626 - acc: 0.9448\n","Epoch 3: val_loss did not improve from 0.17002\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1627 - acc: 0.9447 - val_loss: 0.1712 - val_acc: 0.9413\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9479\n","Epoch 4: val_loss improved from 0.17002 to 0.16612, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1500 - acc: 0.9479 - val_loss: 0.1661 - val_acc: 0.9409\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9524\n","Epoch 5: val_loss did not improve from 0.16612\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1372 - acc: 0.9525 - val_loss: 0.1720 - val_acc: 0.9409\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9570\n","Epoch 6: val_loss did not improve from 0.16612\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1228 - acc: 0.9569 - val_loss: 0.1759 - val_acc: 0.9409\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9641\n","Epoch 7: val_loss did not improve from 0.16612\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1073 - acc: 0.9641 - val_loss: 0.1886 - val_acc: 0.9376\n","0.891125520857718 0.5381186326388998 0.9431922723091076 0.4948875255623723\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6856 - acc: 0.6205\n","Epoch 1: val_loss improved from inf to 0.63144, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.6854 - acc: 0.6206 - val_loss: 0.6314 - val_acc: 0.6751\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6306 - acc: 0.6605\n","Epoch 2: val_loss improved from 0.63144 to 0.62187, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6306 - acc: 0.6603 - val_loss: 0.6219 - val_acc: 0.6664\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6131 - acc: 0.6788\n","Epoch 3: val_loss improved from 0.62187 to 0.61396, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6132 - acc: 0.6786 - val_loss: 0.6140 - val_acc: 0.6784\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5964 - acc: 0.6859\n","Epoch 4: val_loss did not improve from 0.61396\n","238/238 [==============================] - 8s 35ms/step - loss: 0.5966 - acc: 0.6857 - val_loss: 0.6194 - val_acc: 0.6696\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5816 - acc: 0.7035\n","Epoch 5: val_loss did not improve from 0.61396\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5817 - acc: 0.7037 - val_loss: 0.6159 - val_acc: 0.6668\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5645 - acc: 0.7144\n","Epoch 6: val_loss did not improve from 0.61396\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5646 - acc: 0.7145 - val_loss: 0.6158 - val_acc: 0.6807\n","0.7066117664323048 0.6540706688143476 0.6589236430542779 0.5826062482409232\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4828 - acc: 0.8049\n","Epoch 1: val_loss improved from inf to 0.44357, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.4822 - acc: 0.8052 - val_loss: 0.4436 - val_acc: 0.8175\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4394 - acc: 0.8164\n","Epoch 2: val_loss improved from 0.44357 to 0.43444, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4393 - acc: 0.8165 - val_loss: 0.4344 - val_acc: 0.8179\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4235 - acc: 0.8196\n","Epoch 3: val_loss improved from 0.43444 to 0.42933, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4235 - acc: 0.8197 - val_loss: 0.4293 - val_acc: 0.8179\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4132 - acc: 0.8237\n","Epoch 4: val_loss improved from 0.42933 to 0.42355, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4132 - acc: 0.8236 - val_loss: 0.4235 - val_acc: 0.8152\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3987 - acc: 0.8308\n","Epoch 5: val_loss improved from 0.42355 to 0.42315, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3984 - acc: 0.8307 - val_loss: 0.4231 - val_acc: 0.8216\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3805 - acc: 0.8409\n","Epoch 6: val_loss did not improve from 0.42315\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3806 - acc: 0.8408 - val_loss: 0.4373 - val_acc: 0.8216\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3567 - acc: 0.8490\n","Epoch 7: val_loss did not improve from 0.42315\n","238/238 [==============================] - 8s 32ms/step - loss: 0.3568 - acc: 0.8486 - val_loss: 0.4397 - val_acc: 0.8152\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3303 - acc: 0.8623\n","Epoch 8: val_loss did not improve from 0.42315\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3304 - acc: 0.8622 - val_loss: 0.4663 - val_acc: 0.8031\n","0.725065033279398 0.38511830245102535 0.8261269549218031 0.25882352941176473\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2924 - acc: 0.9178\n","Epoch 1: val_loss improved from inf to 0.26448, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2927 - acc: 0.9176 - val_loss: 0.2645 - val_acc: 0.9233\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2567 - acc: 0.9215\n","Epoch 2: val_loss improved from 0.26448 to 0.25928, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2567 - acc: 0.9214 - val_loss: 0.2593 - val_acc: 0.9251\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2456 - acc: 0.9216\n","Epoch 3: val_loss did not improve from 0.25928\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2455 - acc: 0.9217 - val_loss: 0.2660 - val_acc: 0.9251\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2351 - acc: 0.9228\n","Epoch 4: val_loss improved from 0.25928 to 0.25841, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2354 - acc: 0.9227 - val_loss: 0.2584 - val_acc: 0.9247\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2231 - acc: 0.9238\n","Epoch 5: val_loss did not improve from 0.25841\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2234 - acc: 0.9236 - val_loss: 0.2710 - val_acc: 0.9210\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9264\n","Epoch 6: val_loss did not improve from 0.25841\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2104 - acc: 0.9265 - val_loss: 0.2706 - val_acc: 0.9201\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1921 - acc: 0.9317\n","Epoch 7: val_loss did not improve from 0.25841\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1921 - acc: 0.9317 - val_loss: 0.2939 - val_acc: 0.9224\n","0.7183833960054942 0.19511157816419017 0.9183532658693653 0.01662049861495845\n","Iteration number:  2\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2865 - acc: 0.9018\n","Epoch 1: val_loss improved from inf to 0.23898, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.2868 - acc: 0.9017 - val_loss: 0.2390 - val_acc: 0.9136\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2418 - acc: 0.9148\n","Epoch 2: val_loss improved from 0.23898 to 0.23169, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2423 - acc: 0.9146 - val_loss: 0.2317 - val_acc: 0.9145\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2242 - acc: 0.9184\n","Epoch 3: val_loss did not improve from 0.23169\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2242 - acc: 0.9185 - val_loss: 0.2421 - val_acc: 0.9127\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2146 - acc: 0.9219\n","Epoch 4: val_loss did not improve from 0.23169\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2145 - acc: 0.9220 - val_loss: 0.2330 - val_acc: 0.9127\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1989 - acc: 0.9258\n","Epoch 5: val_loss did not improve from 0.23169\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1990 - acc: 0.9258 - val_loss: 0.2383 - val_acc: 0.9108\n","0.8761212441624813 0.5731736489063046 0.9153633854645814 0.4320987654320988\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2147 - acc: 0.9359\n","Epoch 1: val_loss improved from inf to 0.18257, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.2143 - acc: 0.9361 - val_loss: 0.1826 - val_acc: 0.9418\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9426\n","Epoch 2: val_loss improved from 0.18257 to 0.17293, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1773 - acc: 0.9426 - val_loss: 0.1729 - val_acc: 0.9459\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1614 - acc: 0.9459\n","Epoch 3: val_loss did not improve from 0.17293\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1612 - acc: 0.9461 - val_loss: 0.1750 - val_acc: 0.9450\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9476\n","Epoch 4: val_loss improved from 0.17293 to 0.16529, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1500 - acc: 0.9476 - val_loss: 0.1653 - val_acc: 0.9441\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1399 - acc: 0.9525\n","Epoch 5: val_loss did not improve from 0.16529\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1404 - acc: 0.9524 - val_loss: 0.1760 - val_acc: 0.9390\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1307 - acc: 0.9546\n","Epoch 6: val_loss did not improve from 0.16529\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1306 - acc: 0.9547 - val_loss: 0.1737 - val_acc: 0.9422\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9606\n","Epoch 7: val_loss did not improve from 0.16529\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1117 - acc: 0.9608 - val_loss: 0.1902 - val_acc: 0.9390\n","0.886051157201492 0.5376776821823448 0.9457221711131555 0.4636363636363637\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6818 - acc: 0.6230\n","Epoch 1: val_loss improved from inf to 0.63743, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.6816 - acc: 0.6231 - val_loss: 0.6374 - val_acc: 0.6576\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6293 - acc: 0.6612\n","Epoch 2: val_loss improved from 0.63743 to 0.61697, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 36ms/step - loss: 0.6294 - acc: 0.6610 - val_loss: 0.6170 - val_acc: 0.6765\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6105 - acc: 0.6795\n","Epoch 3: val_loss did not improve from 0.61697\n","238/238 [==============================] - 9s 36ms/step - loss: 0.6108 - acc: 0.6794 - val_loss: 0.6174 - val_acc: 0.6728\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6000 - acc: 0.6878\n","Epoch 4: val_loss improved from 0.61697 to 0.61271, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6001 - acc: 0.6880 - val_loss: 0.6127 - val_acc: 0.6747\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5823 - acc: 0.7025\n","Epoch 5: val_loss improved from 0.61271 to 0.61146, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5826 - acc: 0.7024 - val_loss: 0.6115 - val_acc: 0.6779\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5633 - acc: 0.7180\n","Epoch 6: val_loss did not improve from 0.61146\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5637 - acc: 0.7178 - val_loss: 0.6190 - val_acc: 0.6719\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5414 - acc: 0.7313\n","Epoch 7: val_loss did not improve from 0.61146\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5410 - acc: 0.7317 - val_loss: 0.6375 - val_acc: 0.6613\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5132 - acc: 0.7534\n","Epoch 8: val_loss did not improve from 0.61146\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5131 - acc: 0.7536 - val_loss: 0.6515 - val_acc: 0.6613\n","0.7022348538799187 0.6460565576201567 0.6616835326586936 0.5361084831283507\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4813 - acc: 0.8046\n","Epoch 1: val_loss improved from inf to 0.43806, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 33ms/step - loss: 0.4817 - acc: 0.8041 - val_loss: 0.4381 - val_acc: 0.8161\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4411 - acc: 0.8168\n","Epoch 2: val_loss improved from 0.43806 to 0.42681, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4408 - acc: 0.8170 - val_loss: 0.4268 - val_acc: 0.8189\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4282 - acc: 0.8190\n","Epoch 3: val_loss did not improve from 0.42681\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4281 - acc: 0.8190 - val_loss: 0.4384 - val_acc: 0.8198\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4124 - acc: 0.8232\n","Epoch 4: val_loss did not improve from 0.42681\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4121 - acc: 0.8234 - val_loss: 0.4282 - val_acc: 0.8202\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4018 - acc: 0.8298\n","Epoch 5: val_loss did not improve from 0.42681\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4024 - acc: 0.8297 - val_loss: 0.4351 - val_acc: 0.8212\n","0.7162824678376272 0.36953135060783204 0.8252069917203312 0.17391304347826084\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2972 - acc: 0.9144\n","Epoch 1: val_loss improved from inf to 0.27276, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.2967 - acc: 0.9146 - val_loss: 0.2728 - val_acc: 0.9242\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2579 - acc: 0.9221\n","Epoch 2: val_loss improved from 0.27276 to 0.26310, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2579 - acc: 0.9220 - val_loss: 0.2631 - val_acc: 0.9242\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2452 - acc: 0.9218\n","Epoch 3: val_loss improved from 0.26310 to 0.26232, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2453 - acc: 0.9217 - val_loss: 0.2623 - val_acc: 0.9228\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2363 - acc: 0.9229\n","Epoch 4: val_loss did not improve from 0.26232\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2363 - acc: 0.9229 - val_loss: 0.2656 - val_acc: 0.9233\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2258 - acc: 0.9241\n","Epoch 5: val_loss improved from 0.26232 to 0.25647, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2256 - acc: 0.9242 - val_loss: 0.2565 - val_acc: 0.9247\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2125 - acc: 0.9273\n","Epoch 6: val_loss did not improve from 0.25647\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2130 - acc: 0.9272 - val_loss: 0.2677 - val_acc: 0.9219\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1949 - acc: 0.9334\n","Epoch 7: val_loss did not improve from 0.25647\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1946 - acc: 0.9336 - val_loss: 0.2855 - val_acc: 0.9145\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1709 - acc: 0.9419\n","Epoch 8: val_loss did not improve from 0.25647\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1710 - acc: 0.9419 - val_loss: 0.2996 - val_acc: 0.9191\n","0.7278060334151449 0.2159396685589851 0.9176632934682613 0.07253886010362695\n","Iteration number:  3\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2943 - acc: 0.8981\n","Epoch 1: val_loss improved from inf to 0.24407, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2942 - acc: 0.8982 - val_loss: 0.2441 - val_acc: 0.9136\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2423 - acc: 0.9137\n","Epoch 2: val_loss improved from 0.24407 to 0.23389, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 38ms/step - loss: 0.2418 - acc: 0.9140 - val_loss: 0.2339 - val_acc: 0.9150\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2267 - acc: 0.9172\n","Epoch 3: val_loss did not improve from 0.23389\n","238/238 [==============================] - 9s 37ms/step - loss: 0.2267 - acc: 0.9171 - val_loss: 0.2354 - val_acc: 0.9168\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9227\n","Epoch 4: val_loss did not improve from 0.23389\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2115 - acc: 0.9228 - val_loss: 0.2361 - val_acc: 0.9159\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1964 - acc: 0.9261\n","Epoch 5: val_loss did not improve from 0.23389\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1964 - acc: 0.9261 - val_loss: 0.2357 - val_acc: 0.9173\n","0.8741921094369549 0.5752251298907948 0.9135234590616376 0.3856209150326797\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2224 - acc: 0.9324\n","Epoch 1: val_loss improved from inf to 0.17926, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.2222 - acc: 0.9325 - val_loss: 0.1793 - val_acc: 0.9432\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.9437\n","Epoch 2: val_loss improved from 0.17926 to 0.17040, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1753 - acc: 0.9438 - val_loss: 0.1704 - val_acc: 0.9441\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1626 - acc: 0.9436\n","Epoch 3: val_loss did not improve from 0.17040\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1625 - acc: 0.9435 - val_loss: 0.1704 - val_acc: 0.9436\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1507 - acc: 0.9490\n","Epoch 4: val_loss improved from 0.17040 to 0.16676, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1508 - acc: 0.9487 - val_loss: 0.1668 - val_acc: 0.9432\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9514\n","Epoch 5: val_loss did not improve from 0.16676\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1380 - acc: 0.9514 - val_loss: 0.1724 - val_acc: 0.9422\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1228 - acc: 0.9570\n","Epoch 6: val_loss did not improve from 0.16676\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1228 - acc: 0.9570 - val_loss: 0.1768 - val_acc: 0.9385\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9626\n","Epoch 7: val_loss did not improve from 0.16676\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1086 - acc: 0.9627 - val_loss: 0.1895 - val_acc: 0.9404\n","0.8847222872481546 0.5308341814548515 0.9420423183072677 0.4056603773584906\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6879 - acc: 0.6216\n","Epoch 1: val_loss improved from inf to 0.62934, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.6881 - acc: 0.6213 - val_loss: 0.6293 - val_acc: 0.6617\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6327 - acc: 0.6561\n","Epoch 2: val_loss improved from 0.62934 to 0.62178, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.6327 - acc: 0.6562 - val_loss: 0.6218 - val_acc: 0.6774\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6116 - acc: 0.6774\n","Epoch 3: val_loss improved from 0.62178 to 0.62137, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.6114 - acc: 0.6778 - val_loss: 0.6214 - val_acc: 0.6724\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5976 - acc: 0.6890\n","Epoch 4: val_loss improved from 0.62137 to 0.61359, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5976 - acc: 0.6887 - val_loss: 0.6136 - val_acc: 0.6724\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5828 - acc: 0.6969\n","Epoch 5: val_loss did not improve from 0.61359\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5832 - acc: 0.6968 - val_loss: 0.6149 - val_acc: 0.6756\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5666 - acc: 0.7148\n","Epoch 6: val_loss did not improve from 0.61359\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5662 - acc: 0.7151 - val_loss: 0.6275 - val_acc: 0.6650\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5444 - acc: 0.7306\n","Epoch 7: val_loss did not improve from 0.61359\n","238/238 [==============================] - 8s 35ms/step - loss: 0.5444 - acc: 0.7306 - val_loss: 0.6322 - val_acc: 0.6576\n","0.7135234987677659 0.6562777483554807 0.6780128794848206 0.6069623806850084\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4762 - acc: 0.8069\n","Epoch 1: val_loss improved from inf to 0.43907, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.4761 - acc: 0.8070 - val_loss: 0.4391 - val_acc: 0.8165\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4381 - acc: 0.8178\n","Epoch 2: val_loss improved from 0.43907 to 0.43004, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.4381 - acc: 0.8177 - val_loss: 0.4300 - val_acc: 0.8170\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4246 - acc: 0.8196\n","Epoch 3: val_loss improved from 0.43004 to 0.42921, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4244 - acc: 0.8197 - val_loss: 0.4292 - val_acc: 0.8207\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4112 - acc: 0.8248\n","Epoch 4: val_loss improved from 0.42921 to 0.42637, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4112 - acc: 0.8248 - val_loss: 0.4264 - val_acc: 0.8165\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3995 - acc: 0.8311\n","Epoch 5: val_loss did not improve from 0.42637\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4002 - acc: 0.8307 - val_loss: 0.4288 - val_acc: 0.8221\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3848 - acc: 0.8359\n","Epoch 6: val_loss did not improve from 0.42637\n","238/238 [==============================] - 8s 36ms/step - loss: 0.3851 - acc: 0.8359 - val_loss: 0.4341 - val_acc: 0.8262\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3639 - acc: 0.8461\n","Epoch 7: val_loss did not improve from 0.42637\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3642 - acc: 0.8460 - val_loss: 0.4432 - val_acc: 0.8138\n","0.72467931616368 0.37834732727529646 0.8249770009199632 0.12226066897347175\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3001 - acc: 0.9154\n","Epoch 1: val_loss improved from inf to 0.27679, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.2999 - acc: 0.9155 - val_loss: 0.2768 - val_acc: 0.9251\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2619 - acc: 0.9213\n","Epoch 2: val_loss improved from 0.27679 to 0.26531, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2620 - acc: 0.9213 - val_loss: 0.2653 - val_acc: 0.9251\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2472 - acc: 0.9225\n","Epoch 3: val_loss improved from 0.26531 to 0.26027, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.2475 - acc: 0.9223 - val_loss: 0.2603 - val_acc: 0.9251\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2372 - acc: 0.9232\n","Epoch 4: val_loss improved from 0.26027 to 0.25810, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2370 - acc: 0.9233 - val_loss: 0.2581 - val_acc: 0.9256\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2263 - acc: 0.9243\n","Epoch 5: val_loss improved from 0.25810 to 0.25546, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2264 - acc: 0.9243 - val_loss: 0.2555 - val_acc: 0.9270\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2141 - acc: 0.9267\n","Epoch 6: val_loss did not improve from 0.25546\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2149 - acc: 0.9262 - val_loss: 0.2693 - val_acc: 0.9168\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1974 - acc: 0.9314\n","Epoch 7: val_loss did not improve from 0.25546\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1972 - acc: 0.9314 - val_loss: 0.2778 - val_acc: 0.9154\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1773 - acc: 0.9390\n","Epoch 8: val_loss did not improve from 0.25546\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1774 - acc: 0.9390 - val_loss: 0.2884 - val_acc: 0.9159\n","0.7140263673414244 0.20969765112930322 0.9178932842686293 0.048\n","Iteration number:  4\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2899 - acc: 0.9020\n","Epoch 1: val_loss improved from inf to 0.23752, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.2900 - acc: 0.9018 - val_loss: 0.2375 - val_acc: 0.9154\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2426 - acc: 0.9142\n","Epoch 2: val_loss improved from 0.23752 to 0.23343, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2427 - acc: 0.9141 - val_loss: 0.2334 - val_acc: 0.9164\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2257 - acc: 0.9182\n","Epoch 3: val_loss improved from 0.23343 to 0.23049, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2252 - acc: 0.9185 - val_loss: 0.2305 - val_acc: 0.9140\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2101 - acc: 0.9222\n","Epoch 4: val_loss did not improve from 0.23049\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2099 - acc: 0.9222 - val_loss: 0.2398 - val_acc: 0.9117\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1972 - acc: 0.9262\n","Epoch 5: val_loss improved from 0.23049 to 0.22987, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1971 - acc: 0.9263 - val_loss: 0.2299 - val_acc: 0.9168\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1801 - acc: 0.9330\n","Epoch 6: val_loss did not improve from 0.22987\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1800 - acc: 0.9330 - val_loss: 0.2391 - val_acc: 0.9117\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1606 - acc: 0.9419\n","Epoch 7: val_loss did not improve from 0.22987\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1605 - acc: 0.9420 - val_loss: 0.2518 - val_acc: 0.9039\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9505\n","Epoch 8: val_loss did not improve from 0.22987\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1381 - acc: 0.9505 - val_loss: 0.2840 - val_acc: 0.9030\n","0.87609040444092 0.5777015258026581 0.9139834406623735 0.48626373626373626\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2191 - acc: 0.9330\n","Epoch 1: val_loss improved from inf to 0.17506, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.2191 - acc: 0.9329 - val_loss: 0.1751 - val_acc: 0.9422\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1751 - acc: 0.9425\n","Epoch 2: val_loss improved from 0.17506 to 0.16930, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1753 - acc: 0.9424 - val_loss: 0.1693 - val_acc: 0.9390\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9459\n","Epoch 3: val_loss improved from 0.16930 to 0.16703, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1607 - acc: 0.9459 - val_loss: 0.1670 - val_acc: 0.9432\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9479\n","Epoch 4: val_loss improved from 0.16703 to 0.16474, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1513 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9455\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1378 - acc: 0.9527\n","Epoch 5: val_loss did not improve from 0.16474\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1383 - acc: 0.9525 - val_loss: 0.1733 - val_acc: 0.9409\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9583\n","Epoch 6: val_loss did not improve from 0.16474\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1253 - acc: 0.9583 - val_loss: 0.1805 - val_acc: 0.9385\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9622\n","Epoch 7: val_loss did not improve from 0.16474\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1097 - acc: 0.9622 - val_loss: 0.1972 - val_acc: 0.9344\n","0.8820520623624701 0.5145039504586183 0.9392824287028518 0.3465346534653465\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6870 - acc: 0.6220\n","Epoch 1: val_loss improved from inf to 0.63997, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.6870 - acc: 0.6217 - val_loss: 0.6400 - val_acc: 0.6516\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6328 - acc: 0.6600\n","Epoch 2: val_loss improved from 0.63997 to 0.62227, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.6329 - acc: 0.6598 - val_loss: 0.6223 - val_acc: 0.6664\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6139 - acc: 0.6783\n","Epoch 3: val_loss improved from 0.62227 to 0.61683, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.6137 - acc: 0.6786 - val_loss: 0.6168 - val_acc: 0.6627\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5990 - acc: 0.6886\n","Epoch 4: val_loss improved from 0.61683 to 0.61394, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5989 - acc: 0.6885 - val_loss: 0.6139 - val_acc: 0.6659\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5807 - acc: 0.7032\n","Epoch 5: val_loss did not improve from 0.61394\n","238/238 [==============================] - 8s 32ms/step - loss: 0.5811 - acc: 0.7030 - val_loss: 0.6280 - val_acc: 0.6701\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5667 - acc: 0.7104\n","Epoch 6: val_loss did not improve from 0.61394\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5664 - acc: 0.7108 - val_loss: 0.6240 - val_acc: 0.6668\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5418 - acc: 0.7338\n","Epoch 7: val_loss did not improve from 0.61394\n","238/238 [==============================] - 8s 32ms/step - loss: 0.5417 - acc: 0.7339 - val_loss: 0.6296 - val_acc: 0.6608\n","0.7024366295054232 0.6435391968584145 0.6593836246550138 0.5545864661654134\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4820 - acc: 0.8071\n","Epoch 1: val_loss improved from inf to 0.43733, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 11s 35ms/step - loss: 0.4814 - acc: 0.8074 - val_loss: 0.4373 - val_acc: 0.8184\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4402 - acc: 0.8184\n","Epoch 2: val_loss improved from 0.43733 to 0.43631, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4403 - acc: 0.8185 - val_loss: 0.4363 - val_acc: 0.8170\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4249 - acc: 0.8203\n","Epoch 3: val_loss improved from 0.43631 to 0.42915, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.4249 - acc: 0.8204 - val_loss: 0.4291 - val_acc: 0.8175\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4129 - acc: 0.8269\n","Epoch 4: val_loss improved from 0.42915 to 0.42209, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4129 - acc: 0.8269 - val_loss: 0.4221 - val_acc: 0.8249\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3982 - acc: 0.8331\n","Epoch 5: val_loss did not improve from 0.42209\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3982 - acc: 0.8331 - val_loss: 0.4249 - val_acc: 0.8226\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3826 - acc: 0.8392\n","Epoch 6: val_loss did not improve from 0.42209\n","238/238 [==============================] - 8s 33ms/step - loss: 0.3824 - acc: 0.8392 - val_loss: 0.4303 - val_acc: 0.8202\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3616 - acc: 0.8482\n","Epoch 7: val_loss did not improve from 0.42209\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3613 - acc: 0.8482 - val_loss: 0.4531 - val_acc: 0.8170\n","0.7246039440749946 0.3926621049859089 0.8265869365225391 0.24750499001996007\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2935 - acc: 0.9160\n","Epoch 1: val_loss improved from inf to 0.26343, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.2931 - acc: 0.9161 - val_loss: 0.2634 - val_acc: 0.9242\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2582 - acc: 0.9213\n","Epoch 2: val_loss improved from 0.26343 to 0.25684, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2585 - acc: 0.9212 - val_loss: 0.2568 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2471 - acc: 0.9218\n","Epoch 3: val_loss did not improve from 0.25684\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2469 - acc: 0.9219 - val_loss: 0.2622 - val_acc: 0.9233\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2352 - acc: 0.9225\n","Epoch 4: val_loss did not improve from 0.25684\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2351 - acc: 0.9225 - val_loss: 0.2600 - val_acc: 0.9247\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2238 - acc: 0.9233\n","Epoch 5: val_loss did not improve from 0.25684\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2244 - acc: 0.9231 - val_loss: 0.2640 - val_acc: 0.9233\n","0.7243862725450902 0.2115325203618381 0.9178932842686293 0.016528925619834708\n","Iteration number:  5\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2918 - acc: 0.9012\n","Epoch 1: val_loss improved from inf to 0.24019, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.2918 - acc: 0.9012 - val_loss: 0.2402 - val_acc: 0.9173\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2427 - acc: 0.9139\n","Epoch 2: val_loss improved from 0.24019 to 0.23314, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2423 - acc: 0.9141 - val_loss: 0.2331 - val_acc: 0.9177\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2248 - acc: 0.9179\n","Epoch 3: val_loss improved from 0.23314 to 0.23200, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2244 - acc: 0.9181 - val_loss: 0.2320 - val_acc: 0.9159\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2115 - acc: 0.9235\n","Epoch 4: val_loss did not improve from 0.23200\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2118 - acc: 0.9232 - val_loss: 0.2403 - val_acc: 0.9108\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1975 - acc: 0.9254\n","Epoch 5: val_loss did not improve from 0.23200\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1972 - acc: 0.9256 - val_loss: 0.2431 - val_acc: 0.9094\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1833 - acc: 0.9333\n","Epoch 6: val_loss did not improve from 0.23200\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1831 - acc: 0.9335 - val_loss: 0.2381 - val_acc: 0.9168\n","0.879386950392105 0.589820177893412 0.9169733210671573 0.4760522496371552\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2298 - acc: 0.9293\n","Epoch 1: val_loss improved from inf to 0.18832, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2297 - acc: 0.9294 - val_loss: 0.1883 - val_acc: 0.9376\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1786 - acc: 0.9425\n","Epoch 2: val_loss improved from 0.18832 to 0.17313, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1787 - acc: 0.9425 - val_loss: 0.1731 - val_acc: 0.9418\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1615 - acc: 0.9449\n","Epoch 3: val_loss improved from 0.17313 to 0.16972, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 38ms/step - loss: 0.1616 - acc: 0.9449 - val_loss: 0.1697 - val_acc: 0.9376\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1512 - acc: 0.9487\n","Epoch 4: val_loss did not improve from 0.16972\n","238/238 [==============================] - 10s 40ms/step - loss: 0.1510 - acc: 0.9488 - val_loss: 0.1709 - val_acc: 0.9390\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9496\n","Epoch 5: val_loss did not improve from 0.16972\n","238/238 [==============================] - 10s 40ms/step - loss: 0.1391 - acc: 0.9497 - val_loss: 0.1739 - val_acc: 0.9422\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9574\n","Epoch 6: val_loss did not improve from 0.16972\n","238/238 [==============================] - 10s 42ms/step - loss: 0.1244 - acc: 0.9575 - val_loss: 0.1790 - val_acc: 0.9404\n","0.8868950637514241 0.5287759402770483 0.9429622815087396 0.47679324894514763\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6830 - acc: 0.6203\n","Epoch 1: val_loss improved from inf to 0.63163, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 12s 39ms/step - loss: 0.6828 - acc: 0.6205 - val_loss: 0.6316 - val_acc: 0.6728\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6311 - acc: 0.6644\n","Epoch 2: val_loss improved from 0.63163 to 0.62385, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 38ms/step - loss: 0.6307 - acc: 0.6650 - val_loss: 0.6239 - val_acc: 0.6705\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6133 - acc: 0.6795\n","Epoch 3: val_loss improved from 0.62385 to 0.61810, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.6131 - acc: 0.6797 - val_loss: 0.6181 - val_acc: 0.6774\n","Epoch 4/100\n","238/238 [==============================] - ETA: 0s - loss: 0.5977 - acc: 0.6899\n","Epoch 4: val_loss did not improve from 0.61810\n","238/238 [==============================] - 10s 41ms/step - loss: 0.5977 - acc: 0.6899 - val_loss: 0.6194 - val_acc: 0.6738\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5837 - acc: 0.7019\n","Epoch 5: val_loss did not improve from 0.61810\n","238/238 [==============================] - 9s 38ms/step - loss: 0.5835 - acc: 0.7022 - val_loss: 0.6202 - val_acc: 0.6682\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5643 - acc: 0.7148\n","Epoch 6: val_loss did not improve from 0.61810\n","238/238 [==============================] - 9s 40ms/step - loss: 0.5644 - acc: 0.7149 - val_loss: 0.6248 - val_acc: 0.6677\n","0.7055353420258705 0.6450760576355372 0.6593836246550138 0.5873502368347729\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4855 - acc: 0.8079\n","Epoch 1: val_loss improved from inf to 0.44169, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 12s 42ms/step - loss: 0.4855 - acc: 0.8077 - val_loss: 0.4417 - val_acc: 0.8142\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4376 - acc: 0.8151\n","Epoch 2: val_loss improved from 0.44169 to 0.43354, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 38ms/step - loss: 0.4371 - acc: 0.8153 - val_loss: 0.4335 - val_acc: 0.8193\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4232 - acc: 0.8219\n","Epoch 3: val_loss did not improve from 0.43354\n","238/238 [==============================] - 9s 38ms/step - loss: 0.4232 - acc: 0.8219 - val_loss: 0.4343 - val_acc: 0.8184\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4101 - acc: 0.8265\n","Epoch 4: val_loss improved from 0.43354 to 0.43109, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.4101 - acc: 0.8265 - val_loss: 0.4311 - val_acc: 0.8216\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3998 - acc: 0.8300\n","Epoch 5: val_loss did not improve from 0.43109\n","238/238 [==============================] - 9s 36ms/step - loss: 0.3996 - acc: 0.8302 - val_loss: 0.4348 - val_acc: 0.8156\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3851 - acc: 0.8367\n","Epoch 6: val_loss did not improve from 0.43109\n","238/238 [==============================] - 9s 36ms/step - loss: 0.3851 - acc: 0.8367 - val_loss: 0.4452 - val_acc: 0.8133\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3603 - acc: 0.8506\n","Epoch 7: val_loss did not improve from 0.43109\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3599 - acc: 0.8510 - val_loss: 0.4562 - val_acc: 0.8059\n","0.7187630590729197 0.3818008245249039 0.8252069917203312 0.2534381139489194\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2912 - acc: 0.9167\n","Epoch 1: val_loss improved from inf to 0.26547, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.2911 - acc: 0.9167 - val_loss: 0.2655 - val_acc: 0.9238\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2576 - acc: 0.9217\n","Epoch 2: val_loss did not improve from 0.26547\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2581 - acc: 0.9215 - val_loss: 0.2743 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2439 - acc: 0.9225\n","Epoch 3: val_loss improved from 0.26547 to 0.25453, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2436 - acc: 0.9226 - val_loss: 0.2545 - val_acc: 0.9238\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2324 - acc: 0.9225\n","Epoch 4: val_loss did not improve from 0.25453\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2328 - acc: 0.9223 - val_loss: 0.2596 - val_acc: 0.9219\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2232 - acc: 0.9241\n","Epoch 5: val_loss did not improve from 0.25453\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2233 - acc: 0.9239 - val_loss: 0.2661 - val_acc: 0.9214\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9278\n","Epoch 6: val_loss did not improve from 0.25453\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2107 - acc: 0.9279 - val_loss: 0.2749 - val_acc: 0.9182\n","0.7347553252572561 0.2150575310400255 0.9174333026678932 0.03234501347708895\n","Iteration number:  6\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2897 - acc: 0.9023\n","Epoch 1: val_loss improved from inf to 0.24620, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.2892 - acc: 0.9024 - val_loss: 0.2462 - val_acc: 0.9117\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2447 - acc: 0.9152\n","Epoch 2: val_loss improved from 0.24620 to 0.23367, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2446 - acc: 0.9150 - val_loss: 0.2337 - val_acc: 0.9136\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2277 - acc: 0.9159\n","Epoch 3: val_loss did not improve from 0.23367\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2276 - acc: 0.9158 - val_loss: 0.2357 - val_acc: 0.9173\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2098 - acc: 0.9210\n","Epoch 4: val_loss did not improve from 0.23367\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2099 - acc: 0.9210 - val_loss: 0.2368 - val_acc: 0.9113\n","Epoch 5/100\n","238/238 [==============================] - ETA: 0s - loss: 0.1978 - acc: 0.9287\n","Epoch 5: val_loss did not improve from 0.23367\n","238/238 [==============================] - 9s 39ms/step - loss: 0.1978 - acc: 0.9287 - val_loss: 0.2390 - val_acc: 0.9094\n","0.8765304211824831 0.5763543163774467 0.9142134314627415 0.5046480743691899\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2346 - acc: 0.9279\n","Epoch 1: val_loss improved from inf to 0.18091, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 12s 41ms/step - loss: 0.2342 - acc: 0.9280 - val_loss: 0.1809 - val_acc: 0.9422\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1798 - acc: 0.9396\n","Epoch 2: val_loss improved from 0.18091 to 0.17151, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 41ms/step - loss: 0.1802 - acc: 0.9395 - val_loss: 0.1715 - val_acc: 0.9441\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1631 - acc: 0.9458\n","Epoch 3: val_loss improved from 0.17151 to 0.16785, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 42ms/step - loss: 0.1631 - acc: 0.9458 - val_loss: 0.1678 - val_acc: 0.9422\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1494 - acc: 0.9498\n","Epoch 4: val_loss did not improve from 0.16785\n","238/238 [==============================] - 10s 42ms/step - loss: 0.1503 - acc: 0.9495 - val_loss: 0.1775 - val_acc: 0.9409\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9515\n","Epoch 5: val_loss did not improve from 0.16785\n","238/238 [==============================] - 10s 42ms/step - loss: 0.1382 - acc: 0.9515 - val_loss: 0.1792 - val_acc: 0.9404\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9573\n","Epoch 6: val_loss did not improve from 0.16785\n","238/238 [==============================] - 10s 41ms/step - loss: 0.1241 - acc: 0.9572 - val_loss: 0.1788 - val_acc: 0.9445\n","0.8846481576852848 0.5027478014356188 0.93721251149954 0.2982005141388175\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6837 - acc: 0.6249\n","Epoch 1: val_loss improved from inf to 0.63493, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 13s 42ms/step - loss: 0.6837 - acc: 0.6247 - val_loss: 0.6349 - val_acc: 0.6562\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6310 - acc: 0.6585\n","Epoch 2: val_loss improved from 0.63493 to 0.61751, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 43ms/step - loss: 0.6309 - acc: 0.6588 - val_loss: 0.6175 - val_acc: 0.6724\n","Epoch 3/100\n","238/238 [==============================] - ETA: 0s - loss: 0.6112 - acc: 0.6777\n","Epoch 3: val_loss improved from 0.61751 to 0.61291, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 42ms/step - loss: 0.6112 - acc: 0.6777 - val_loss: 0.6129 - val_acc: 0.6733\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5951 - acc: 0.6937\n","Epoch 4: val_loss did not improve from 0.61291\n","238/238 [==============================] - 10s 41ms/step - loss: 0.5951 - acc: 0.6939 - val_loss: 0.6345 - val_acc: 0.6654\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5807 - acc: 0.7021\n","Epoch 5: val_loss did not improve from 0.61291\n","238/238 [==============================] - 10s 41ms/step - loss: 0.5803 - acc: 0.7026 - val_loss: 0.6142 - val_acc: 0.6668\n","Epoch 6/100\n","238/238 [==============================] - ETA: 0s - loss: 0.5624 - acc: 0.7205\n","Epoch 6: val_loss did not improve from 0.61291\n","238/238 [==============================] - 10s 43ms/step - loss: 0.5624 - acc: 0.7205 - val_loss: 0.6230 - val_acc: 0.6617\n","0.7041162227602905 0.6446781682996825 0.6658233670653174 0.5497365974589402\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4830 - acc: 0.8093\n","Epoch 1: val_loss improved from inf to 0.44501, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 13s 44ms/step - loss: 0.4827 - acc: 0.8093 - val_loss: 0.4450 - val_acc: 0.8170\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4380 - acc: 0.8161\n","Epoch 2: val_loss improved from 0.44501 to 0.43571, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 41ms/step - loss: 0.4379 - acc: 0.8163 - val_loss: 0.4357 - val_acc: 0.8124\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4237 - acc: 0.8203\n","Epoch 3: val_loss improved from 0.43571 to 0.43162, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 40ms/step - loss: 0.4238 - acc: 0.8203 - val_loss: 0.4316 - val_acc: 0.8207\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4097 - acc: 0.8256\n","Epoch 4: val_loss did not improve from 0.43162\n","238/238 [==============================] - 10s 41ms/step - loss: 0.4105 - acc: 0.8253 - val_loss: 0.4318 - val_acc: 0.8193\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3979 - acc: 0.8294\n","Epoch 5: val_loss did not improve from 0.43162\n","238/238 [==============================] - 10s 42ms/step - loss: 0.3985 - acc: 0.8288 - val_loss: 0.4505 - val_acc: 0.8059\n","Epoch 6/100\n","238/238 [==============================] - ETA: 0s - loss: 0.3821 - acc: 0.8336\n","Epoch 6: val_loss improved from 0.43162 to 0.42743, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 42ms/step - loss: 0.3821 - acc: 0.8336 - val_loss: 0.4274 - val_acc: 0.8202\n","Epoch 7/100\n","238/238 [==============================] - ETA: 0s - loss: 0.3589 - acc: 0.8506\n","Epoch 7: val_loss did not improve from 0.42743\n","238/238 [==============================] - 10s 42ms/step - loss: 0.3589 - acc: 0.8506 - val_loss: 0.4466 - val_acc: 0.8152\n","Epoch 8/100\n","238/238 [==============================] - ETA: 0s - loss: 0.3278 - acc: 0.8652\n","Epoch 8: val_loss did not improve from 0.42743\n","238/238 [==============================] - 10s 44ms/step - loss: 0.3278 - acc: 0.8652 - val_loss: 0.4877 - val_acc: 0.8175\n","Epoch 9/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2895 - acc: 0.8838\n","Epoch 9: val_loss did not improve from 0.42743\n","238/238 [==============================] - 10s 42ms/step - loss: 0.2895 - acc: 0.8836 - val_loss: 0.4974 - val_acc: 0.7994\n","0.7164252590847768 0.37018873554393966 0.8192272309107635 0.24856596558317395\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2901 - acc: 0.9191\n","Epoch 1: val_loss improved from inf to 0.26214, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 13s 43ms/step - loss: 0.2901 - acc: 0.9191 - val_loss: 0.2621 - val_acc: 0.9233\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2560 - acc: 0.9218\n","Epoch 2: val_loss improved from 0.26214 to 0.25941, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 10s 41ms/step - loss: 0.2555 - acc: 0.9219 - val_loss: 0.2594 - val_acc: 0.9247\n","Epoch 3/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2438 - acc: 0.9223\n","Epoch 3: val_loss did not improve from 0.25941\n","238/238 [==============================] - 10s 41ms/step - loss: 0.2438 - acc: 0.9223 - val_loss: 0.2597 - val_acc: 0.9247\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2360 - acc: 0.9231\n","Epoch 4: val_loss improved from 0.25941 to 0.25446, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 40ms/step - loss: 0.2363 - acc: 0.9229 - val_loss: 0.2545 - val_acc: 0.9247\n","Epoch 5/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2270 - acc: 0.9231\n","Epoch 5: val_loss did not improve from 0.25446\n","238/238 [==============================] - 9s 40ms/step - loss: 0.2270 - acc: 0.9231 - val_loss: 0.2586 - val_acc: 0.9251\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2156 - acc: 0.9274\n","Epoch 6: val_loss did not improve from 0.25446\n","238/238 [==============================] - 10s 40ms/step - loss: 0.2154 - acc: 0.9274 - val_loss: 0.2712 - val_acc: 0.9233\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9313\n","Epoch 7: val_loss did not improve from 0.25446\n","238/238 [==============================] - 10s 42ms/step - loss: 0.2006 - acc: 0.9313 - val_loss: 0.2696 - val_acc: 0.9233\n","0.7359445013622752 0.2180648250115893 0.9183532658693653 0.01662049861495845\n","Iteration number:  7\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3143 - acc: 0.8968\n","Epoch 1: val_loss improved from inf to 0.24698, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 13s 43ms/step - loss: 0.3140 - acc: 0.8968 - val_loss: 0.2470 - val_acc: 0.9136\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2488 - acc: 0.9119\n","Epoch 2: val_loss improved from 0.24698 to 0.23450, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 40ms/step - loss: 0.2487 - acc: 0.9119 - val_loss: 0.2345 - val_acc: 0.9140\n","Epoch 3/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2262 - acc: 0.9196\n","Epoch 3: val_loss improved from 0.23450 to 0.23240, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 41ms/step - loss: 0.2262 - acc: 0.9196 - val_loss: 0.2324 - val_acc: 0.9159\n","Epoch 4/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2129 - acc: 0.9216\n","Epoch 4: val_loss did not improve from 0.23240\n","238/238 [==============================] - 10s 40ms/step - loss: 0.2129 - acc: 0.9216 - val_loss: 0.2339 - val_acc: 0.9136\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9291\n","Epoch 5: val_loss did not improve from 0.23240\n","238/238 [==============================] - 10s 40ms/step - loss: 0.1960 - acc: 0.9290 - val_loss: 0.2328 - val_acc: 0.9177\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9353\n","Epoch 6: val_loss did not improve from 0.23240\n","238/238 [==============================] - 9s 39ms/step - loss: 0.1812 - acc: 0.9351 - val_loss: 0.2628 - val_acc: 0.9034\n","0.8795516124768703 0.5784322115870948 0.9165133394664213 0.4474885844748858\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2308 - acc: 0.9314\n","Epoch 1: val_loss improved from inf to 0.18026, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 12s 41ms/step - loss: 0.2308 - acc: 0.9314 - val_loss: 0.1803 - val_acc: 0.9436\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1806 - acc: 0.9407\n","Epoch 2: val_loss improved from 0.18026 to 0.17325, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 42ms/step - loss: 0.1808 - acc: 0.9405 - val_loss: 0.1732 - val_acc: 0.9427\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1630 - acc: 0.9458\n","Epoch 3: val_loss improved from 0.17325 to 0.16827, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 40ms/step - loss: 0.1628 - acc: 0.9459 - val_loss: 0.1683 - val_acc: 0.9409\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1509 - acc: 0.9489\n","Epoch 4: val_loss improved from 0.16827 to 0.16354, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 41ms/step - loss: 0.1510 - acc: 0.9488 - val_loss: 0.1635 - val_acc: 0.9445\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9529\n","Epoch 5: val_loss did not improve from 0.16354\n","238/238 [==============================] - 9s 40ms/step - loss: 0.1380 - acc: 0.9530 - val_loss: 0.1723 - val_acc: 0.9385\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9560\n","Epoch 6: val_loss did not improve from 0.16354\n","238/238 [==============================] - 9s 38ms/step - loss: 0.1252 - acc: 0.9562 - val_loss: 0.1848 - val_acc: 0.9385\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9622\n","Epoch 7: val_loss did not improve from 0.16354\n","238/238 [==============================] - 10s 41ms/step - loss: 0.1104 - acc: 0.9622 - val_loss: 0.1981 - val_acc: 0.9441\n","0.8838381946720353 0.5264622509066404 0.9418123275068997 0.43400447427293065\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6767 - acc: 0.6224\n","Epoch 1: val_loss improved from inf to 0.63247, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 13s 41ms/step - loss: 0.6767 - acc: 0.6225 - val_loss: 0.6325 - val_acc: 0.6668\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6318 - acc: 0.6610\n","Epoch 2: val_loss improved from 0.63247 to 0.62446, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 40ms/step - loss: 0.6317 - acc: 0.6611 - val_loss: 0.6245 - val_acc: 0.6654\n","Epoch 3/100\n","238/238 [==============================] - ETA: 0s - loss: 0.6118 - acc: 0.6778\n","Epoch 3: val_loss did not improve from 0.62446\n","238/238 [==============================] - 10s 40ms/step - loss: 0.6118 - acc: 0.6778 - val_loss: 0.6273 - val_acc: 0.6654\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5966 - acc: 0.6891\n","Epoch 4: val_loss improved from 0.62446 to 0.61885, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 40ms/step - loss: 0.5966 - acc: 0.6892 - val_loss: 0.6189 - val_acc: 0.6714\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5824 - acc: 0.6995\n","Epoch 5: val_loss did not improve from 0.61885\n","238/238 [==============================] - 9s 39ms/step - loss: 0.5821 - acc: 0.6998 - val_loss: 0.6213 - val_acc: 0.6798\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5671 - acc: 0.7127\n","Epoch 6: val_loss did not improve from 0.61885\n","238/238 [==============================] - 9s 39ms/step - loss: 0.5670 - acc: 0.7129 - val_loss: 0.6233 - val_acc: 0.6733\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5412 - acc: 0.7327\n","Epoch 7: val_loss did not improve from 0.61885\n","238/238 [==============================] - 9s 40ms/step - loss: 0.5412 - acc: 0.7328 - val_loss: 0.6446 - val_acc: 0.6567\n","0.6968516528337068 0.6410956143239452 0.6573137074517019 0.5800450958286358\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5125 - acc: 0.7983\n","Epoch 1: val_loss improved from inf to 0.44618, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 12s 38ms/step - loss: 0.5125 - acc: 0.7984 - val_loss: 0.4462 - val_acc: 0.8207\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4437 - acc: 0.8164\n","Epoch 2: val_loss improved from 0.44618 to 0.44197, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 40ms/step - loss: 0.4442 - acc: 0.8162 - val_loss: 0.4420 - val_acc: 0.8175\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4274 - acc: 0.8205\n","Epoch 3: val_loss improved from 0.44197 to 0.43231, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 41ms/step - loss: 0.4274 - acc: 0.8205 - val_loss: 0.4323 - val_acc: 0.8189\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4119 - acc: 0.8252\n","Epoch 4: val_loss improved from 0.43231 to 0.42935, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 41ms/step - loss: 0.4124 - acc: 0.8251 - val_loss: 0.4294 - val_acc: 0.8202\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3997 - acc: 0.8290\n","Epoch 5: val_loss did not improve from 0.42935\n","238/238 [==============================] - 9s 39ms/step - loss: 0.3994 - acc: 0.8293 - val_loss: 0.4313 - val_acc: 0.8170\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3860 - acc: 0.8364\n","Epoch 6: val_loss did not improve from 0.42935\n","238/238 [==============================] - 10s 40ms/step - loss: 0.3858 - acc: 0.8365 - val_loss: 0.4493 - val_acc: 0.8179\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3631 - acc: 0.8474\n","Epoch 7: val_loss did not improve from 0.42935\n","238/238 [==============================] - 9s 39ms/step - loss: 0.3630 - acc: 0.8474 - val_loss: 0.4440 - val_acc: 0.8156\n","0.7244501271745841 0.3850643549892617 0.827966881324747 0.2109704641350211\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3095 - acc: 0.9110\n","Epoch 1: val_loss improved from inf to 0.26557, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 12s 42ms/step - loss: 0.3094 - acc: 0.9110 - val_loss: 0.2656 - val_acc: 0.9233\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2595 - acc: 0.9211\n","Epoch 2: val_loss improved from 0.26557 to 0.26267, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 10s 42ms/step - loss: 0.2597 - acc: 0.9212 - val_loss: 0.2627 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2481 - acc: 0.9220\n","Epoch 3: val_loss improved from 0.26267 to 0.25875, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 10s 41ms/step - loss: 0.2485 - acc: 0.9219 - val_loss: 0.2588 - val_acc: 0.9242\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2375 - acc: 0.9225\n","Epoch 4: val_loss did not improve from 0.25875\n","238/238 [==============================] - 10s 40ms/step - loss: 0.2375 - acc: 0.9225 - val_loss: 0.2637 - val_acc: 0.9247\n","Epoch 5/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2270 - acc: 0.9237\n","Epoch 5: val_loss did not improve from 0.25875\n","238/238 [==============================] - 10s 42ms/step - loss: 0.2270 - acc: 0.9237 - val_loss: 0.2665 - val_acc: 0.9201\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2153 - acc: 0.9259\n","Epoch 6: val_loss did not improve from 0.25875\n","238/238 [==============================] - 10s 42ms/step - loss: 0.2154 - acc: 0.9259 - val_loss: 0.2673 - val_acc: 0.9173\n","0.734185365112247 0.21675068779682197 0.9188132474701012 0.027548209366391185\n","Iteration number:  8\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2918 - acc: 0.9014\n","Epoch 1: val_loss improved from inf to 0.23723, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 13s 43ms/step - loss: 0.2918 - acc: 0.9014 - val_loss: 0.2372 - val_acc: 0.9136\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2427 - acc: 0.9134\n","Epoch 2: val_loss did not improve from 0.23723\n","238/238 [==============================] - 10s 42ms/step - loss: 0.2429 - acc: 0.9132 - val_loss: 0.2403 - val_acc: 0.9108\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2255 - acc: 0.9177\n","Epoch 3: val_loss improved from 0.23723 to 0.22993, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 43ms/step - loss: 0.2252 - acc: 0.9177 - val_loss: 0.2299 - val_acc: 0.9145\n","Epoch 4/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2095 - acc: 0.9242\n","Epoch 4: val_loss did not improve from 0.22993\n","238/238 [==============================] - 10s 42ms/step - loss: 0.2095 - acc: 0.9242 - val_loss: 0.2361 - val_acc: 0.9150\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9261\n","Epoch 5: val_loss did not improve from 0.22993\n","238/238 [==============================] - 10s 42ms/step - loss: 0.1962 - acc: 0.9259 - val_loss: 0.2358 - val_acc: 0.9122\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1779 - acc: 0.9362\n","Epoch 6: val_loss did not improve from 0.22993\n","238/238 [==============================] - 10s 40ms/step - loss: 0.1780 - acc: 0.9362 - val_loss: 0.2440 - val_acc: 0.9076\n","0.8799046171468852 0.5881639338947412 0.9146734130634775 0.469241773962804\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2236 - acc: 0.9285\n","Epoch 1: val_loss improved from inf to 0.17781, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 13s 42ms/step - loss: 0.2235 - acc: 0.9285 - val_loss: 0.1778 - val_acc: 0.9409\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1761 - acc: 0.9432\n","Epoch 2: val_loss improved from 0.17781 to 0.16901, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 40ms/step - loss: 0.1760 - acc: 0.9432 - val_loss: 0.1690 - val_acc: 0.9427\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1620 - acc: 0.9453\n","Epoch 3: val_loss did not improve from 0.16901\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1619 - acc: 0.9453 - val_loss: 0.1692 - val_acc: 0.9404\n","Epoch 4/100\n","238/238 [==============================] - ETA: 0s - loss: 0.1509 - acc: 0.9482\n","Epoch 4: val_loss improved from 0.16901 to 0.16869, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 40ms/step - loss: 0.1509 - acc: 0.9482 - val_loss: 0.1687 - val_acc: 0.9399\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9527\n","Epoch 5: val_loss did not improve from 0.16869\n","238/238 [==============================] - 10s 43ms/step - loss: 0.1381 - acc: 0.9528 - val_loss: 0.1733 - val_acc: 0.9427\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9557\n","Epoch 6: val_loss did not improve from 0.16869\n","238/238 [==============================] - 10s 41ms/step - loss: 0.1277 - acc: 0.9558 - val_loss: 0.1843 - val_acc: 0.9385\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9629\n","Epoch 7: val_loss did not improve from 0.16869\n","238/238 [==============================] - 9s 40ms/step - loss: 0.1098 - acc: 0.9630 - val_loss: 0.1857 - val_acc: 0.9385\n","0.8877038562978916 0.5183697030106278 0.9420423183072677 0.4349775784753363\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6814 - acc: 0.6257\n","Epoch 1: val_loss improved from inf to 0.62338, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 12s 38ms/step - loss: 0.6812 - acc: 0.6259 - val_loss: 0.6234 - val_acc: 0.6779\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6313 - acc: 0.6572\n","Epoch 2: val_loss did not improve from 0.62338\n","238/238 [==============================] - 9s 37ms/step - loss: 0.6312 - acc: 0.6574 - val_loss: 0.6242 - val_acc: 0.6622\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6134 - acc: 0.6774\n","Epoch 3: val_loss improved from 0.62338 to 0.61319, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.6133 - acc: 0.6776 - val_loss: 0.6132 - val_acc: 0.6742\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5974 - acc: 0.6915\n","Epoch 4: val_loss did not improve from 0.61319\n","238/238 [==============================] - 9s 39ms/step - loss: 0.5977 - acc: 0.6911 - val_loss: 0.6157 - val_acc: 0.6835\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5823 - acc: 0.7011\n","Epoch 5: val_loss did not improve from 0.61319\n","238/238 [==============================] - 9s 37ms/step - loss: 0.5822 - acc: 0.7014 - val_loss: 0.6151 - val_acc: 0.6807\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5656 - acc: 0.7183\n","Epoch 6: val_loss did not improve from 0.61319\n","238/238 [==============================] - 9s 38ms/step - loss: 0.5658 - acc: 0.7182 - val_loss: 0.6189 - val_acc: 0.6738\n","0.7059278873336701 0.6492155738594618 0.6649034038638455 0.5700796695190321\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4798 - acc: 0.8080\n","Epoch 1: val_loss improved from inf to 0.44643, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.4798 - acc: 0.8077 - val_loss: 0.4464 - val_acc: 0.8193\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4380 - acc: 0.8172\n","Epoch 2: val_loss improved from 0.44643 to 0.43337, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.4380 - acc: 0.8171 - val_loss: 0.4334 - val_acc: 0.8184\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4219 - acc: 0.8208\n","Epoch 3: val_loss improved from 0.43337 to 0.43329, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 38ms/step - loss: 0.4219 - acc: 0.8209 - val_loss: 0.4333 - val_acc: 0.8198\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4114 - acc: 0.8240\n","Epoch 4: val_loss improved from 0.43329 to 0.42845, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.4114 - acc: 0.8241 - val_loss: 0.4285 - val_acc: 0.8119\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3982 - acc: 0.8304\n","Epoch 5: val_loss did not improve from 0.42845\n","238/238 [==============================] - 9s 36ms/step - loss: 0.3978 - acc: 0.8306 - val_loss: 0.4306 - val_acc: 0.8216\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3830 - acc: 0.8358\n","Epoch 6: val_loss did not improve from 0.42845\n","238/238 [==============================] - 9s 37ms/step - loss: 0.3828 - acc: 0.8359 - val_loss: 0.4411 - val_acc: 0.8198\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3636 - acc: 0.8462\n","Epoch 7: val_loss did not improve from 0.42845\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3637 - acc: 0.8462 - val_loss: 0.4483 - val_acc: 0.8096\n","0.7159415763286093 0.3740050171023689 0.8245170193192273 0.2726406101048618\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2935 - acc: 0.9176\n","Epoch 1: val_loss improved from inf to 0.27666, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2930 - acc: 0.9177 - val_loss: 0.2767 - val_acc: 0.9251\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2605 - acc: 0.9220\n","Epoch 2: val_loss improved from 0.27666 to 0.26092, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2606 - acc: 0.9218 - val_loss: 0.2609 - val_acc: 0.9242\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2443 - acc: 0.9219\n","Epoch 3: val_loss improved from 0.26092 to 0.25910, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2448 - acc: 0.9217 - val_loss: 0.2591 - val_acc: 0.9233\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2353 - acc: 0.9221\n","Epoch 4: val_loss improved from 0.25910 to 0.25876, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2348 - acc: 0.9222 - val_loss: 0.2588 - val_acc: 0.9238\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2263 - acc: 0.9251\n","Epoch 5: val_loss did not improve from 0.25876\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2260 - acc: 0.9253 - val_loss: 0.2644 - val_acc: 0.9168\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2139 - acc: 0.9268\n","Epoch 6: val_loss did not improve from 0.25876\n","238/238 [==============================] - 9s 38ms/step - loss: 0.2142 - acc: 0.9266 - val_loss: 0.2672 - val_acc: 0.9150\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1989 - acc: 0.9303\n","Epoch 7: val_loss did not improve from 0.25876\n","238/238 [==============================] - 10s 40ms/step - loss: 0.1988 - acc: 0.9304 - val_loss: 0.2826 - val_acc: 0.9154\n","0.732989856116728 0.20929535826399434 0.9183532658693653 0.0431266846361186\n","Iteration number:  9\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3029 - acc: 0.8988\n","Epoch 1: val_loss improved from inf to 0.24899, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 12s 39ms/step - loss: 0.3024 - acc: 0.8989 - val_loss: 0.2490 - val_acc: 0.9140\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2464 - acc: 0.9138\n","Epoch 2: val_loss improved from 0.24899 to 0.23748, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2467 - acc: 0.9137 - val_loss: 0.2375 - val_acc: 0.9117\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2279 - acc: 0.9181\n","Epoch 3: val_loss improved from 0.23748 to 0.23137, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2275 - acc: 0.9183 - val_loss: 0.2314 - val_acc: 0.9150\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2127 - acc: 0.9237\n","Epoch 4: val_loss improved from 0.23137 to 0.23008, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2125 - acc: 0.9238 - val_loss: 0.2301 - val_acc: 0.9168\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9275\n","Epoch 5: val_loss did not improve from 0.23008\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1980 - acc: 0.9275 - val_loss: 0.2468 - val_acc: 0.9099\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1834 - acc: 0.9333\n","Epoch 6: val_loss did not improve from 0.23008\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1834 - acc: 0.9333 - val_loss: 0.2454 - val_acc: 0.9090\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1642 - acc: 0.9395\n","Epoch 7: val_loss did not improve from 0.23008\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1643 - acc: 0.9395 - val_loss: 0.2631 - val_acc: 0.9164\n","0.8757869636091286 0.5807221409919424 0.9132934682612696 0.38499184339314846\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2134 - acc: 0.9335\n","Epoch 1: val_loss improved from inf to 0.17848, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2133 - acc: 0.9334 - val_loss: 0.1785 - val_acc: 0.9436\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9422\n","Epoch 2: val_loss improved from 0.17848 to 0.16792, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1748 - acc: 0.9424 - val_loss: 0.1679 - val_acc: 0.9432\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9461\n","Epoch 3: val_loss did not improve from 0.16792\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1606 - acc: 0.9461 - val_loss: 0.1710 - val_acc: 0.9436\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1509 - acc: 0.9492\n","Epoch 4: val_loss did not improve from 0.16792\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1507 - acc: 0.9491 - val_loss: 0.1719 - val_acc: 0.9399\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1377 - acc: 0.9518\n","Epoch 5: val_loss did not improve from 0.16792\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1376 - acc: 0.9518 - val_loss: 0.1703 - val_acc: 0.9436\n","0.8768965463426817 0.511609402344157 0.9413523459061638 0.41108545034642024\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6798 - acc: 0.6227\n","Epoch 1: val_loss improved from inf to 0.63226, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 32ms/step - loss: 0.6796 - acc: 0.6230 - val_loss: 0.6323 - val_acc: 0.6631\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6293 - acc: 0.6608\n","Epoch 2: val_loss improved from 0.63226 to 0.62539, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.6295 - acc: 0.6606 - val_loss: 0.6254 - val_acc: 0.6659\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6118 - acc: 0.6826\n","Epoch 3: val_loss improved from 0.62539 to 0.62169, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6116 - acc: 0.6828 - val_loss: 0.6217 - val_acc: 0.6631\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5979 - acc: 0.6880\n","Epoch 4: val_loss improved from 0.62169 to 0.61538, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.5980 - acc: 0.6876 - val_loss: 0.6154 - val_acc: 0.6668\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5832 - acc: 0.7009\n","Epoch 5: val_loss did not improve from 0.61538\n","238/238 [==============================] - 7s 31ms/step - loss: 0.5831 - acc: 0.7007 - val_loss: 0.6220 - val_acc: 0.6724\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5658 - acc: 0.7126\n","Epoch 6: val_loss did not improve from 0.61538\n","238/238 [==============================] - 8s 32ms/step - loss: 0.5660 - acc: 0.7126 - val_loss: 0.6249 - val_acc: 0.6691\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5470 - acc: 0.7275\n","Epoch 7: val_loss did not improve from 0.61538\n","238/238 [==============================] - 8s 32ms/step - loss: 0.5468 - acc: 0.7276 - val_loss: 0.6449 - val_acc: 0.6617\n","0.7086286594761171 0.650146175782445 0.6630634774609016 0.534181240063593\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4791 - acc: 0.8099\n","Epoch 1: val_loss improved from inf to 0.44216, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.4789 - acc: 0.8100 - val_loss: 0.4422 - val_acc: 0.8138\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4428 - acc: 0.8167\n","Epoch 2: val_loss improved from 0.44216 to 0.43204, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.4424 - acc: 0.8169 - val_loss: 0.4320 - val_acc: 0.8170\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4224 - acc: 0.8205\n","Epoch 3: val_loss improved from 0.43204 to 0.42737, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4222 - acc: 0.8206 - val_loss: 0.4274 - val_acc: 0.8179\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4129 - acc: 0.8242\n","Epoch 4: val_loss improved from 0.42737 to 0.42598, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.4128 - acc: 0.8240 - val_loss: 0.4260 - val_acc: 0.8198\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3985 - acc: 0.8299\n","Epoch 5: val_loss did not improve from 0.42598\n","238/238 [==============================] - 8s 33ms/step - loss: 0.3986 - acc: 0.8298 - val_loss: 0.4293 - val_acc: 0.8202\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3834 - acc: 0.8366\n","Epoch 6: val_loss did not improve from 0.42598\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3835 - acc: 0.8365 - val_loss: 0.4386 - val_acc: 0.8133\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3612 - acc: 0.8484\n","Epoch 7: val_loss did not improve from 0.42598\n","238/238 [==============================] - 8s 33ms/step - loss: 0.3623 - acc: 0.8481 - val_loss: 0.4537 - val_acc: 0.8175\n","0.7237715976280024 0.3733467387375921 0.8210671573137075 0.25621414913957935\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2888 - acc: 0.9176\n","Epoch 1: val_loss improved from inf to 0.26480, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 10s 33ms/step - loss: 0.2887 - acc: 0.9176 - val_loss: 0.2648 - val_acc: 0.9251\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2561 - acc: 0.9214\n","Epoch 2: val_loss improved from 0.26480 to 0.26054, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2560 - acc: 0.9214 - val_loss: 0.2605 - val_acc: 0.9247\n","Epoch 3/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2447 - acc: 0.9219\n","Epoch 3: val_loss improved from 0.26054 to 0.25955, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2447 - acc: 0.9219 - val_loss: 0.2595 - val_acc: 0.9247\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2352 - acc: 0.9228\n","Epoch 4: val_loss did not improve from 0.25955\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2350 - acc: 0.9229 - val_loss: 0.2645 - val_acc: 0.9205\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2246 - acc: 0.9242\n","Epoch 5: val_loss did not improve from 0.25955\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2253 - acc: 0.9240 - val_loss: 0.2701 - val_acc: 0.9247\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2109 - acc: 0.9279\n","Epoch 6: val_loss did not improve from 0.25955\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2111 - acc: 0.9278 - val_loss: 0.2710 - val_acc: 0.9191\n","0.7113102609713811 0.19814405497333978 0.9181232750689973 0.00558659217877095\n","Iteration number:  10\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2990 - acc: 0.8975\n","Epoch 1: val_loss improved from inf to 0.24619, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.2990 - acc: 0.8976 - val_loss: 0.2462 - val_acc: 0.9113\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2456 - acc: 0.9135\n","Epoch 2: val_loss improved from 0.24619 to 0.23977, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2456 - acc: 0.9133 - val_loss: 0.2398 - val_acc: 0.9191\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2273 - acc: 0.9186\n","Epoch 3: val_loss improved from 0.23977 to 0.23312, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.2270 - acc: 0.9188 - val_loss: 0.2331 - val_acc: 0.9173\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2113 - acc: 0.9237\n","Epoch 4: val_loss did not improve from 0.23312\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2110 - acc: 0.9237 - val_loss: 0.2379 - val_acc: 0.9182\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1973 - acc: 0.9282\n","Epoch 5: val_loss improved from 0.23312 to 0.23193, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1978 - acc: 0.9281 - val_loss: 0.2319 - val_acc: 0.9187\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1807 - acc: 0.9334\n","Epoch 6: val_loss did not improve from 0.23193\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1805 - acc: 0.9334 - val_loss: 0.2473 - val_acc: 0.9090\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1619 - acc: 0.9416\n","Epoch 7: val_loss did not improve from 0.23193\n","238/238 [==============================] - 7s 31ms/step - loss: 0.1616 - acc: 0.9417 - val_loss: 0.2697 - val_acc: 0.9011\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9488\n","Epoch 8: val_loss did not improve from 0.23193\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1408 - acc: 0.9488 - val_loss: 0.2782 - val_acc: 0.8997\n","0.867130914618028 0.5606670814617184 0.9130634774609016 0.425531914893617\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2185 - acc: 0.9326\n","Epoch 1: val_loss improved from inf to 0.17412, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.2185 - acc: 0.9324 - val_loss: 0.1741 - val_acc: 0.9427\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1751 - acc: 0.9433\n","Epoch 2: val_loss improved from 0.17412 to 0.16919, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1752 - acc: 0.9433 - val_loss: 0.1692 - val_acc: 0.9404\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1619 - acc: 0.9444\n","Epoch 3: val_loss did not improve from 0.16919\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1617 - acc: 0.9444 - val_loss: 0.1715 - val_acc: 0.9422\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9477\n","Epoch 4: val_loss improved from 0.16919 to 0.16768, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1500 - acc: 0.9478 - val_loss: 0.1677 - val_acc: 0.9413\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9520\n","Epoch 5: val_loss did not improve from 0.16768\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1364 - acc: 0.9519 - val_loss: 0.1784 - val_acc: 0.9353\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9564\n","Epoch 6: val_loss did not improve from 0.16768\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1234 - acc: 0.9562 - val_loss: 0.1810 - val_acc: 0.9404\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9612\n","Epoch 7: val_loss did not improve from 0.16768\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1081 - acc: 0.9612 - val_loss: 0.1994 - val_acc: 0.9381\n","0.8751525508372738 0.5075045039130488 0.9392824287028518 0.4522821576763486\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6862 - acc: 0.6222\n","Epoch 1: val_loss improved from inf to 0.63516, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 12s 40ms/step - loss: 0.6861 - acc: 0.6221 - val_loss: 0.6352 - val_acc: 0.6664\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6313 - acc: 0.6630\n","Epoch 2: val_loss improved from 0.63516 to 0.62166, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 39ms/step - loss: 0.6314 - acc: 0.6628 - val_loss: 0.6217 - val_acc: 0.6627\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6133 - acc: 0.6741\n","Epoch 3: val_loss improved from 0.62166 to 0.61586, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 39ms/step - loss: 0.6133 - acc: 0.6741 - val_loss: 0.6159 - val_acc: 0.6738\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5992 - acc: 0.6865\n","Epoch 4: val_loss improved from 0.61586 to 0.61042, saving model to avg-word2vec-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 39ms/step - loss: 0.5992 - acc: 0.6866 - val_loss: 0.6104 - val_acc: 0.6788\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5845 - acc: 0.6986\n","Epoch 5: val_loss did not improve from 0.61042\n","238/238 [==============================] - 9s 39ms/step - loss: 0.5844 - acc: 0.6987 - val_loss: 0.6198 - val_acc: 0.6751\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5676 - acc: 0.7123\n","Epoch 6: val_loss did not improve from 0.61042\n","238/238 [==============================] - 9s 38ms/step - loss: 0.5675 - acc: 0.7124 - val_loss: 0.6130 - val_acc: 0.6779\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5474 - acc: 0.7289\n","Epoch 7: val_loss did not improve from 0.61042\n","238/238 [==============================] - 9s 39ms/step - loss: 0.5474 - acc: 0.7289 - val_loss: 0.6297 - val_acc: 0.6627\n","0.7062965864311825 0.6480568687452988 0.6589236430542779 0.5809550720542527\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4838 - acc: 0.8072\n","Epoch 1: val_loss improved from inf to 0.43701, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 12s 41ms/step - loss: 0.4835 - acc: 0.8072 - val_loss: 0.4370 - val_acc: 0.8193\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4401 - acc: 0.8164\n","Epoch 2: val_loss improved from 0.43701 to 0.43647, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 38ms/step - loss: 0.4403 - acc: 0.8160 - val_loss: 0.4365 - val_acc: 0.8165\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4270 - acc: 0.8203\n","Epoch 3: val_loss improved from 0.43647 to 0.42639, saving model to avg-word2vec-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 39ms/step - loss: 0.4269 - acc: 0.8204 - val_loss: 0.4264 - val_acc: 0.8170\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4135 - acc: 0.8244\n","Epoch 4: val_loss did not improve from 0.42639\n","238/238 [==============================] - 9s 37ms/step - loss: 0.4139 - acc: 0.8244 - val_loss: 0.4281 - val_acc: 0.8216\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4011 - acc: 0.8304\n","Epoch 5: val_loss did not improve from 0.42639\n","238/238 [==============================] - 9s 38ms/step - loss: 0.4014 - acc: 0.8301 - val_loss: 0.4320 - val_acc: 0.8119\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3843 - acc: 0.8354\n","Epoch 6: val_loss did not improve from 0.42639\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3844 - acc: 0.8351 - val_loss: 0.4360 - val_acc: 0.8179\n","0.7006889406552347 0.3517188041925094 0.8226770929162833 0.20268872802481902\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2939 - acc: 0.9179\n","Epoch 1: val_loss improved from inf to 0.26265, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 38ms/step - loss: 0.2937 - acc: 0.9178 - val_loss: 0.2627 - val_acc: 0.9233\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2552 - acc: 0.9213\n","Epoch 2: val_loss improved from 0.26265 to 0.26057, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2552 - acc: 0.9213 - val_loss: 0.2606 - val_acc: 0.9238\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2463 - acc: 0.9225\n","Epoch 3: val_loss improved from 0.26057 to 0.25509, saving model to avg-word2vec-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2466 - acc: 0.9223 - val_loss: 0.2551 - val_acc: 0.9242\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2340 - acc: 0.9237\n","Epoch 4: val_loss did not improve from 0.25509\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2340 - acc: 0.9237 - val_loss: 0.2594 - val_acc: 0.9228\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2236 - acc: 0.9233\n","Epoch 5: val_loss did not improve from 0.25509\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2231 - acc: 0.9235 - val_loss: 0.2651 - val_acc: 0.9191\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2128 - acc: 0.9263\n","Epoch 6: val_loss did not improve from 0.25509\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2122 - acc: 0.9265 - val_loss: 0.2704 - val_acc: 0.9196\n","0.730179460043683 0.22801487360262365 0.9181232750689973 0.03783783783783784\n","Embedding:  fasttext\n","=============================\n","Iteration number:  1\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2912 - acc: 0.9009\n","Epoch 1: val_loss improved from inf to 0.24622, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.2905 - acc: 0.9012 - val_loss: 0.2462 - val_acc: 0.9117\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2404 - acc: 0.9142\n","Epoch 2: val_loss improved from 0.24622 to 0.23677, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2403 - acc: 0.9143 - val_loss: 0.2368 - val_acc: 0.9145\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2245 - acc: 0.9188\n","Epoch 3: val_loss improved from 0.23677 to 0.22958, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2245 - acc: 0.9187 - val_loss: 0.2296 - val_acc: 0.9145\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2094 - acc: 0.9223\n","Epoch 4: val_loss did not improve from 0.22958\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2094 - acc: 0.9223 - val_loss: 0.2379 - val_acc: 0.9182\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1976 - acc: 0.9271\n","Epoch 5: val_loss did not improve from 0.22958\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1978 - acc: 0.9271 - val_loss: 0.2402 - val_acc: 0.9057\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1831 - acc: 0.9316\n","Epoch 6: val_loss did not improve from 0.22958\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1830 - acc: 0.9316 - val_loss: 0.2435 - val_acc: 0.9071\n","0.8779440919904837 0.5784591176255783 0.9128334866605335 0.4562410329985652\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2123 - acc: 0.9361\n","Epoch 1: val_loss improved from inf to 0.17887, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.2123 - acc: 0.9362 - val_loss: 0.1789 - val_acc: 0.9418\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1793 - acc: 0.9415\n","Epoch 2: val_loss improved from 0.17887 to 0.17146, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1791 - acc: 0.9416 - val_loss: 0.1715 - val_acc: 0.9395\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1596 - acc: 0.9464\n","Epoch 3: val_loss improved from 0.17146 to 0.17031, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1599 - acc: 0.9462 - val_loss: 0.1703 - val_acc: 0.9436\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9490\n","Epoch 4: val_loss improved from 0.17031 to 0.16793, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1496 - acc: 0.9487 - val_loss: 0.1679 - val_acc: 0.9422\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9519\n","Epoch 5: val_loss did not improve from 0.16793\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1386 - acc: 0.9520 - val_loss: 0.1680 - val_acc: 0.9441\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9564\n","Epoch 6: val_loss did not improve from 0.16793\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1242 - acc: 0.9564 - val_loss: 0.1750 - val_acc: 0.9445\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9617\n","Epoch 7: val_loss did not improve from 0.16793\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1102 - acc: 0.9616 - val_loss: 0.1861 - val_acc: 0.9436\n","0.8780248763206768 0.5171373554575995 0.9420423183072677 0.41935483870967744\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6898 - acc: 0.6151\n","Epoch 1: val_loss improved from inf to 0.62935, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.6899 - acc: 0.6150 - val_loss: 0.6294 - val_acc: 0.6691\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6332 - acc: 0.6571\n","Epoch 2: val_loss improved from 0.62935 to 0.62347, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.6330 - acc: 0.6572 - val_loss: 0.6235 - val_acc: 0.6701\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6156 - acc: 0.6752\n","Epoch 3: val_loss improved from 0.62347 to 0.61522, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6155 - acc: 0.6751 - val_loss: 0.6152 - val_acc: 0.6728\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5990 - acc: 0.6877\n","Epoch 4: val_loss improved from 0.61522 to 0.61497, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.5990 - acc: 0.6879 - val_loss: 0.6150 - val_acc: 0.6761\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5860 - acc: 0.6991\n","Epoch 5: val_loss improved from 0.61497 to 0.60692, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 36ms/step - loss: 0.5859 - acc: 0.6991 - val_loss: 0.6069 - val_acc: 0.6705\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5682 - acc: 0.7145\n","Epoch 6: val_loss did not improve from 0.60692\n","238/238 [==============================] - 8s 35ms/step - loss: 0.5683 - acc: 0.7144 - val_loss: 0.6185 - val_acc: 0.6604\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5483 - acc: 0.7294\n","Epoch 7: val_loss did not improve from 0.60692\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5483 - acc: 0.7294 - val_loss: 0.6441 - val_acc: 0.6534\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5196 - acc: 0.7476\n","Epoch 8: val_loss did not improve from 0.60692\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5191 - acc: 0.7477 - val_loss: 0.6566 - val_acc: 0.6520\n","0.6993590656601623 0.6408596199050514 0.6616835326586936 0.5489113768782583\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4846 - acc: 0.8055\n","Epoch 1: val_loss improved from inf to 0.44187, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.4844 - acc: 0.8055 - val_loss: 0.4419 - val_acc: 0.8179\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4385 - acc: 0.8157\n","Epoch 2: val_loss improved from 0.44187 to 0.43539, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.4387 - acc: 0.8156 - val_loss: 0.4354 - val_acc: 0.8170\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4248 - acc: 0.8205\n","Epoch 3: val_loss improved from 0.43539 to 0.43216, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4249 - acc: 0.8206 - val_loss: 0.4322 - val_acc: 0.8161\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4112 - acc: 0.8258\n","Epoch 4: val_loss improved from 0.43216 to 0.42326, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.4109 - acc: 0.8259 - val_loss: 0.4233 - val_acc: 0.8216\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3972 - acc: 0.8305\n","Epoch 5: val_loss did not improve from 0.42326\n","238/238 [==============================] - 9s 36ms/step - loss: 0.3971 - acc: 0.8307 - val_loss: 0.4347 - val_acc: 0.8165\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3814 - acc: 0.8372\n","Epoch 6: val_loss did not improve from 0.42326\n","238/238 [==============================] - 9s 36ms/step - loss: 0.3815 - acc: 0.8370 - val_loss: 0.4436 - val_acc: 0.8165\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3595 - acc: 0.8497\n","Epoch 7: val_loss did not improve from 0.42326\n","238/238 [==============================] - 9s 37ms/step - loss: 0.3599 - acc: 0.8495 - val_loss: 0.4645 - val_acc: 0.8059\n","0.7155668848661522 0.37312334388781915 0.8247470101195952 0.21280991735537189\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3055 - acc: 0.9141\n","Epoch 1: val_loss improved from inf to 0.27140, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 12s 38ms/step - loss: 0.3053 - acc: 0.9142 - val_loss: 0.2714 - val_acc: 0.9238\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2609 - acc: 0.9210\n","Epoch 2: val_loss improved from 0.27140 to 0.26576, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.2606 - acc: 0.9211 - val_loss: 0.2658 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2460 - acc: 0.9221\n","Epoch 3: val_loss improved from 0.26576 to 0.26296, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2457 - acc: 0.9222 - val_loss: 0.2630 - val_acc: 0.9242\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2360 - acc: 0.9224\n","Epoch 4: val_loss improved from 0.26296 to 0.25997, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.2366 - acc: 0.9223 - val_loss: 0.2600 - val_acc: 0.9247\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2243 - acc: 0.9233\n","Epoch 5: val_loss did not improve from 0.25997\n","238/238 [==============================] - 9s 37ms/step - loss: 0.2243 - acc: 0.9233 - val_loss: 0.2691 - val_acc: 0.9242\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2136 - acc: 0.9264\n","Epoch 6: val_loss did not improve from 0.25997\n","238/238 [==============================] - 8s 36ms/step - loss: 0.2134 - acc: 0.9265 - val_loss: 0.2761 - val_acc: 0.9224\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1963 - acc: 0.9327\n","Epoch 7: val_loss did not improve from 0.25997\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1965 - acc: 0.9325 - val_loss: 0.2908 - val_acc: 0.9191\n","0.7336484767287383 0.2219090615357447 0.9190432382704692 0.027624309392265196\n","Iteration number:  2\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2884 - acc: 0.9016\n","Epoch 1: val_loss improved from inf to 0.24627, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.2881 - acc: 0.9018 - val_loss: 0.2463 - val_acc: 0.9122\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2431 - acc: 0.9146\n","Epoch 2: val_loss improved from 0.24627 to 0.23851, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2431 - acc: 0.9144 - val_loss: 0.2385 - val_acc: 0.9090\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2263 - acc: 0.9186\n","Epoch 3: val_loss improved from 0.23851 to 0.23248, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2263 - acc: 0.9186 - val_loss: 0.2325 - val_acc: 0.9113\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2110 - acc: 0.9228\n","Epoch 4: val_loss improved from 0.23248 to 0.22839, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2109 - acc: 0.9229 - val_loss: 0.2284 - val_acc: 0.9164\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1975 - acc: 0.9282\n","Epoch 5: val_loss did not improve from 0.22839\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1974 - acc: 0.9282 - val_loss: 0.2394 - val_acc: 0.9104\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1827 - acc: 0.9337\n","Epoch 6: val_loss did not improve from 0.22839\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1826 - acc: 0.9338 - val_loss: 0.2510 - val_acc: 0.9099\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1619 - acc: 0.9418\n","Epoch 7: val_loss did not improve from 0.22839\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1618 - acc: 0.9418 - val_loss: 0.2585 - val_acc: 0.9094\n","0.8741419948894177 0.5908273699089591 0.9176632934682613 0.47965116279069764\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2175 - acc: 0.9359\n","Epoch 1: val_loss improved from inf to 0.17955, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.2172 - acc: 0.9360 - val_loss: 0.1796 - val_acc: 0.9422\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1750 - acc: 0.9413\n","Epoch 2: val_loss improved from 0.17955 to 0.17276, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1754 - acc: 0.9413 - val_loss: 0.1728 - val_acc: 0.9413\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1611 - acc: 0.9455\n","Epoch 3: val_loss improved from 0.17276 to 0.16651, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1612 - acc: 0.9453 - val_loss: 0.1665 - val_acc: 0.9418\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9484\n","Epoch 4: val_loss improved from 0.16651 to 0.16329, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1497 - acc: 0.9484 - val_loss: 0.1633 - val_acc: 0.9450\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9513\n","Epoch 5: val_loss did not improve from 0.16329\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1376 - acc: 0.9511 - val_loss: 0.1800 - val_acc: 0.9358\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9569\n","Epoch 6: val_loss did not improve from 0.16329\n","238/238 [==============================] - 8s 36ms/step - loss: 0.1235 - acc: 0.9571 - val_loss: 0.1791 - val_acc: 0.9321\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9608\n","Epoch 7: val_loss did not improve from 0.16329\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1088 - acc: 0.9608 - val_loss: 0.1890 - val_acc: 0.9418\n","0.8758423459275558 0.5151411908129344 0.9420423183072677 0.4056603773584906\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6831 - acc: 0.6210\n","Epoch 1: val_loss improved from inf to 0.62772, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 11s 38ms/step - loss: 0.6833 - acc: 0.6211 - val_loss: 0.6277 - val_acc: 0.6747\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6329 - acc: 0.6568\n","Epoch 2: val_loss improved from 0.62772 to 0.61849, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6328 - acc: 0.6568 - val_loss: 0.6185 - val_acc: 0.6770\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6133 - acc: 0.6730\n","Epoch 3: val_loss improved from 0.61849 to 0.61584, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.6134 - acc: 0.6730 - val_loss: 0.6158 - val_acc: 0.6701\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5996 - acc: 0.6870\n","Epoch 4: val_loss improved from 0.61584 to 0.61204, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.5996 - acc: 0.6872 - val_loss: 0.6120 - val_acc: 0.6798\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5833 - acc: 0.7017\n","Epoch 5: val_loss did not improve from 0.61204\n","238/238 [==============================] - 8s 35ms/step - loss: 0.5832 - acc: 0.7016 - val_loss: 0.6188 - val_acc: 0.6714\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5666 - acc: 0.7149\n","Epoch 6: val_loss did not improve from 0.61204\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5664 - acc: 0.7153 - val_loss: 0.6340 - val_acc: 0.6636\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5456 - acc: 0.7296\n","Epoch 7: val_loss did not improve from 0.61204\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5453 - acc: 0.7299 - val_loss: 0.6338 - val_acc: 0.6668\n","0.7095005028205427 0.6529044637952301 0.6658233670653174 0.5772475996508584\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4783 - acc: 0.8076\n","Epoch 1: val_loss improved from inf to 0.44234, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.4782 - acc: 0.8076 - val_loss: 0.4423 - val_acc: 0.8212\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4381 - acc: 0.8178\n","Epoch 2: val_loss improved from 0.44234 to 0.43142, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4383 - acc: 0.8178 - val_loss: 0.4314 - val_acc: 0.8165\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4235 - acc: 0.8198\n","Epoch 3: val_loss improved from 0.43142 to 0.42809, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 36ms/step - loss: 0.4234 - acc: 0.8198 - val_loss: 0.4281 - val_acc: 0.8184\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4109 - acc: 0.8248\n","Epoch 4: val_loss improved from 0.42809 to 0.42713, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4108 - acc: 0.8248 - val_loss: 0.4271 - val_acc: 0.8202\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3968 - acc: 0.8310\n","Epoch 5: val_loss improved from 0.42713 to 0.42141, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3967 - acc: 0.8311 - val_loss: 0.4214 - val_acc: 0.8193\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3837 - acc: 0.8356\n","Epoch 6: val_loss did not improve from 0.42141\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3837 - acc: 0.8355 - val_loss: 0.4360 - val_acc: 0.8161\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3641 - acc: 0.8451\n","Epoch 7: val_loss did not improve from 0.42141\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3639 - acc: 0.8453 - val_loss: 0.4448 - val_acc: 0.8152\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3370 - acc: 0.8621\n","Epoch 8: val_loss did not improve from 0.42141\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3372 - acc: 0.8618 - val_loss: 0.4579 - val_acc: 0.8165\n","0.7233240645546576 0.3862459255399085 0.8249770009199632 0.27037392138063276\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3151 - acc: 0.9120\n","Epoch 1: val_loss improved from inf to 0.27587, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.3149 - acc: 0.9119 - val_loss: 0.2759 - val_acc: 0.9196\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2613 - acc: 0.9208\n","Epoch 2: val_loss improved from 0.27587 to 0.26479, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2614 - acc: 0.9208 - val_loss: 0.2648 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2479 - acc: 0.9215\n","Epoch 3: val_loss improved from 0.26479 to 0.26078, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2476 - acc: 0.9216 - val_loss: 0.2608 - val_acc: 0.9233\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2374 - acc: 0.9229\n","Epoch 4: val_loss improved from 0.26078 to 0.25970, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2374 - acc: 0.9228 - val_loss: 0.2597 - val_acc: 0.9205\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2270 - acc: 0.9246\n","Epoch 5: val_loss did not improve from 0.25970\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2267 - acc: 0.9248 - val_loss: 0.2638 - val_acc: 0.9247\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2125 - acc: 0.9252\n","Epoch 6: val_loss did not improve from 0.25970\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2125 - acc: 0.9252 - val_loss: 0.2702 - val_acc: 0.9251\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1971 - acc: 0.9313\n","Epoch 7: val_loss did not improve from 0.25970\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1972 - acc: 0.9314 - val_loss: 0.2920 - val_acc: 0.9127\n","0.7213077841075409 0.2070792484771884 0.9172033118675254 0.09999999999999999\n","Iteration number:  3\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3083 - acc: 0.8975\n","Epoch 1: val_loss improved from inf to 0.24553, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.3086 - acc: 0.8975 - val_loss: 0.2455 - val_acc: 0.9136\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2446 - acc: 0.9167\n","Epoch 2: val_loss improved from 0.24553 to 0.23599, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2442 - acc: 0.9169 - val_loss: 0.2360 - val_acc: 0.9159\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2275 - acc: 0.9160\n","Epoch 3: val_loss improved from 0.23599 to 0.23594, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2271 - acc: 0.9163 - val_loss: 0.2359 - val_acc: 0.9159\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9235\n","Epoch 4: val_loss improved from 0.23594 to 0.22847, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2108 - acc: 0.9235 - val_loss: 0.2285 - val_acc: 0.9136\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1950 - acc: 0.9284\n","Epoch 5: val_loss did not improve from 0.22847\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1951 - acc: 0.9283 - val_loss: 0.2382 - val_acc: 0.9085\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1789 - acc: 0.9359\n","Epoch 6: val_loss did not improve from 0.22847\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1789 - acc: 0.9358 - val_loss: 0.2506 - val_acc: 0.9205\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9416\n","Epoch 7: val_loss did not improve from 0.22847\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1598 - acc: 0.9416 - val_loss: 0.2680 - val_acc: 0.9076\n","0.8774418450964844 0.5788655494196319 0.9137534498620056 0.48700410396716826\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2225 - acc: 0.9310\n","Epoch 1: val_loss improved from inf to 0.17844, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.2227 - acc: 0.9309 - val_loss: 0.1784 - val_acc: 0.9409\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1779 - acc: 0.9417\n","Epoch 2: val_loss improved from 0.17844 to 0.16777, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1778 - acc: 0.9417 - val_loss: 0.1678 - val_acc: 0.9413\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1607 - acc: 0.9457\n","Epoch 3: val_loss did not improve from 0.16777\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1604 - acc: 0.9458 - val_loss: 0.1706 - val_acc: 0.9436\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9490\n","Epoch 4: val_loss improved from 0.16777 to 0.16389, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1500 - acc: 0.9491 - val_loss: 0.1639 - val_acc: 0.9432\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9508\n","Epoch 5: val_loss did not improve from 0.16389\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1392 - acc: 0.9509 - val_loss: 0.1944 - val_acc: 0.9293\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9554\n","Epoch 6: val_loss did not improve from 0.16389\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1263 - acc: 0.9555 - val_loss: 0.1790 - val_acc: 0.9413\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9618\n","Epoch 7: val_loss did not improve from 0.16389\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1102 - acc: 0.9617 - val_loss: 0.1902 - val_acc: 0.9321\n","0.8933423849431154 0.5448528886452869 0.9425022999080037 0.47916666666666663\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6867 - acc: 0.6142\n","Epoch 1: val_loss improved from inf to 0.63491, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.6866 - acc: 0.6144 - val_loss: 0.6349 - val_acc: 0.6613\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6339 - acc: 0.6584\n","Epoch 2: val_loss improved from 0.63491 to 0.61981, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6343 - acc: 0.6582 - val_loss: 0.6198 - val_acc: 0.6687\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6144 - acc: 0.6744\n","Epoch 3: val_loss improved from 0.61981 to 0.61904, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6145 - acc: 0.6742 - val_loss: 0.6190 - val_acc: 0.6691\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5998 - acc: 0.6892\n","Epoch 4: val_loss improved from 0.61904 to 0.61713, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.5998 - acc: 0.6892 - val_loss: 0.6171 - val_acc: 0.6645\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5854 - acc: 0.6994\n","Epoch 5: val_loss improved from 0.61713 to 0.61501, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.5853 - acc: 0.6996 - val_loss: 0.6150 - val_acc: 0.6761\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5649 - acc: 0.7173\n","Epoch 6: val_loss did not improve from 0.61501\n","238/238 [==============================] - 9s 36ms/step - loss: 0.5649 - acc: 0.7173 - val_loss: 0.6177 - val_acc: 0.6774\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5445 - acc: 0.7345\n","Epoch 7: val_loss did not improve from 0.61501\n","238/238 [==============================] - 9s 37ms/step - loss: 0.5443 - acc: 0.7348 - val_loss: 0.6406 - val_acc: 0.6530\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5172 - acc: 0.7516\n","Epoch 8: val_loss did not improve from 0.61501\n","238/238 [==============================] - 9s 38ms/step - loss: 0.5173 - acc: 0.7513 - val_loss: 0.6466 - val_acc: 0.6502\n","0.7071020704121402 0.6521789185357543 0.6616835326586936 0.595100467932838\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4737 - acc: 0.8105\n","Epoch 1: val_loss improved from inf to 0.44142, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.4741 - acc: 0.8104 - val_loss: 0.4414 - val_acc: 0.8105\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4384 - acc: 0.8151\n","Epoch 2: val_loss improved from 0.44142 to 0.42447, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4381 - acc: 0.8153 - val_loss: 0.4245 - val_acc: 0.8128\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4214 - acc: 0.8212\n","Epoch 3: val_loss did not improve from 0.42447\n","238/238 [==============================] - 9s 36ms/step - loss: 0.4216 - acc: 0.8210 - val_loss: 0.4365 - val_acc: 0.8147\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4123 - acc: 0.8253\n","Epoch 4: val_loss did not improve from 0.42447\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4129 - acc: 0.8248 - val_loss: 0.4257 - val_acc: 0.8235\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4008 - acc: 0.8290\n","Epoch 5: val_loss did not improve from 0.42447\n","238/238 [==============================] - 8s 36ms/step - loss: 0.4005 - acc: 0.8292 - val_loss: 0.4283 - val_acc: 0.8165\n","0.7178763073532792 0.36707966070202314 0.8226770929162833 0.21884498480243159\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2929 - acc: 0.9171\n","Epoch 1: val_loss improved from inf to 0.26908, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 12s 38ms/step - loss: 0.2924 - acc: 0.9173 - val_loss: 0.2691 - val_acc: 0.9233\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2591 - acc: 0.9218\n","Epoch 2: val_loss improved from 0.26908 to 0.26181, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.2592 - acc: 0.9217 - val_loss: 0.2618 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2455 - acc: 0.9223\n","Epoch 3: val_loss improved from 0.26181 to 0.25774, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.2462 - acc: 0.9221 - val_loss: 0.2577 - val_acc: 0.9247\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2366 - acc: 0.9223\n","Epoch 4: val_loss did not improve from 0.25774\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2368 - acc: 0.9224 - val_loss: 0.2586 - val_acc: 0.9242\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2248 - acc: 0.9230\n","Epoch 5: val_loss did not improve from 0.25774\n","238/238 [==============================] - 9s 37ms/step - loss: 0.2248 - acc: 0.9231 - val_loss: 0.2591 - val_acc: 0.9205\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2128 - acc: 0.9262\n","Epoch 6: val_loss did not improve from 0.25774\n","238/238 [==============================] - 9s 37ms/step - loss: 0.2127 - acc: 0.9262 - val_loss: 0.2680 - val_acc: 0.9238\n","0.7315755105717052 0.21530021635510396 0.9178932842686293 0.016528925619834708\n","Iteration number:  4\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2958 - acc: 0.8987\n","Epoch 1: val_loss improved from inf to 0.24434, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2953 - acc: 0.8989 - val_loss: 0.2443 - val_acc: 0.9187\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2410 - acc: 0.9136\n","Epoch 2: val_loss improved from 0.24434 to 0.24382, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2412 - acc: 0.9135 - val_loss: 0.2438 - val_acc: 0.9136\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2260 - acc: 0.9191\n","Epoch 3: val_loss improved from 0.24382 to 0.23736, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2264 - acc: 0.9190 - val_loss: 0.2374 - val_acc: 0.9140\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2118 - acc: 0.9221\n","Epoch 4: val_loss improved from 0.23736 to 0.23036, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2119 - acc: 0.9221 - val_loss: 0.2304 - val_acc: 0.9145\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1993 - acc: 0.9275\n","Epoch 5: val_loss did not improve from 0.23036\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1990 - acc: 0.9277 - val_loss: 0.2447 - val_acc: 0.9145\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9348\n","Epoch 6: val_loss did not improve from 0.23036\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1806 - acc: 0.9347 - val_loss: 0.2449 - val_acc: 0.9071\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1618 - acc: 0.9410\n","Epoch 7: val_loss did not improve from 0.23036\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1618 - acc: 0.9411 - val_loss: 0.2622 - val_acc: 0.9099\n","0.8738132214292009 0.5817550052820485 0.9151333946642134 0.4690647482014388\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2180 - acc: 0.9353\n","Epoch 1: val_loss improved from inf to 0.17565, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 11s 38ms/step - loss: 0.2179 - acc: 0.9353 - val_loss: 0.1757 - val_acc: 0.9418\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1758 - acc: 0.9430\n","Epoch 2: val_loss improved from 0.17565 to 0.16702, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1758 - acc: 0.9429 - val_loss: 0.1670 - val_acc: 0.9441\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1618 - acc: 0.9454\n","Epoch 3: val_loss did not improve from 0.16702\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1616 - acc: 0.9456 - val_loss: 0.1699 - val_acc: 0.9427\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1469 - acc: 0.9485\n","Epoch 4: val_loss did not improve from 0.16702\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1470 - acc: 0.9486 - val_loss: 0.1813 - val_acc: 0.9399\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1378 - acc: 0.9524\n","Epoch 5: val_loss did not improve from 0.16702\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1376 - acc: 0.9525 - val_loss: 0.1715 - val_acc: 0.9418\n","0.8788083087535309 0.509962777014294 0.9422723091076357 0.4434589800443459\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6855 - acc: 0.6179\n","Epoch 1: val_loss improved from inf to 0.63354, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 11s 38ms/step - loss: 0.6853 - acc: 0.6182 - val_loss: 0.6335 - val_acc: 0.6654\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6332 - acc: 0.6622\n","Epoch 2: val_loss improved from 0.63354 to 0.62147, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 36ms/step - loss: 0.6333 - acc: 0.6618 - val_loss: 0.6215 - val_acc: 0.6728\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6135 - acc: 0.6785\n","Epoch 3: val_loss improved from 0.62147 to 0.61885, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6132 - acc: 0.6790 - val_loss: 0.6189 - val_acc: 0.6738\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6005 - acc: 0.6870\n","Epoch 4: val_loss did not improve from 0.61885\n","238/238 [==============================] - 8s 36ms/step - loss: 0.6004 - acc: 0.6873 - val_loss: 0.6274 - val_acc: 0.6627\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5830 - acc: 0.7009\n","Epoch 5: val_loss improved from 0.61885 to 0.61312, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 36ms/step - loss: 0.5828 - acc: 0.7012 - val_loss: 0.6131 - val_acc: 0.6765\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5683 - acc: 0.7122\n","Epoch 6: val_loss did not improve from 0.61312\n","238/238 [==============================] - 9s 37ms/step - loss: 0.5683 - acc: 0.7122 - val_loss: 0.6254 - val_acc: 0.6650\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5462 - acc: 0.7294\n","Epoch 7: val_loss did not improve from 0.61312\n","238/238 [==============================] - 9s 36ms/step - loss: 0.5460 - acc: 0.7295 - val_loss: 0.6343 - val_acc: 0.6557\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5183 - acc: 0.7492\n","Epoch 8: val_loss did not improve from 0.61312\n","238/238 [==============================] - 8s 36ms/step - loss: 0.5184 - acc: 0.7493 - val_loss: 0.6473 - val_acc: 0.6567\n","0.7032137354171253 0.6448925206958325 0.6653633854645814 0.5778938207136641\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4881 - acc: 0.8045\n","Epoch 1: val_loss improved from inf to 0.43756, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.4885 - acc: 0.8041 - val_loss: 0.4376 - val_acc: 0.8161\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4416 - acc: 0.8158\n","Epoch 2: val_loss improved from 0.43756 to 0.43365, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.4411 - acc: 0.8161 - val_loss: 0.4337 - val_acc: 0.8198\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4261 - acc: 0.8211\n","Epoch 3: val_loss improved from 0.43365 to 0.42780, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4259 - acc: 0.8211 - val_loss: 0.4278 - val_acc: 0.8165\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4115 - acc: 0.8249\n","Epoch 4: val_loss did not improve from 0.42780\n","238/238 [==============================] - 9s 36ms/step - loss: 0.4108 - acc: 0.8253 - val_loss: 0.4306 - val_acc: 0.8156\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3993 - acc: 0.8306\n","Epoch 5: val_loss did not improve from 0.42780\n","238/238 [==============================] - 8s 36ms/step - loss: 0.3995 - acc: 0.8304 - val_loss: 0.4334 - val_acc: 0.8161\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3840 - acc: 0.8387\n","Epoch 6: val_loss improved from 0.42780 to 0.42553, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.3841 - acc: 0.8386 - val_loss: 0.4255 - val_acc: 0.8170\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3624 - acc: 0.8507\n","Epoch 7: val_loss did not improve from 0.42553\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3627 - acc: 0.8506 - val_loss: 0.4459 - val_acc: 0.8115\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3396 - acc: 0.8605\n","Epoch 8: val_loss did not improve from 0.42553\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3396 - acc: 0.8603 - val_loss: 0.4559 - val_acc: 0.8105\n","Epoch 9/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3019 - acc: 0.8787\n","Epoch 9: val_loss did not improve from 0.42553\n","238/238 [==============================] - 9s 37ms/step - loss: 0.3022 - acc: 0.8784 - val_loss: 0.5048 - val_acc: 0.7976\n","0.7070462238764318 0.3702557239084898 0.827736890524379 0.22060353798126953\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2963 - acc: 0.9177\n","Epoch 1: val_loss improved from inf to 0.27428, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2966 - acc: 0.9177 - val_loss: 0.2743 - val_acc: 0.9242\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2581 - acc: 0.9217\n","Epoch 2: val_loss improved from 0.27428 to 0.26341, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 36ms/step - loss: 0.2580 - acc: 0.9218 - val_loss: 0.2634 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2481 - acc: 0.9221\n","Epoch 3: val_loss improved from 0.26341 to 0.25868, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2482 - acc: 0.9221 - val_loss: 0.2587 - val_acc: 0.9247\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2354 - acc: 0.9224\n","Epoch 4: val_loss improved from 0.25868 to 0.25482, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2361 - acc: 0.9222 - val_loss: 0.2548 - val_acc: 0.9242\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2256 - acc: 0.9238\n","Epoch 5: val_loss did not improve from 0.25482\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2255 - acc: 0.9238 - val_loss: 0.2594 - val_acc: 0.9214\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9271\n","Epoch 6: val_loss did not improve from 0.25482\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2124 - acc: 0.9272 - val_loss: 0.2666 - val_acc: 0.9210\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1957 - acc: 0.9313\n","Epoch 7: val_loss did not improve from 0.25482\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1955 - acc: 0.9314 - val_loss: 0.2751 - val_acc: 0.9210\n","0.7325307215554705 0.21325596516330841 0.9185832566697332 0.0111731843575419\n","Iteration number:  5\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2851 - acc: 0.9040\n","Epoch 1: val_loss improved from inf to 0.25138, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2852 - acc: 0.9039 - val_loss: 0.2514 - val_acc: 0.9145\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2416 - acc: 0.9134\n","Epoch 2: val_loss improved from 0.25138 to 0.23668, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.2414 - acc: 0.9134 - val_loss: 0.2367 - val_acc: 0.9131\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2244 - acc: 0.9201\n","Epoch 3: val_loss improved from 0.23668 to 0.23169, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2240 - acc: 0.9202 - val_loss: 0.2317 - val_acc: 0.9173\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2093 - acc: 0.9223\n","Epoch 4: val_loss did not improve from 0.23169\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2095 - acc: 0.9222 - val_loss: 0.2319 - val_acc: 0.9131\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1934 - acc: 0.9279\n","Epoch 5: val_loss did not improve from 0.23169\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1936 - acc: 0.9278 - val_loss: 0.2398 - val_acc: 0.9117\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1795 - acc: 0.9339\n","Epoch 6: val_loss did not improve from 0.23169\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1796 - acc: 0.9338 - val_loss: 0.2484 - val_acc: 0.9131\n","0.8774495550268746 0.5810402320624042 0.9160533578656854 0.432348367029549\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2475 - acc: 0.9254\n","Epoch 1: val_loss improved from inf to 0.18161, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 12s 38ms/step - loss: 0.2470 - acc: 0.9256 - val_loss: 0.1816 - val_acc: 0.9409\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1793 - acc: 0.9419\n","Epoch 2: val_loss improved from 0.18161 to 0.17400, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1790 - acc: 0.9420 - val_loss: 0.1740 - val_acc: 0.9413\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1649 - acc: 0.9455\n","Epoch 3: val_loss improved from 0.17400 to 0.17293, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1647 - acc: 0.9455 - val_loss: 0.1729 - val_acc: 0.9418\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9494\n","Epoch 4: val_loss improved from 0.17293 to 0.17016, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1518 - acc: 0.9493 - val_loss: 0.1702 - val_acc: 0.9427\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1365 - acc: 0.9535\n","Epoch 5: val_loss did not improve from 0.17016\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1366 - acc: 0.9535 - val_loss: 0.1714 - val_acc: 0.9427\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9579\n","Epoch 6: val_loss did not improve from 0.17016\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1248 - acc: 0.9579 - val_loss: 0.1864 - val_acc: 0.9344\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9637\n","Epoch 7: val_loss did not improve from 0.17016\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1067 - acc: 0.9637 - val_loss: 0.1927 - val_acc: 0.9372\n","0.8861163131856985 0.5211177105283561 0.9420423183072677 0.46610169491525416\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6885 - acc: 0.6202\n","Epoch 1: val_loss improved from inf to 0.63356, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.6881 - acc: 0.6206 - val_loss: 0.6336 - val_acc: 0.6654\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6309 - acc: 0.6620\n","Epoch 2: val_loss improved from 0.63356 to 0.62404, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.6307 - acc: 0.6620 - val_loss: 0.6240 - val_acc: 0.6650\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6124 - acc: 0.6781\n","Epoch 3: val_loss improved from 0.62404 to 0.62334, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 36ms/step - loss: 0.6123 - acc: 0.6780 - val_loss: 0.6233 - val_acc: 0.6677\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5978 - acc: 0.6894\n","Epoch 4: val_loss improved from 0.62334 to 0.62153, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.5978 - acc: 0.6892 - val_loss: 0.6215 - val_acc: 0.6627\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5822 - acc: 0.7016\n","Epoch 5: val_loss improved from 0.62153 to 0.61924, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.5824 - acc: 0.7013 - val_loss: 0.6192 - val_acc: 0.6742\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5616 - acc: 0.7177\n","Epoch 6: val_loss did not improve from 0.61924\n","238/238 [==============================] - 9s 37ms/step - loss: 0.5616 - acc: 0.7179 - val_loss: 0.6343 - val_acc: 0.6627\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5382 - acc: 0.7368\n","Epoch 7: val_loss did not improve from 0.61924\n","238/238 [==============================] - 9s 36ms/step - loss: 0.5379 - acc: 0.7372 - val_loss: 0.6418 - val_acc: 0.6479\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5100 - acc: 0.7537\n","Epoch 8: val_loss did not improve from 0.61924\n","238/238 [==============================] - 9s 36ms/step - loss: 0.5102 - acc: 0.7536 - val_loss: 0.6505 - val_acc: 0.6585\n","0.7122265238915289 0.6560529111076326 0.6646734130634775 0.6040195545898968\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4793 - acc: 0.8051\n","Epoch 1: val_loss improved from inf to 0.43626, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 12s 39ms/step - loss: 0.4792 - acc: 0.8052 - val_loss: 0.4363 - val_acc: 0.8184\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4363 - acc: 0.8190\n","Epoch 2: val_loss improved from 0.43626 to 0.42687, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4365 - acc: 0.8188 - val_loss: 0.4269 - val_acc: 0.8212\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4234 - acc: 0.8217\n","Epoch 3: val_loss improved from 0.42687 to 0.42683, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.4246 - acc: 0.8211 - val_loss: 0.4268 - val_acc: 0.8147\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4114 - acc: 0.8262\n","Epoch 4: val_loss did not improve from 0.42683\n","238/238 [==============================] - 9s 36ms/step - loss: 0.4116 - acc: 0.8263 - val_loss: 0.4319 - val_acc: 0.8175\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3985 - acc: 0.8301\n","Epoch 5: val_loss did not improve from 0.42683\n","238/238 [==============================] - 9s 36ms/step - loss: 0.3986 - acc: 0.8301 - val_loss: 0.4317 - val_acc: 0.8119\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3826 - acc: 0.8367\n","Epoch 6: val_loss did not improve from 0.42683\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3824 - acc: 0.8367 - val_loss: 0.4318 - val_acc: 0.8249\n","0.7244278951196482 0.3817893069167931 0.8261269549218031 0.24701195219123503\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2920 - acc: 0.9188\n","Epoch 1: val_loss improved from inf to 0.27264, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2918 - acc: 0.9188 - val_loss: 0.2726 - val_acc: 0.9251\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2577 - acc: 0.9221\n","Epoch 2: val_loss improved from 0.27264 to 0.26074, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 36ms/step - loss: 0.2578 - acc: 0.9221 - val_loss: 0.2607 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2466 - acc: 0.9223\n","Epoch 3: val_loss improved from 0.26074 to 0.25786, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2466 - acc: 0.9223 - val_loss: 0.2579 - val_acc: 0.9261\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2386 - acc: 0.9219\n","Epoch 4: val_loss did not improve from 0.25786\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2383 - acc: 0.9221 - val_loss: 0.2628 - val_acc: 0.9251\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2276 - acc: 0.9230\n","Epoch 5: val_loss did not improve from 0.25786\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2274 - acc: 0.9231 - val_loss: 0.2591 - val_acc: 0.9242\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2159 - acc: 0.9264\n","Epoch 6: val_loss did not improve from 0.25786\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2161 - acc: 0.9262 - val_loss: 0.2580 - val_acc: 0.9238\n","0.7163287248654612 0.2159112410689943 0.9178932842686293 0.027247956403269755\n","Iteration number:  6\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2828 - acc: 0.9054\n","Epoch 1: val_loss improved from inf to 0.24450, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.2827 - acc: 0.9054 - val_loss: 0.2445 - val_acc: 0.9131\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2413 - acc: 0.9137\n","Epoch 2: val_loss improved from 0.24450 to 0.22968, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2410 - acc: 0.9139 - val_loss: 0.2297 - val_acc: 0.9168\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2232 - acc: 0.9200\n","Epoch 3: val_loss did not improve from 0.22968\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2232 - acc: 0.9199 - val_loss: 0.2323 - val_acc: 0.9164\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9227\n","Epoch 4: val_loss did not improve from 0.22968\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2108 - acc: 0.9226 - val_loss: 0.2338 - val_acc: 0.9136\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1975 - acc: 0.9260\n","Epoch 5: val_loss did not improve from 0.22968\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1976 - acc: 0.9259 - val_loss: 0.2424 - val_acc: 0.9094\n","0.8688298528504715 0.5642251797436615 0.9135234590616376 0.3974358974358974\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2215 - acc: 0.9328\n","Epoch 1: val_loss improved from inf to 0.17917, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2213 - acc: 0.9328 - val_loss: 0.1792 - val_acc: 0.9432\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1770 - acc: 0.9409\n","Epoch 2: val_loss improved from 0.17917 to 0.16984, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1780 - acc: 0.9406 - val_loss: 0.1698 - val_acc: 0.9427\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1622 - acc: 0.9452\n","Epoch 3: val_loss improved from 0.16984 to 0.16427, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1621 - acc: 0.9453 - val_loss: 0.1643 - val_acc: 0.9436\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9486\n","Epoch 4: val_loss did not improve from 0.16427\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1498 - acc: 0.9487 - val_loss: 0.1667 - val_acc: 0.9418\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9520\n","Epoch 5: val_loss did not improve from 0.16427\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1362 - acc: 0.9520 - val_loss: 0.1718 - val_acc: 0.9413\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9546\n","Epoch 6: val_loss did not improve from 0.16427\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1233 - acc: 0.9545 - val_loss: 0.1827 - val_acc: 0.9344\n","0.8864257065717808 0.5220965105074027 0.9415823367065317 0.40375586854460094\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6829 - acc: 0.6248\n","Epoch 1: val_loss improved from inf to 0.64035, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.6825 - acc: 0.6251 - val_loss: 0.6404 - val_acc: 0.6543\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6335 - acc: 0.6607\n","Epoch 2: val_loss improved from 0.64035 to 0.62817, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6334 - acc: 0.6608 - val_loss: 0.6282 - val_acc: 0.6599\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6120 - acc: 0.6774\n","Epoch 3: val_loss improved from 0.62817 to 0.61819, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6120 - acc: 0.6774 - val_loss: 0.6182 - val_acc: 0.6733\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5980 - acc: 0.6888\n","Epoch 4: val_loss improved from 0.61819 to 0.61359, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.5982 - acc: 0.6885 - val_loss: 0.6136 - val_acc: 0.6608\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5863 - acc: 0.7033\n","Epoch 5: val_loss did not improve from 0.61359\n","238/238 [==============================] - 8s 35ms/step - loss: 0.5862 - acc: 0.7037 - val_loss: 0.6302 - val_acc: 0.6580\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5688 - acc: 0.7131\n","Epoch 6: val_loss did not improve from 0.61359\n","238/238 [==============================] - 8s 35ms/step - loss: 0.5688 - acc: 0.7131 - val_loss: 0.6244 - val_acc: 0.6677\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5481 - acc: 0.7322\n","Epoch 7: val_loss did not improve from 0.61359\n","238/238 [==============================] - 8s 35ms/step - loss: 0.5483 - acc: 0.7321 - val_loss: 0.6480 - val_acc: 0.6520\n","0.704433021282473 0.6462037672964709 0.6683532658693653 0.5846774193548387\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4888 - acc: 0.8076\n","Epoch 1: val_loss improved from inf to 0.44341, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.4887 - acc: 0.8077 - val_loss: 0.4434 - val_acc: 0.8193\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4411 - acc: 0.8179\n","Epoch 2: val_loss improved from 0.44341 to 0.43720, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4409 - acc: 0.8180 - val_loss: 0.4372 - val_acc: 0.8189\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4258 - acc: 0.8223\n","Epoch 3: val_loss improved from 0.43720 to 0.43195, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.4258 - acc: 0.8222 - val_loss: 0.4319 - val_acc: 0.8152\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4120 - acc: 0.8266\n","Epoch 4: val_loss improved from 0.43195 to 0.43126, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.4116 - acc: 0.8269 - val_loss: 0.4313 - val_acc: 0.8161\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3977 - acc: 0.8339\n","Epoch 5: val_loss improved from 0.43126 to 0.42541, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.3976 - acc: 0.8338 - val_loss: 0.4254 - val_acc: 0.8189\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3850 - acc: 0.8373\n","Epoch 6: val_loss did not improve from 0.42541\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3847 - acc: 0.8374 - val_loss: 0.4328 - val_acc: 0.8207\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3617 - acc: 0.8480\n","Epoch 7: val_loss did not improve from 0.42541\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3620 - acc: 0.8478 - val_loss: 0.4430 - val_acc: 0.8101\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3350 - acc: 0.8600\n","Epoch 8: val_loss did not improve from 0.42541\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3350 - acc: 0.8600 - val_loss: 0.4636 - val_acc: 0.7957\n","0.7112184395194115 0.3690859320885621 0.8258969641214351 0.1560758082497213\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2984 - acc: 0.9136\n","Epoch 1: val_loss improved from inf to 0.27212, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2985 - acc: 0.9135 - val_loss: 0.2721 - val_acc: 0.9242\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2578 - acc: 0.9211\n","Epoch 2: val_loss improved from 0.27212 to 0.26781, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2576 - acc: 0.9212 - val_loss: 0.2678 - val_acc: 0.9238\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2468 - acc: 0.9220\n","Epoch 3: val_loss improved from 0.26781 to 0.25785, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2464 - acc: 0.9221 - val_loss: 0.2579 - val_acc: 0.9247\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2342 - acc: 0.9237\n","Epoch 4: val_loss did not improve from 0.25785\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2342 - acc: 0.9237 - val_loss: 0.2660 - val_acc: 0.9219\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2249 - acc: 0.9245\n","Epoch 5: val_loss did not improve from 0.25785\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2251 - acc: 0.9245 - val_loss: 0.2734 - val_acc: 0.9228\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2106 - acc: 0.9271\n","Epoch 6: val_loss did not improve from 0.25785\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2105 - acc: 0.9271 - val_loss: 0.2687 - val_acc: 0.9214\n","0.7393304868163293 0.21852058033203003 0.9192732290708372 0.03835616438356164\n","Iteration number:  7\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2901 - acc: 0.9041\n","Epoch 1: val_loss improved from inf to 0.25370, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 11s 34ms/step - loss: 0.2905 - acc: 0.9037 - val_loss: 0.2537 - val_acc: 0.9048\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2428 - acc: 0.9133\n","Epoch 2: val_loss improved from 0.25370 to 0.23125, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2428 - acc: 0.9133 - val_loss: 0.2312 - val_acc: 0.9150\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2254 - acc: 0.9197\n","Epoch 3: val_loss improved from 0.23125 to 0.23124, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2251 - acc: 0.9198 - val_loss: 0.2312 - val_acc: 0.9140\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9229\n","Epoch 4: val_loss improved from 0.23124 to 0.22613, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2116 - acc: 0.9229 - val_loss: 0.2261 - val_acc: 0.9150\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1969 - acc: 0.9268\n","Epoch 5: val_loss did not improve from 0.22613\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1965 - acc: 0.9269 - val_loss: 0.2418 - val_acc: 0.9131\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1786 - acc: 0.9343\n","Epoch 6: val_loss did not improve from 0.22613\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1789 - acc: 0.9342 - val_loss: 0.2471 - val_acc: 0.9131\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9429\n","Epoch 7: val_loss did not improve from 0.22613\n","238/238 [==============================] - 7s 31ms/step - loss: 0.1603 - acc: 0.9430 - val_loss: 0.2686 - val_acc: 0.9034\n","0.8756289100361266 0.5689859586316459 0.9158233670653174 0.4633431085043988\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2180 - acc: 0.9331\n","Epoch 1: val_loss improved from inf to 0.17272, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.2183 - acc: 0.9330 - val_loss: 0.1727 - val_acc: 0.9422\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1747 - acc: 0.9424\n","Epoch 2: val_loss did not improve from 0.17272\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1747 - acc: 0.9424 - val_loss: 0.1757 - val_acc: 0.9432\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1616 - acc: 0.9445\n","Epoch 3: val_loss did not improve from 0.17272\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1614 - acc: 0.9445 - val_loss: 0.1747 - val_acc: 0.9404\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1494 - acc: 0.9500\n","Epoch 4: val_loss improved from 0.17272 to 0.16499, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1496 - acc: 0.9499 - val_loss: 0.1650 - val_acc: 0.9413\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9519\n","Epoch 5: val_loss did not improve from 0.16499\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1392 - acc: 0.9520 - val_loss: 0.1667 - val_acc: 0.9436\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9573\n","Epoch 6: val_loss did not improve from 0.16499\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1245 - acc: 0.9574 - val_loss: 0.1757 - val_acc: 0.9422\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9633\n","Epoch 7: val_loss did not improve from 0.16499\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1085 - acc: 0.9634 - val_loss: 0.1912 - val_acc: 0.9381\n","0.8824156873761254 0.5114285667099583 0.9418123275068997 0.46055437100213215\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6837 - acc: 0.6220\n","Epoch 1: val_loss improved from inf to 0.63069, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.6835 - acc: 0.6219 - val_loss: 0.6307 - val_acc: 0.6567\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6319 - acc: 0.6601\n","Epoch 2: val_loss improved from 0.63069 to 0.61463, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.6315 - acc: 0.6606 - val_loss: 0.6146 - val_acc: 0.6696\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6140 - acc: 0.6750\n","Epoch 3: val_loss improved from 0.61463 to 0.60945, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.6142 - acc: 0.6747 - val_loss: 0.6094 - val_acc: 0.6784\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5986 - acc: 0.6875\n","Epoch 4: val_loss did not improve from 0.60945\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5986 - acc: 0.6876 - val_loss: 0.6138 - val_acc: 0.6705\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5821 - acc: 0.7035\n","Epoch 5: val_loss did not improve from 0.60945\n","238/238 [==============================] - 8s 32ms/step - loss: 0.5820 - acc: 0.7038 - val_loss: 0.6154 - val_acc: 0.6710\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5649 - acc: 0.7147\n","Epoch 6: val_loss did not improve from 0.60945\n","238/238 [==============================] - 8s 32ms/step - loss: 0.5649 - acc: 0.7146 - val_loss: 0.6110 - val_acc: 0.6779\n","0.6995724946373003 0.6418802657132787 0.6591536338546458 0.5175781249999999\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4828 - acc: 0.8095\n","Epoch 1: val_loss improved from inf to 0.44228, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.4829 - acc: 0.8094 - val_loss: 0.4423 - val_acc: 0.8175\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4397 - acc: 0.8162\n","Epoch 2: val_loss improved from 0.44228 to 0.43671, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.4399 - acc: 0.8161 - val_loss: 0.4367 - val_acc: 0.8184\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4258 - acc: 0.8207\n","Epoch 3: val_loss improved from 0.43671 to 0.42636, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.4257 - acc: 0.8208 - val_loss: 0.4264 - val_acc: 0.8198\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4129 - acc: 0.8256\n","Epoch 4: val_loss did not improve from 0.42636\n","238/238 [==============================] - 8s 32ms/step - loss: 0.4130 - acc: 0.8258 - val_loss: 0.4283 - val_acc: 0.8165\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3980 - acc: 0.8317\n","Epoch 5: val_loss did not improve from 0.42636\n","238/238 [==============================] - 8s 32ms/step - loss: 0.3981 - acc: 0.8316 - val_loss: 0.4294 - val_acc: 0.8244\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3838 - acc: 0.8377\n","Epoch 6: val_loss did not improve from 0.42636\n","238/238 [==============================] - 8s 32ms/step - loss: 0.3837 - acc: 0.8378 - val_loss: 0.4388 - val_acc: 0.8193\n","0.71837155800795 0.38008689417178326 0.8249770009199632 0.21788283658787252\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2958 - acc: 0.9169\n","Epoch 1: val_loss improved from inf to 0.27249, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 10s 33ms/step - loss: 0.2960 - acc: 0.9168 - val_loss: 0.2725 - val_acc: 0.9233\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2589 - acc: 0.9217\n","Epoch 2: val_loss improved from 0.27249 to 0.26665, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2587 - acc: 0.9217 - val_loss: 0.2667 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2457 - acc: 0.9223\n","Epoch 3: val_loss improved from 0.26665 to 0.26033, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 7s 31ms/step - loss: 0.2462 - acc: 0.9222 - val_loss: 0.2603 - val_acc: 0.9256\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2368 - acc: 0.9233\n","Epoch 4: val_loss did not improve from 0.26033\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2368 - acc: 0.9233 - val_loss: 0.2621 - val_acc: 0.9233\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2255 - acc: 0.9243\n","Epoch 5: val_loss did not improve from 0.26033\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2251 - acc: 0.9245 - val_loss: 0.2619 - val_acc: 0.9256\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2127 - acc: 0.9270\n","Epoch 6: val_loss did not improve from 0.26033\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2125 - acc: 0.9271 - val_loss: 0.2736 - val_acc: 0.9196\n","0.7382721904483124 0.21418602803444087 0.9181232750689973 0.00558659217877095\n","Iteration number:  8\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2944 - acc: 0.8997\n","Epoch 1: val_loss improved from inf to 0.24398, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.2940 - acc: 0.8998 - val_loss: 0.2440 - val_acc: 0.9168\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2420 - acc: 0.9148\n","Epoch 2: val_loss improved from 0.24398 to 0.23437, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2420 - acc: 0.9148 - val_loss: 0.2344 - val_acc: 0.9154\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2229 - acc: 0.9196\n","Epoch 3: val_loss did not improve from 0.23437\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2235 - acc: 0.9194 - val_loss: 0.2421 - val_acc: 0.9177\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2090 - acc: 0.9236\n","Epoch 4: val_loss did not improve from 0.23437\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2091 - acc: 0.9235 - val_loss: 0.2441 - val_acc: 0.9127\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1941 - acc: 0.9291\n","Epoch 5: val_loss did not improve from 0.23437\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1941 - acc: 0.9291 - val_loss: 0.2469 - val_acc: 0.9067\n","0.8717293373865539 0.5795685068906652 0.9169733210671573 0.4555052790346908\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2295 - acc: 0.9299\n","Epoch 1: val_loss improved from inf to 0.18514, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 11s 35ms/step - loss: 0.2295 - acc: 0.9299 - val_loss: 0.1851 - val_acc: 0.9445\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1778 - acc: 0.9422\n","Epoch 2: val_loss improved from 0.18514 to 0.17414, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1779 - acc: 0.9422 - val_loss: 0.1741 - val_acc: 0.9432\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1629 - acc: 0.9455\n","Epoch 3: val_loss improved from 0.17414 to 0.17053, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1628 - acc: 0.9455 - val_loss: 0.1705 - val_acc: 0.9436\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1495 - acc: 0.9500\n","Epoch 4: val_loss improved from 0.17053 to 0.16811, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1499 - acc: 0.9499 - val_loss: 0.1681 - val_acc: 0.9436\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9508\n","Epoch 5: val_loss did not improve from 0.16811\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1388 - acc: 0.9509 - val_loss: 0.1742 - val_acc: 0.9418\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1270 - acc: 0.9560\n","Epoch 6: val_loss did not improve from 0.16811\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1270 - acc: 0.9561 - val_loss: 0.1774 - val_acc: 0.9404\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9612\n","Epoch 7: val_loss did not improve from 0.16811\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1115 - acc: 0.9612 - val_loss: 0.1880 - val_acc: 0.9432\n","0.8799936014482576 0.5223803073647293 0.9411223551057958 0.4128440366972477\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6851 - acc: 0.6224\n","Epoch 1: val_loss improved from inf to 0.62641, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 33ms/step - loss: 0.6850 - acc: 0.6222 - val_loss: 0.6264 - val_acc: 0.6677\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6317 - acc: 0.6617\n","Epoch 2: val_loss did not improve from 0.62641\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6315 - acc: 0.6619 - val_loss: 0.6283 - val_acc: 0.6654\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6121 - acc: 0.6764\n","Epoch 3: val_loss improved from 0.62641 to 0.61501, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6120 - acc: 0.6763 - val_loss: 0.6150 - val_acc: 0.6793\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5986 - acc: 0.6862\n","Epoch 4: val_loss improved from 0.61501 to 0.61307, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5983 - acc: 0.6864 - val_loss: 0.6131 - val_acc: 0.6659\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5834 - acc: 0.7056\n","Epoch 5: val_loss did not improve from 0.61307\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5834 - acc: 0.7057 - val_loss: 0.6171 - val_acc: 0.6673\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5653 - acc: 0.7157\n","Epoch 6: val_loss did not improve from 0.61307\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5655 - acc: 0.7155 - val_loss: 0.6242 - val_acc: 0.6677\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5408 - acc: 0.7365\n","Epoch 7: val_loss did not improve from 0.61307\n","238/238 [==============================] - 7s 31ms/step - loss: 0.5405 - acc: 0.7367 - val_loss: 0.6439 - val_acc: 0.6627\n","0.7007056751822455 0.6496200390469908 0.6609935602575897 0.542803970223325\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4770 - acc: 0.8068\n","Epoch 1: val_loss improved from inf to 0.44497, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.4775 - acc: 0.8065 - val_loss: 0.4450 - val_acc: 0.8175\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4406 - acc: 0.8171\n","Epoch 2: val_loss improved from 0.44497 to 0.43533, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4407 - acc: 0.8171 - val_loss: 0.4353 - val_acc: 0.8184\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4244 - acc: 0.8209\n","Epoch 3: val_loss improved from 0.43533 to 0.42699, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4239 - acc: 0.8213 - val_loss: 0.4270 - val_acc: 0.8212\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4128 - acc: 0.8246\n","Epoch 4: val_loss improved from 0.42699 to 0.42616, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4127 - acc: 0.8246 - val_loss: 0.4262 - val_acc: 0.8152\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3974 - acc: 0.8309\n","Epoch 5: val_loss did not improve from 0.42616\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3972 - acc: 0.8309 - val_loss: 0.4290 - val_acc: 0.8235\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3831 - acc: 0.8349\n","Epoch 6: val_loss did not improve from 0.42616\n","238/238 [==============================] - 8s 33ms/step - loss: 0.3831 - acc: 0.8347 - val_loss: 0.4433 - val_acc: 0.8170\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3626 - acc: 0.8501\n","Epoch 7: val_loss did not improve from 0.42616\n","238/238 [==============================] - 8s 33ms/step - loss: 0.3624 - acc: 0.8500 - val_loss: 0.4411 - val_acc: 0.8161\n","0.717746891488774 0.37572181634149815 0.8261269549218031 0.22540983606557377\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2904 - acc: 0.9163\n","Epoch 1: val_loss improved from inf to 0.26304, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.2906 - acc: 0.9163 - val_loss: 0.2630 - val_acc: 0.9247\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2585 - acc: 0.9206\n","Epoch 2: val_loss improved from 0.26304 to 0.25790, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2582 - acc: 0.9208 - val_loss: 0.2579 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2444 - acc: 0.9221\n","Epoch 3: val_loss improved from 0.25790 to 0.25758, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2446 - acc: 0.9221 - val_loss: 0.2576 - val_acc: 0.9247\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2349 - acc: 0.9225\n","Epoch 4: val_loss did not improve from 0.25758\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2352 - acc: 0.9223 - val_loss: 0.2631 - val_acc: 0.9242\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2258 - acc: 0.9244\n","Epoch 5: val_loss did not improve from 0.25758\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2258 - acc: 0.9245 - val_loss: 0.2621 - val_acc: 0.9251\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2121 - acc: 0.9266\n","Epoch 6: val_loss did not improve from 0.25758\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2125 - acc: 0.9263 - val_loss: 0.2718 - val_acc: 0.9201\n","0.7283928812681544 0.2018147284116248 0.9178932842686293 0.005571030640668524\n","Iteration number:  9\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3113 - acc: 0.8954\n","Epoch 1: val_loss improved from inf to 0.24809, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 33ms/step - loss: 0.3108 - acc: 0.8956 - val_loss: 0.2481 - val_acc: 0.9094\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2438 - acc: 0.9163\n","Epoch 2: val_loss improved from 0.24809 to 0.23643, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2441 - acc: 0.9163 - val_loss: 0.2364 - val_acc: 0.9150\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2262 - acc: 0.9188\n","Epoch 3: val_loss did not improve from 0.23643\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2261 - acc: 0.9188 - val_loss: 0.2373 - val_acc: 0.9127\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2109 - acc: 0.9243\n","Epoch 4: val_loss improved from 0.23643 to 0.23275, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 7s 31ms/step - loss: 0.2113 - acc: 0.9242 - val_loss: 0.2328 - val_acc: 0.9117\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1966 - acc: 0.9289\n","Epoch 5: val_loss did not improve from 0.23275\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1963 - acc: 0.9290 - val_loss: 0.2422 - val_acc: 0.9080\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1821 - acc: 0.9326\n","Epoch 6: val_loss did not improve from 0.23275\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1824 - acc: 0.9326 - val_loss: 0.2396 - val_acc: 0.9145\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1650 - acc: 0.9407\n","Epoch 7: val_loss did not improve from 0.23275\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1649 - acc: 0.9407 - val_loss: 0.2447 - val_acc: 0.9122\n","0.8754714071724381 0.5717546333470714 0.9130634774609016 0.48076923076923084\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2183 - acc: 0.9335\n","Epoch 1: val_loss improved from inf to 0.16957, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 33ms/step - loss: 0.2182 - acc: 0.9336 - val_loss: 0.1696 - val_acc: 0.9390\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1780 - acc: 0.9426\n","Epoch 2: val_loss did not improve from 0.16957\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1776 - acc: 0.9428 - val_loss: 0.1704 - val_acc: 0.9445\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1625 - acc: 0.9448\n","Epoch 3: val_loss improved from 0.16957 to 0.16663, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1625 - acc: 0.9447 - val_loss: 0.1666 - val_acc: 0.9436\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9489\n","Epoch 4: val_loss improved from 0.16663 to 0.16572, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1494 - acc: 0.9489 - val_loss: 0.1657 - val_acc: 0.9390\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9517\n","Epoch 5: val_loss did not improve from 0.16572\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1376 - acc: 0.9517 - val_loss: 0.1705 - val_acc: 0.9390\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9573\n","Epoch 6: val_loss did not improve from 0.16572\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1239 - acc: 0.9574 - val_loss: 0.1732 - val_acc: 0.9450\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9620\n","Epoch 7: val_loss did not improve from 0.16572\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1076 - acc: 0.9620 - val_loss: 0.1879 - val_acc: 0.9335\n","0.8794044665012406 0.514758903985204 0.9411223551057958 0.46443514644351463\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6902 - acc: 0.6165\n","Epoch 1: val_loss improved from inf to 0.64172, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.6904 - acc: 0.6162 - val_loss: 0.6417 - val_acc: 0.6423\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6335 - acc: 0.6600\n","Epoch 2: val_loss improved from 0.64172 to 0.62027, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.6334 - acc: 0.6601 - val_loss: 0.6203 - val_acc: 0.6668\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6147 - acc: 0.6772\n","Epoch 3: val_loss improved from 0.62027 to 0.61634, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.6145 - acc: 0.6775 - val_loss: 0.6163 - val_acc: 0.6761\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5971 - acc: 0.6898\n","Epoch 4: val_loss improved from 0.61634 to 0.61430, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5975 - acc: 0.6895 - val_loss: 0.6143 - val_acc: 0.6673\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5828 - acc: 0.7040\n","Epoch 5: val_loss did not improve from 0.61430\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5824 - acc: 0.7045 - val_loss: 0.6190 - val_acc: 0.6668\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5649 - acc: 0.7162\n","Epoch 6: val_loss did not improve from 0.61430\n","238/238 [==============================] - 8s 32ms/step - loss: 0.5649 - acc: 0.7162 - val_loss: 0.6311 - val_acc: 0.6622\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5409 - acc: 0.7322\n","Epoch 7: val_loss did not improve from 0.61430\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5407 - acc: 0.7322 - val_loss: 0.6441 - val_acc: 0.6622\n","0.6978178020052397 0.6421336682598131 0.656623735050598 0.583310075355847\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4838 - acc: 0.8043\n","Epoch 1: val_loss improved from inf to 0.44285, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.4839 - acc: 0.8042 - val_loss: 0.4429 - val_acc: 0.8175\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4402 - acc: 0.8167\n","Epoch 2: val_loss improved from 0.44285 to 0.43818, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4400 - acc: 0.8167 - val_loss: 0.4382 - val_acc: 0.8170\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4231 - acc: 0.8203\n","Epoch 3: val_loss improved from 0.43818 to 0.42723, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4233 - acc: 0.8203 - val_loss: 0.4272 - val_acc: 0.8221\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4123 - acc: 0.8247\n","Epoch 4: val_loss did not improve from 0.42723\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4124 - acc: 0.8247 - val_loss: 0.4287 - val_acc: 0.8202\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3987 - acc: 0.8292\n","Epoch 5: val_loss improved from 0.42723 to 0.42386, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.3988 - acc: 0.8292 - val_loss: 0.4239 - val_acc: 0.8170\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3845 - acc: 0.8368\n","Epoch 6: val_loss did not improve from 0.42386\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3844 - acc: 0.8368 - val_loss: 0.4320 - val_acc: 0.8212\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3619 - acc: 0.8449\n","Epoch 7: val_loss did not improve from 0.42386\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3618 - acc: 0.8451 - val_loss: 0.4519 - val_acc: 0.8068\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3329 - acc: 0.8629\n","Epoch 8: val_loss did not improve from 0.42386\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3326 - acc: 0.8631 - val_loss: 0.4639 - val_acc: 0.7976\n","0.7187912558255213 0.3729527153682848 0.8201471941122355 0.2705223880597015\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2989 - acc: 0.9159\n","Epoch 1: val_loss improved from inf to 0.26769, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.2989 - acc: 0.9159 - val_loss: 0.2677 - val_acc: 0.9228\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2570 - acc: 0.9221\n","Epoch 2: val_loss improved from 0.26769 to 0.25935, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2573 - acc: 0.9219 - val_loss: 0.2593 - val_acc: 0.9251\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2447 - acc: 0.9218\n","Epoch 3: val_loss did not improve from 0.25935\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2447 - acc: 0.9218 - val_loss: 0.2607 - val_acc: 0.9247\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2381 - acc: 0.9231\n","Epoch 4: val_loss improved from 0.25935 to 0.25512, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2380 - acc: 0.9232 - val_loss: 0.2551 - val_acc: 0.9247\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2252 - acc: 0.9248\n","Epoch 5: val_loss did not improve from 0.25512\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2259 - acc: 0.9244 - val_loss: 0.2655 - val_acc: 0.9228\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2132 - acc: 0.9267\n","Epoch 6: val_loss did not improve from 0.25512\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2134 - acc: 0.9267 - val_loss: 0.2819 - val_acc: 0.9247\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1985 - acc: 0.9313\n","Epoch 7: val_loss did not improve from 0.25512\n","238/238 [==============================] - 8s 36ms/step - loss: 0.1983 - acc: 0.9313 - val_loss: 0.2789 - val_acc: 0.9173\n","0.7220733602035532 0.20905301867714945 0.9185832566697332 0.0111731843575419\n","Iteration number:  10\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2912 - acc: 0.9004\n","Epoch 1: val_loss improved from inf to 0.24316, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2908 - acc: 0.9006 - val_loss: 0.2432 - val_acc: 0.9164\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2435 - acc: 0.9139\n","Epoch 2: val_loss improved from 0.24316 to 0.23773, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2433 - acc: 0.9140 - val_loss: 0.2377 - val_acc: 0.9145\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2229 - acc: 0.9196\n","Epoch 3: val_loss improved from 0.23773 to 0.22514, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2232 - acc: 0.9194 - val_loss: 0.2251 - val_acc: 0.9164\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2114 - acc: 0.9228\n","Epoch 4: val_loss did not improve from 0.22514\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2119 - acc: 0.9226 - val_loss: 0.2291 - val_acc: 0.9173\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1970 - acc: 0.9258\n","Epoch 5: val_loss did not improve from 0.22514\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1966 - acc: 0.9261 - val_loss: 0.2327 - val_acc: 0.9164\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1825 - acc: 0.9339\n","Epoch 6: val_loss did not improve from 0.22514\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1825 - acc: 0.9339 - val_loss: 0.2408 - val_acc: 0.9108\n","0.8711621067935501 0.5663859007598451 0.9137534498620056 0.4509516837481698\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2264 - acc: 0.9303\n","Epoch 1: val_loss improved from inf to 0.17842, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.2262 - acc: 0.9304 - val_loss: 0.1784 - val_acc: 0.9427\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9432\n","Epoch 2: val_loss did not improve from 0.17842\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1767 - acc: 0.9433 - val_loss: 0.1788 - val_acc: 0.9385\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1636 - acc: 0.9443\n","Epoch 3: val_loss improved from 0.17842 to 0.16766, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1632 - acc: 0.9445 - val_loss: 0.1677 - val_acc: 0.9404\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9482\n","Epoch 4: val_loss improved from 0.16766 to 0.16734, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1505 - acc: 0.9481 - val_loss: 0.1673 - val_acc: 0.9385\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9515\n","Epoch 5: val_loss did not improve from 0.16734\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1386 - acc: 0.9516 - val_loss: 0.1772 - val_acc: 0.9427\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9564\n","Epoch 6: val_loss did not improve from 0.16734\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1273 - acc: 0.9563 - val_loss: 0.1805 - val_acc: 0.9381\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9624\n","Epoch 7: val_loss did not improve from 0.16734\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1086 - acc: 0.9623 - val_loss: 0.1953 - val_acc: 0.9362\n","0.8859832701281272 0.5077417646196416 0.937442502299908 0.456\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6828 - acc: 0.6197\n","Epoch 1: val_loss improved from inf to 0.63762, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.6828 - acc: 0.6194 - val_loss: 0.6376 - val_acc: 0.6613\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6298 - acc: 0.6609\n","Epoch 2: val_loss improved from 0.63762 to 0.62272, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.6302 - acc: 0.6607 - val_loss: 0.6227 - val_acc: 0.6710\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6125 - acc: 0.6755\n","Epoch 3: val_loss improved from 0.62272 to 0.61934, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.6130 - acc: 0.6753 - val_loss: 0.6193 - val_acc: 0.6682\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5972 - acc: 0.6895\n","Epoch 4: val_loss improved from 0.61934 to 0.61805, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5974 - acc: 0.6893 - val_loss: 0.6181 - val_acc: 0.6627\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5822 - acc: 0.7048\n","Epoch 5: val_loss did not improve from 0.61805\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5822 - acc: 0.7048 - val_loss: 0.6241 - val_acc: 0.6687\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5649 - acc: 0.7188\n","Epoch 6: val_loss improved from 0.61805 to 0.61468, saving model to avg-fasttext-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5648 - acc: 0.7188 - val_loss: 0.6147 - val_acc: 0.6788\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5415 - acc: 0.7348\n","Epoch 7: val_loss did not improve from 0.61468\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5415 - acc: 0.7349 - val_loss: 0.6327 - val_acc: 0.6580\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5163 - acc: 0.7478\n","Epoch 8: val_loss did not improve from 0.61468\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5167 - acc: 0.7476 - val_loss: 0.6437 - val_acc: 0.6636\n","Epoch 9/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4797 - acc: 0.7781\n","Epoch 9: val_loss did not improve from 0.61468\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4797 - acc: 0.7780 - val_loss: 0.6829 - val_acc: 0.6543\n","0.7069805734312216 0.6472133183265389 0.6598436062557498 0.5801873403349418\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4767 - acc: 0.8079\n","Epoch 1: val_loss improved from inf to 0.44552, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.4765 - acc: 0.8079 - val_loss: 0.4455 - val_acc: 0.8156\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4402 - acc: 0.8160\n","Epoch 2: val_loss improved from 0.44552 to 0.42930, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4399 - acc: 0.8162 - val_loss: 0.4293 - val_acc: 0.8105\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4233 - acc: 0.8209\n","Epoch 3: val_loss did not improve from 0.42930\n","238/238 [==============================] - 7s 31ms/step - loss: 0.4234 - acc: 0.8209 - val_loss: 0.4310 - val_acc: 0.8161\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4127 - acc: 0.8267\n","Epoch 4: val_loss improved from 0.42930 to 0.42724, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4128 - acc: 0.8268 - val_loss: 0.4272 - val_acc: 0.8216\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4013 - acc: 0.8308\n","Epoch 5: val_loss improved from 0.42724 to 0.42195, saving model to avg-fasttext-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4013 - acc: 0.8308 - val_loss: 0.4220 - val_acc: 0.8184\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3841 - acc: 0.8358\n","Epoch 6: val_loss did not improve from 0.42195\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3841 - acc: 0.8357 - val_loss: 0.4388 - val_acc: 0.8184\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3607 - acc: 0.8507\n","Epoch 7: val_loss did not improve from 0.42195\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3608 - acc: 0.8506 - val_loss: 0.4593 - val_acc: 0.8064\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3392 - acc: 0.8625\n","Epoch 8: val_loss did not improve from 0.42195\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3389 - acc: 0.8628 - val_loss: 0.4613 - val_acc: 0.8064\n","0.7248869960914963 0.38656743632607915 0.8300367985280589 0.19411123227917124\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2978 - acc: 0.9152\n","Epoch 1: val_loss improved from inf to 0.27416, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2986 - acc: 0.9150 - val_loss: 0.2742 - val_acc: 0.9242\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2591 - acc: 0.9210\n","Epoch 2: val_loss improved from 0.27416 to 0.26984, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2592 - acc: 0.9210 - val_loss: 0.2698 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2441 - acc: 0.9227\n","Epoch 3: val_loss improved from 0.26984 to 0.25751, saving model to avg-fasttext-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2443 - acc: 0.9225 - val_loss: 0.2575 - val_acc: 0.9251\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2355 - acc: 0.9233\n","Epoch 4: val_loss did not improve from 0.25751\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2357 - acc: 0.9231 - val_loss: 0.2632 - val_acc: 0.9242\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2247 - acc: 0.9237\n","Epoch 5: val_loss did not improve from 0.25751\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2243 - acc: 0.9238 - val_loss: 0.2755 - val_acc: 0.9242\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2110 - acc: 0.9272\n","Epoch 6: val_loss did not improve from 0.25751\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2107 - acc: 0.9273 - val_loss: 0.2749 - val_acc: 0.9182\n","0.7334810069577357 0.20332350796005239 0.9181232750689973 0.00558659217877095\n","Embedding:  concat\n","=============================\n","Iteration number:  1\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2877 - acc: 0.9033\n","Epoch 1: val_loss improved from inf to 0.24298, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.2876 - acc: 0.9034 - val_loss: 0.2430 - val_acc: 0.9113\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2393 - acc: 0.9152\n","Epoch 2: val_loss improved from 0.24298 to 0.23769, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2393 - acc: 0.9152 - val_loss: 0.2377 - val_acc: 0.9164\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2249 - acc: 0.9176\n","Epoch 3: val_loss improved from 0.23769 to 0.22648, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2250 - acc: 0.9175 - val_loss: 0.2265 - val_acc: 0.9113\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2117 - acc: 0.9244\n","Epoch 4: val_loss did not improve from 0.22648\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2126 - acc: 0.9239 - val_loss: 0.2339 - val_acc: 0.9127\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1980 - acc: 0.9279\n","Epoch 5: val_loss did not improve from 0.22648\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1985 - acc: 0.9275 - val_loss: 0.2414 - val_acc: 0.9062\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1814 - acc: 0.9341\n","Epoch 6: val_loss did not improve from 0.22648\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1814 - acc: 0.9342 - val_loss: 0.2385 - val_acc: 0.9140\n","0.8748890320733105 0.5769054991191438 0.9169733210671573 0.48502139800285304\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2166 - acc: 0.9333\n","Epoch 1: val_loss improved from inf to 0.17943, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.2166 - acc: 0.9332 - val_loss: 0.1794 - val_acc: 0.9432\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1750 - acc: 0.9436\n","Epoch 2: val_loss did not improve from 0.17943\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1749 - acc: 0.9436 - val_loss: 0.1816 - val_acc: 0.9445\n","Epoch 3/100\n","238/238 [==============================] - ETA: 0s - loss: 0.1627 - acc: 0.9445\n","Epoch 3: val_loss improved from 0.17943 to 0.16768, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1627 - acc: 0.9445 - val_loss: 0.1677 - val_acc: 0.9432\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9478\n","Epoch 4: val_loss did not improve from 0.16768\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1491 - acc: 0.9478 - val_loss: 0.1683 - val_acc: 0.9418\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9537\n","Epoch 5: val_loss did not improve from 0.16768\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1338 - acc: 0.9537 - val_loss: 0.1710 - val_acc: 0.9404\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9567\n","Epoch 6: val_loss did not improve from 0.16768\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1221 - acc: 0.9568 - val_loss: 0.1818 - val_acc: 0.9344\n","0.8861877116594098 0.5211430404010308 0.9434222631094756 0.4605263157894736\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6868 - acc: 0.6166\n","Epoch 1: val_loss improved from inf to 0.63097, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.6865 - acc: 0.6170 - val_loss: 0.6310 - val_acc: 0.6673\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6335 - acc: 0.6614\n","Epoch 2: val_loss improved from 0.63097 to 0.62743, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.6332 - acc: 0.6615 - val_loss: 0.6274 - val_acc: 0.6682\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6134 - acc: 0.6748\n","Epoch 3: val_loss improved from 0.62743 to 0.61514, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6139 - acc: 0.6742 - val_loss: 0.6151 - val_acc: 0.6751\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5996 - acc: 0.6877\n","Epoch 4: val_loss improved from 0.61514 to 0.61098, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6000 - acc: 0.6872 - val_loss: 0.6110 - val_acc: 0.6844\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5824 - acc: 0.7044\n","Epoch 5: val_loss did not improve from 0.61098\n","238/238 [==============================] - 8s 35ms/step - loss: 0.5825 - acc: 0.7043 - val_loss: 0.6208 - val_acc: 0.6659\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5676 - acc: 0.7128\n","Epoch 6: val_loss did not improve from 0.61098\n","238/238 [==============================] - 8s 35ms/step - loss: 0.5676 - acc: 0.7127 - val_loss: 0.6323 - val_acc: 0.6664\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5453 - acc: 0.7292\n","Epoch 7: val_loss did not improve from 0.61098\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5455 - acc: 0.7288 - val_loss: 0.6305 - val_acc: 0.6719\n","0.7064058905534478 0.6502817373781998 0.6674333026678932 0.5868571428571429\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4846 - acc: 0.8070\n","Epoch 1: val_loss improved from inf to 0.44295, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.4849 - acc: 0.8068 - val_loss: 0.4430 - val_acc: 0.8147\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4399 - acc: 0.8161\n","Epoch 2: val_loss improved from 0.44295 to 0.43190, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4403 - acc: 0.8158 - val_loss: 0.4319 - val_acc: 0.8175\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4220 - acc: 0.8226\n","Epoch 3: val_loss did not improve from 0.43190\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4219 - acc: 0.8225 - val_loss: 0.4349 - val_acc: 0.8170\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4089 - acc: 0.8270\n","Epoch 4: val_loss did not improve from 0.43190\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4094 - acc: 0.8269 - val_loss: 0.4326 - val_acc: 0.8216\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3953 - acc: 0.8316\n","Epoch 5: val_loss improved from 0.43190 to 0.42680, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3952 - acc: 0.8317 - val_loss: 0.4268 - val_acc: 0.8124\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3801 - acc: 0.8410\n","Epoch 6: val_loss did not improve from 0.42680\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3797 - acc: 0.8412 - val_loss: 0.4272 - val_acc: 0.8216\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3567 - acc: 0.8501\n","Epoch 7: val_loss did not improve from 0.42680\n","238/238 [==============================] - 8s 33ms/step - loss: 0.3572 - acc: 0.8498 - val_loss: 0.4348 - val_acc: 0.8165\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3295 - acc: 0.8650\n","Epoch 8: val_loss did not improve from 0.42680\n","238/238 [==============================] - 8s 35ms/step - loss: 0.3299 - acc: 0.8648 - val_loss: 0.4679 - val_acc: 0.8110\n","0.7119116096875366 0.3617393347050367 0.8171573137074517 0.2590866728797763\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2925 - acc: 0.9149\n","Epoch 1: val_loss improved from inf to 0.27226, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 12s 40ms/step - loss: 0.2922 - acc: 0.9150 - val_loss: 0.2723 - val_acc: 0.9224\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2578 - acc: 0.9219\n","Epoch 2: val_loss improved from 0.27226 to 0.26421, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 38ms/step - loss: 0.2580 - acc: 0.9217 - val_loss: 0.2642 - val_acc: 0.9233\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2456 - acc: 0.9217\n","Epoch 3: val_loss improved from 0.26421 to 0.26381, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 38ms/step - loss: 0.2461 - acc: 0.9214 - val_loss: 0.2638 - val_acc: 0.9242\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2381 - acc: 0.9229\n","Epoch 4: val_loss improved from 0.26381 to 0.25613, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 38ms/step - loss: 0.2381 - acc: 0.9228 - val_loss: 0.2561 - val_acc: 0.9256\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2254 - acc: 0.9234\n","Epoch 5: val_loss did not improve from 0.25613\n","238/238 [==============================] - 8s 36ms/step - loss: 0.2253 - acc: 0.9235 - val_loss: 0.2673 - val_acc: 0.9228\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9272\n","Epoch 6: val_loss did not improve from 0.25613\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2114 - acc: 0.9273 - val_loss: 0.2737 - val_acc: 0.9187\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1959 - acc: 0.9314\n","Epoch 7: val_loss did not improve from 0.25613\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1961 - acc: 0.9315 - val_loss: 0.2769 - val_acc: 0.9201\n","0.7290944248046656 0.21884021006678245 0.9183532658693653 0.022038567493112945\n","Iteration number:  2\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3014 - acc: 0.9003\n","Epoch 1: val_loss improved from inf to 0.24747, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.3017 - acc: 0.9002 - val_loss: 0.2475 - val_acc: 0.9131\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2446 - acc: 0.9138\n","Epoch 2: val_loss improved from 0.24747 to 0.24427, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.2448 - acc: 0.9138 - val_loss: 0.2443 - val_acc: 0.9117\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2264 - acc: 0.9185\n","Epoch 3: val_loss improved from 0.24427 to 0.23280, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 38ms/step - loss: 0.2262 - acc: 0.9186 - val_loss: 0.2328 - val_acc: 0.9140\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9237\n","Epoch 4: val_loss improved from 0.23280 to 0.23242, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2103 - acc: 0.9239 - val_loss: 0.2324 - val_acc: 0.9164\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1975 - acc: 0.9260\n","Epoch 5: val_loss did not improve from 0.23242\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1976 - acc: 0.9259 - val_loss: 0.2344 - val_acc: 0.9062\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9340\n","Epoch 6: val_loss did not improve from 0.23242\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1812 - acc: 0.9340 - val_loss: 0.2523 - val_acc: 0.9140\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1630 - acc: 0.9406\n","Epoch 7: val_loss did not improve from 0.23242\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1630 - acc: 0.9406 - val_loss: 0.2485 - val_acc: 0.9108\n","0.8747813684025024 0.5863905577181773 0.9160533578656854 0.4527736131934033\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2220 - acc: 0.9325\n","Epoch 1: val_loss improved from inf to 0.18270, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.2223 - acc: 0.9323 - val_loss: 0.1827 - val_acc: 0.9385\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1765 - acc: 0.9422\n","Epoch 2: val_loss improved from 0.18270 to 0.17121, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 38ms/step - loss: 0.1764 - acc: 0.9422 - val_loss: 0.1712 - val_acc: 0.9395\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1612 - acc: 0.9451\n","Epoch 3: val_loss improved from 0.17121 to 0.17078, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1612 - acc: 0.9451 - val_loss: 0.1708 - val_acc: 0.9422\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9490\n","Epoch 4: val_loss did not improve from 0.17078\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1498 - acc: 0.9489 - val_loss: 0.1724 - val_acc: 0.9353\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9513\n","Epoch 5: val_loss improved from 0.17078 to 0.16709, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1366 - acc: 0.9513 - val_loss: 0.1671 - val_acc: 0.9418\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9569\n","Epoch 6: val_loss did not improve from 0.16709\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1249 - acc: 0.9570 - val_loss: 0.1756 - val_acc: 0.9381\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9626\n","Epoch 7: val_loss did not improve from 0.16709\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1088 - acc: 0.9625 - val_loss: 0.1802 - val_acc: 0.9409\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.0903 - acc: 0.9693\n","Epoch 8: val_loss did not improve from 0.16709\n","238/238 [==============================] - 8s 33ms/step - loss: 0.0902 - acc: 0.9694 - val_loss: 0.2149 - val_acc: 0.9353\n","0.8879504346333318 0.5330474621357859 0.9431922723091076 0.46187363834422657\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6916 - acc: 0.6135\n","Epoch 1: val_loss improved from inf to 0.62917, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.6915 - acc: 0.6136 - val_loss: 0.6292 - val_acc: 0.6710\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6333 - acc: 0.6610\n","Epoch 2: val_loss improved from 0.62917 to 0.61659, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.6329 - acc: 0.6615 - val_loss: 0.6166 - val_acc: 0.6811\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6161 - acc: 0.6698\n","Epoch 3: val_loss improved from 0.61659 to 0.61086, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.6159 - acc: 0.6703 - val_loss: 0.6109 - val_acc: 0.6751\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6007 - acc: 0.6874\n","Epoch 4: val_loss did not improve from 0.61086\n","238/238 [==============================] - 8s 34ms/step - loss: 0.6009 - acc: 0.6870 - val_loss: 0.6125 - val_acc: 0.6798\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5855 - acc: 0.7003\n","Epoch 5: val_loss did not improve from 0.61086\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5859 - acc: 0.6997 - val_loss: 0.6154 - val_acc: 0.6742\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5695 - acc: 0.7130\n","Epoch 6: val_loss did not improve from 0.61086\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5695 - acc: 0.7131 - val_loss: 0.6205 - val_acc: 0.6705\n","0.7032916402308228 0.6403783231234752 0.6644434222631095 0.5638266068759343\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4890 - acc: 0.8067\n","Epoch 1: val_loss improved from inf to 0.44549, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.4885 - acc: 0.8070 - val_loss: 0.4455 - val_acc: 0.8202\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4398 - acc: 0.8165\n","Epoch 2: val_loss improved from 0.44549 to 0.43659, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.4399 - acc: 0.8164 - val_loss: 0.4366 - val_acc: 0.8212\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4262 - acc: 0.8205\n","Epoch 3: val_loss improved from 0.43659 to 0.43107, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.4264 - acc: 0.8203 - val_loss: 0.4311 - val_acc: 0.8179\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4155 - acc: 0.8233\n","Epoch 4: val_loss did not improve from 0.43107\n","238/238 [==============================] - 8s 33ms/step - loss: 0.4153 - acc: 0.8235 - val_loss: 0.4364 - val_acc: 0.8198\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4028 - acc: 0.8302\n","Epoch 5: val_loss did not improve from 0.43107\n","238/238 [==============================] - 8s 33ms/step - loss: 0.4027 - acc: 0.8301 - val_loss: 0.4389 - val_acc: 0.8124\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3883 - acc: 0.8344\n","Epoch 6: val_loss did not improve from 0.43107\n","238/238 [==============================] - 8s 33ms/step - loss: 0.3883 - acc: 0.8344 - val_loss: 0.4365 - val_acc: 0.8128\n","0.7131497363242136 0.3803945355895134 0.827966881324747 0.2336065573770492\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2996 - acc: 0.9124\n","Epoch 1: val_loss improved from inf to 0.27073, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.2992 - acc: 0.9125 - val_loss: 0.2707 - val_acc: 0.9233\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2586 - acc: 0.9215\n","Epoch 2: val_loss improved from 0.27073 to 0.26071, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2590 - acc: 0.9214 - val_loss: 0.2607 - val_acc: 0.9251\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2457 - acc: 0.9221\n","Epoch 3: val_loss improved from 0.26071 to 0.25762, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2455 - acc: 0.9221 - val_loss: 0.2576 - val_acc: 0.9242\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2361 - acc: 0.9233\n","Epoch 4: val_loss did not improve from 0.25762\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2360 - acc: 0.9234 - val_loss: 0.2587 - val_acc: 0.9238\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2283 - acc: 0.9242\n","Epoch 5: val_loss did not improve from 0.25762\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2283 - acc: 0.9242 - val_loss: 0.2673 - val_acc: 0.9228\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2137 - acc: 0.9262\n","Epoch 6: val_loss did not improve from 0.25762\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2137 - acc: 0.9261 - val_loss: 0.2763 - val_acc: 0.9173\n","0.7309823298281957 0.20889393063051434 0.9176632934682613 0.01648351648351648\n","Iteration number:  3\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2848 - acc: 0.9026\n","Epoch 1: val_loss improved from inf to 0.24217, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.2851 - acc: 0.9024 - val_loss: 0.2422 - val_acc: 0.9150\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2399 - acc: 0.9153\n","Epoch 2: val_loss improved from 0.24217 to 0.23537, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.2402 - acc: 0.9152 - val_loss: 0.2354 - val_acc: 0.9145\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2246 - acc: 0.9183\n","Epoch 3: val_loss did not improve from 0.23537\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2246 - acc: 0.9183 - val_loss: 0.2417 - val_acc: 0.9122\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2130 - acc: 0.9205\n","Epoch 4: val_loss improved from 0.23537 to 0.23366, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2129 - acc: 0.9206 - val_loss: 0.2337 - val_acc: 0.9164\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9268\n","Epoch 5: val_loss did not improve from 0.23366\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1983 - acc: 0.9270 - val_loss: 0.2532 - val_acc: 0.9039\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1817 - acc: 0.9314\n","Epoch 6: val_loss did not improve from 0.23366\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1820 - acc: 0.9313 - val_loss: 0.2529 - val_acc: 0.9122\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1616 - acc: 0.9391\n","Epoch 7: val_loss did not improve from 0.23366\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1615 - acc: 0.9392 - val_loss: 0.2526 - val_acc: 0.9076\n","0.8739079434311393 0.5750458121314587 0.9153633854645814 0.4231974921630094\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2246 - acc: 0.9312\n","Epoch 1: val_loss improved from inf to 0.18073, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2246 - acc: 0.9311 - val_loss: 0.1807 - val_acc: 0.9413\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1759 - acc: 0.9428\n","Epoch 2: val_loss improved from 0.18073 to 0.17656, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1761 - acc: 0.9426 - val_loss: 0.1766 - val_acc: 0.9399\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1618 - acc: 0.9460\n","Epoch 3: val_loss improved from 0.17656 to 0.16458, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1616 - acc: 0.9461 - val_loss: 0.1646 - val_acc: 0.9450\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9488\n","Epoch 4: val_loss did not improve from 0.16458\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1497 - acc: 0.9488 - val_loss: 0.1675 - val_acc: 0.9445\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1374 - acc: 0.9531\n","Epoch 5: val_loss did not improve from 0.16458\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1375 - acc: 0.9530 - val_loss: 0.1739 - val_acc: 0.9441\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9570\n","Epoch 6: val_loss did not improve from 0.16458\n","238/238 [==============================] - 9s 38ms/step - loss: 0.1223 - acc: 0.9572 - val_loss: 0.1674 - val_acc: 0.9422\n","0.8911653167283113 0.5273285240126244 0.9420423183072677 0.40845070422535207\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6872 - acc: 0.6232\n","Epoch 1: val_loss improved from inf to 0.63499, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.6872 - acc: 0.6230 - val_loss: 0.6350 - val_acc: 0.6650\n","Epoch 2/100\n","238/238 [==============================] - ETA: 0s - loss: 0.6327 - acc: 0.6616\n","Epoch 2: val_loss improved from 0.63499 to 0.61906, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 42ms/step - loss: 0.6327 - acc: 0.6616 - val_loss: 0.6191 - val_acc: 0.6798\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6130 - acc: 0.6739\n","Epoch 3: val_loss did not improve from 0.61906\n","238/238 [==============================] - 9s 39ms/step - loss: 0.6130 - acc: 0.6740 - val_loss: 0.6205 - val_acc: 0.6728\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5982 - acc: 0.6882\n","Epoch 4: val_loss did not improve from 0.61906\n","238/238 [==============================] - 10s 41ms/step - loss: 0.5984 - acc: 0.6882 - val_loss: 0.6230 - val_acc: 0.6696\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5837 - acc: 0.6995\n","Epoch 5: val_loss did not improve from 0.61906\n","238/238 [==============================] - 9s 39ms/step - loss: 0.5839 - acc: 0.6993 - val_loss: 0.6265 - val_acc: 0.6594\n","0.7002082497097453 0.63842571184446 0.6637534498620056 0.5361675126903553\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4916 - acc: 0.8029\n","Epoch 1: val_loss improved from inf to 0.44019, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 13s 41ms/step - loss: 0.4914 - acc: 0.8031 - val_loss: 0.4402 - val_acc: 0.8142\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4419 - acc: 0.8161\n","Epoch 2: val_loss improved from 0.44019 to 0.43249, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 43ms/step - loss: 0.4418 - acc: 0.8161 - val_loss: 0.4325 - val_acc: 0.8179\n","Epoch 3/100\n","238/238 [==============================] - ETA: 0s - loss: 0.4268 - acc: 0.8219\n","Epoch 3: val_loss improved from 0.43249 to 0.42489, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 42ms/step - loss: 0.4268 - acc: 0.8219 - val_loss: 0.4249 - val_acc: 0.8230\n","Epoch 4/100\n","238/238 [==============================] - ETA: 0s - loss: 0.4138 - acc: 0.8279\n","Epoch 4: val_loss did not improve from 0.42489\n","238/238 [==============================] - 10s 42ms/step - loss: 0.4138 - acc: 0.8279 - val_loss: 0.4304 - val_acc: 0.8216\n","Epoch 5/100\n","238/238 [==============================] - ETA: 0s - loss: 0.3997 - acc: 0.8321\n","Epoch 5: val_loss did not improve from 0.42489\n","238/238 [==============================] - 10s 42ms/step - loss: 0.3997 - acc: 0.8321 - val_loss: 0.4292 - val_acc: 0.8165\n","Epoch 6/100\n","238/238 [==============================] - ETA: 0s - loss: 0.3840 - acc: 0.8379\n","Epoch 6: val_loss did not improve from 0.42489\n","238/238 [==============================] - 10s 44ms/step - loss: 0.3840 - acc: 0.8379 - val_loss: 0.4277 - val_acc: 0.8216\n","0.7241569532468922 0.3782897306285454 0.8258969641214351 0.15229563269876817\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2917 - acc: 0.9176\n","Epoch 1: val_loss improved from inf to 0.26665, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 13s 44ms/step - loss: 0.2917 - acc: 0.9176 - val_loss: 0.2667 - val_acc: 0.9242\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2564 - acc: 0.9220\n","Epoch 2: val_loss improved from 0.26665 to 0.26553, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 10s 42ms/step - loss: 0.2564 - acc: 0.9220 - val_loss: 0.2655 - val_acc: 0.9242\n","Epoch 3/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2436 - acc: 0.9219\n","Epoch 3: val_loss did not improve from 0.26553\n","238/238 [==============================] - 10s 43ms/step - loss: 0.2436 - acc: 0.9219 - val_loss: 0.2671 - val_acc: 0.9251\n","Epoch 4/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2335 - acc: 0.9225\n","Epoch 4: val_loss improved from 0.26553 to 0.26035, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 10s 42ms/step - loss: 0.2335 - acc: 0.9225 - val_loss: 0.2604 - val_acc: 0.9238\n","Epoch 5/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2234 - acc: 0.9243\n","Epoch 5: val_loss did not improve from 0.26035\n","238/238 [==============================] - 10s 42ms/step - loss: 0.2234 - acc: 0.9243 - val_loss: 0.2623 - val_acc: 0.9233\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2085 - acc: 0.9266\n","Epoch 6: val_loss did not improve from 0.26035\n","238/238 [==============================] - 10s 41ms/step - loss: 0.2087 - acc: 0.9267 - val_loss: 0.2753 - val_acc: 0.9182\n","Epoch 7/100\n","238/238 [==============================] - ETA: 0s - loss: 0.1931 - acc: 0.9317\n","Epoch 7: val_loss did not improve from 0.26035\n","238/238 [==============================] - 10s 42ms/step - loss: 0.1931 - acc: 0.9317 - val_loss: 0.2777 - val_acc: 0.9136\n","0.7127812507036545 0.21000841452507574 0.9172033118675254 0.09090909090909091\n","Iteration number:  4\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2863 - acc: 0.9022\n","Epoch 1: val_loss improved from inf to 0.25251, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 13s 42ms/step - loss: 0.2859 - acc: 0.9024 - val_loss: 0.2525 - val_acc: 0.9131\n","Epoch 2/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2422 - acc: 0.9138\n","Epoch 2: val_loss improved from 0.25251 to 0.23237, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 41ms/step - loss: 0.2422 - acc: 0.9138 - val_loss: 0.2324 - val_acc: 0.9136\n","Epoch 3/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2226 - acc: 0.9196\n","Epoch 3: val_loss did not improve from 0.23237\n","238/238 [==============================] - 10s 43ms/step - loss: 0.2226 - acc: 0.9196 - val_loss: 0.2378 - val_acc: 0.9080\n","Epoch 4/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2113 - acc: 0.9237\n","Epoch 4: val_loss improved from 0.23237 to 0.22927, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 42ms/step - loss: 0.2113 - acc: 0.9237 - val_loss: 0.2293 - val_acc: 0.9150\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1948 - acc: 0.9301\n","Epoch 5: val_loss did not improve from 0.22927\n","238/238 [==============================] - 10s 43ms/step - loss: 0.1955 - acc: 0.9298 - val_loss: 0.2411 - val_acc: 0.9150\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1824 - acc: 0.9360\n","Epoch 6: val_loss did not improve from 0.22927\n","238/238 [==============================] - 10s 41ms/step - loss: 0.1825 - acc: 0.9359 - val_loss: 0.2413 - val_acc: 0.9085\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1643 - acc: 0.9399\n","Epoch 7: val_loss did not improve from 0.22927\n","238/238 [==============================] - 10s 41ms/step - loss: 0.1644 - acc: 0.9399 - val_loss: 0.2598 - val_acc: 0.9108\n","0.8724386509824655 0.5649676849123342 0.9132934682612696 0.4118564742589703\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2131 - acc: 0.9364\n","Epoch 1: val_loss improved from inf to 0.17897, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 13s 43ms/step - loss: 0.2136 - acc: 0.9362 - val_loss: 0.1790 - val_acc: 0.9422\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1750 - acc: 0.9425\n","Epoch 2: val_loss improved from 0.17897 to 0.16898, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 41ms/step - loss: 0.1753 - acc: 0.9424 - val_loss: 0.1690 - val_acc: 0.9432\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1617 - acc: 0.9460\n","Epoch 3: val_loss improved from 0.16898 to 0.16605, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 40ms/step - loss: 0.1617 - acc: 0.9461 - val_loss: 0.1660 - val_acc: 0.9422\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9488\n","Epoch 4: val_loss did not improve from 0.16605\n","238/238 [==============================] - 10s 40ms/step - loss: 0.1505 - acc: 0.9487 - val_loss: 0.1672 - val_acc: 0.9404\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1378 - acc: 0.9536\n","Epoch 5: val_loss did not improve from 0.16605\n","238/238 [==============================] - 10s 41ms/step - loss: 0.1379 - acc: 0.9534 - val_loss: 0.1692 - val_acc: 0.9445\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9552\n","Epoch 6: val_loss did not improve from 0.16605\n","238/238 [==============================] - 10s 40ms/step - loss: 0.1253 - acc: 0.9552 - val_loss: 0.1739 - val_acc: 0.9372\n","0.8847254084929072 0.5175481868344957 0.9408923643054278 0.4449244060475162\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6808 - acc: 0.6216\n","Epoch 1: val_loss improved from inf to 0.63516, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 13s 43ms/step - loss: 0.6804 - acc: 0.6221 - val_loss: 0.6352 - val_acc: 0.6631\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6314 - acc: 0.6619\n","Epoch 2: val_loss improved from 0.63516 to 0.61566, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 40ms/step - loss: 0.6314 - acc: 0.6619 - val_loss: 0.6157 - val_acc: 0.6751\n","Epoch 3/100\n","238/238 [==============================] - ETA: 0s - loss: 0.6122 - acc: 0.6744\n","Epoch 3: val_loss did not improve from 0.61566\n","238/238 [==============================] - 10s 41ms/step - loss: 0.6122 - acc: 0.6744 - val_loss: 0.6173 - val_acc: 0.6724\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5972 - acc: 0.6845\n","Epoch 4: val_loss improved from 0.61566 to 0.61127, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 40ms/step - loss: 0.5974 - acc: 0.6841 - val_loss: 0.6113 - val_acc: 0.6705\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5825 - acc: 0.7024\n","Epoch 5: val_loss did not improve from 0.61127\n","238/238 [==============================] - 9s 40ms/step - loss: 0.5824 - acc: 0.7025 - val_loss: 0.6223 - val_acc: 0.6627\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5654 - acc: 0.7171\n","Epoch 6: val_loss did not improve from 0.61127\n","238/238 [==============================] - 9s 40ms/step - loss: 0.5651 - acc: 0.7175 - val_loss: 0.6216 - val_acc: 0.6682\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5445 - acc: 0.7314\n","Epoch 7: val_loss did not improve from 0.61127\n","238/238 [==============================] - 9s 39ms/step - loss: 0.5446 - acc: 0.7312 - val_loss: 0.6307 - val_acc: 0.6622\n","0.7061003137772829 0.6445535095545196 0.6653633854645814 0.5796012713088703\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4760 - acc: 0.8102\n","Epoch 1: val_loss improved from inf to 0.43982, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 12s 41ms/step - loss: 0.4763 - acc: 0.8100 - val_loss: 0.4398 - val_acc: 0.8189\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4389 - acc: 0.8170\n","Epoch 2: val_loss improved from 0.43982 to 0.43657, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 40ms/step - loss: 0.4390 - acc: 0.8167 - val_loss: 0.4366 - val_acc: 0.8189\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4210 - acc: 0.8193\n","Epoch 3: val_loss improved from 0.43657 to 0.42975, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 40ms/step - loss: 0.4213 - acc: 0.8192 - val_loss: 0.4298 - val_acc: 0.8147\n","Epoch 4/100\n","238/238 [==============================] - ETA: 0s - loss: 0.4128 - acc: 0.8240\n","Epoch 4: val_loss improved from 0.42975 to 0.42851, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 41ms/step - loss: 0.4128 - acc: 0.8240 - val_loss: 0.4285 - val_acc: 0.8235\n","Epoch 5/100\n","238/238 [==============================] - ETA: 0s - loss: 0.3988 - acc: 0.8313\n","Epoch 5: val_loss did not improve from 0.42851\n","238/238 [==============================] - 9s 39ms/step - loss: 0.3988 - acc: 0.8313 - val_loss: 0.4309 - val_acc: 0.8161\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3829 - acc: 0.8365\n","Epoch 6: val_loss did not improve from 0.42851\n","238/238 [==============================] - 10s 40ms/step - loss: 0.3827 - acc: 0.8367 - val_loss: 0.4315 - val_acc: 0.8221\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3624 - acc: 0.8456\n","Epoch 7: val_loss did not improve from 0.42851\n","238/238 [==============================] - 9s 40ms/step - loss: 0.3627 - acc: 0.8456 - val_loss: 0.4430 - val_acc: 0.8119\n","0.7210256677207914 0.3878370422868395 0.8298068077276909 0.20258620689655174\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2878 - acc: 0.9204\n","Epoch 1: val_loss improved from inf to 0.26655, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 12s 42ms/step - loss: 0.2873 - acc: 0.9205 - val_loss: 0.2665 - val_acc: 0.9251\n","Epoch 2/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2558 - acc: 0.9219\n","Epoch 2: val_loss improved from 0.26655 to 0.26323, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 39ms/step - loss: 0.2558 - acc: 0.9219 - val_loss: 0.2632 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2456 - acc: 0.9223\n","Epoch 3: val_loss improved from 0.26323 to 0.25922, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 39ms/step - loss: 0.2451 - acc: 0.9225 - val_loss: 0.2592 - val_acc: 0.9247\n","Epoch 4/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2340 - acc: 0.9230\n","Epoch 4: val_loss did not improve from 0.25922\n","238/238 [==============================] - 10s 40ms/step - loss: 0.2340 - acc: 0.9230 - val_loss: 0.2609 - val_acc: 0.9233\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2251 - acc: 0.9244\n","Epoch 5: val_loss did not improve from 0.25922\n","238/238 [==============================] - 9s 38ms/step - loss: 0.2250 - acc: 0.9244 - val_loss: 0.2660 - val_acc: 0.9233\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2110 - acc: 0.9280\n","Epoch 6: val_loss did not improve from 0.25922\n","238/238 [==============================] - 10s 40ms/step - loss: 0.2110 - acc: 0.9279 - val_loss: 0.2737 - val_acc: 0.9196\n","0.7196176059985139 0.20479482801614818 0.9183532658693653 0.037940379403794036\n","Iteration number:  5\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2934 - acc: 0.9005\n","Epoch 1: val_loss improved from inf to 0.24382, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 12s 39ms/step - loss: 0.2934 - acc: 0.9006 - val_loss: 0.2438 - val_acc: 0.9145\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2437 - acc: 0.9156\n","Epoch 2: val_loss improved from 0.24382 to 0.24188, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 40ms/step - loss: 0.2441 - acc: 0.9154 - val_loss: 0.2419 - val_acc: 0.9104\n","Epoch 3/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2247 - acc: 0.9190\n","Epoch 3: val_loss improved from 0.24188 to 0.24141, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 41ms/step - loss: 0.2247 - acc: 0.9190 - val_loss: 0.2414 - val_acc: 0.9104\n","Epoch 4/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2098 - acc: 0.9236\n","Epoch 4: val_loss did not improve from 0.24141\n","238/238 [==============================] - 9s 40ms/step - loss: 0.2098 - acc: 0.9236 - val_loss: 0.2421 - val_acc: 0.9127\n","Epoch 5/100\n","238/238 [==============================] - ETA: 0s - loss: 0.1962 - acc: 0.9275\n","Epoch 5: val_loss did not improve from 0.24141\n","238/238 [==============================] - 10s 40ms/step - loss: 0.1962 - acc: 0.9275 - val_loss: 0.2455 - val_acc: 0.9099\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1822 - acc: 0.9328\n","Epoch 6: val_loss did not improve from 0.24141\n","238/238 [==============================] - 9s 39ms/step - loss: 0.1819 - acc: 0.9328 - val_loss: 0.2465 - val_acc: 0.9099\n","0.8687522028372543 0.558982494267895 0.9109935602575897 0.4333821376281113\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2292 - acc: 0.9320\n","Epoch 1: val_loss improved from inf to 0.17784, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 12s 42ms/step - loss: 0.2288 - acc: 0.9321 - val_loss: 0.1778 - val_acc: 0.9436\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1787 - acc: 0.9434\n","Epoch 2: val_loss improved from 0.17784 to 0.16930, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 40ms/step - loss: 0.1789 - acc: 0.9435 - val_loss: 0.1693 - val_acc: 0.9441\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1632 - acc: 0.9451\n","Epoch 3: val_loss improved from 0.16930 to 0.16841, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 38ms/step - loss: 0.1629 - acc: 0.9453 - val_loss: 0.1684 - val_acc: 0.9385\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9479\n","Epoch 4: val_loss did not improve from 0.16841\n","238/238 [==============================] - 9s 40ms/step - loss: 0.1507 - acc: 0.9478 - val_loss: 0.1691 - val_acc: 0.9441\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9528\n","Epoch 5: val_loss did not improve from 0.16841\n","238/238 [==============================] - 9s 39ms/step - loss: 0.1382 - acc: 0.9528 - val_loss: 0.1736 - val_acc: 0.9413\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9569\n","Epoch 6: val_loss did not improve from 0.16841\n","238/238 [==============================] - 9s 38ms/step - loss: 0.1220 - acc: 0.9571 - val_loss: 0.1797 - val_acc: 0.9427\n","0.882716107183545 0.5255574389644422 0.9422723091076357 0.46934460887949264\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6755 - acc: 0.6225\n","Epoch 1: val_loss improved from inf to 0.63559, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 13s 42ms/step - loss: 0.6753 - acc: 0.6224 - val_loss: 0.6356 - val_acc: 0.6562\n","Epoch 2/100\n","238/238 [==============================] - ETA: 0s - loss: 0.6263 - acc: 0.6638\n","Epoch 2: val_loss improved from 0.63559 to 0.61799, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 41ms/step - loss: 0.6263 - acc: 0.6638 - val_loss: 0.6180 - val_acc: 0.6724\n","Epoch 3/100\n","238/238 [==============================] - ETA: 0s - loss: 0.6112 - acc: 0.6746\n","Epoch 3: val_loss improved from 0.61799 to 0.61246, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 43ms/step - loss: 0.6112 - acc: 0.6746 - val_loss: 0.6125 - val_acc: 0.6765\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5973 - acc: 0.6874\n","Epoch 4: val_loss did not improve from 0.61246\n","238/238 [==============================] - 10s 42ms/step - loss: 0.5973 - acc: 0.6876 - val_loss: 0.6179 - val_acc: 0.6682\n","Epoch 5/100\n","238/238 [==============================] - ETA: 0s - loss: 0.5835 - acc: 0.6994\n","Epoch 5: val_loss did not improve from 0.61246\n","238/238 [==============================] - 10s 40ms/step - loss: 0.5835 - acc: 0.6994 - val_loss: 0.6127 - val_acc: 0.6673\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5667 - acc: 0.7157\n","Epoch 6: val_loss did not improve from 0.61246\n","238/238 [==============================] - 9s 40ms/step - loss: 0.5670 - acc: 0.7155 - val_loss: 0.6266 - val_acc: 0.6668\n","0.7096181153509169 0.6519579853571389 0.6639834406623735 0.5163853028798411\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4828 - acc: 0.8081\n","Epoch 1: val_loss improved from inf to 0.43578, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 13s 44ms/step - loss: 0.4825 - acc: 0.8082 - val_loss: 0.4358 - val_acc: 0.8142\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4388 - acc: 0.8200\n","Epoch 2: val_loss improved from 0.43578 to 0.42973, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 39ms/step - loss: 0.4386 - acc: 0.8199 - val_loss: 0.4297 - val_acc: 0.8189\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4222 - acc: 0.8231\n","Epoch 3: val_loss improved from 0.42973 to 0.42550, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 40ms/step - loss: 0.4231 - acc: 0.8227 - val_loss: 0.4255 - val_acc: 0.8184\n","Epoch 4/100\n","238/238 [==============================] - ETA: 0s - loss: 0.4109 - acc: 0.8261\n","Epoch 4: val_loss did not improve from 0.42550\n","238/238 [==============================] - 10s 40ms/step - loss: 0.4109 - acc: 0.8261 - val_loss: 0.4272 - val_acc: 0.8249\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3997 - acc: 0.8284\n","Epoch 5: val_loss did not improve from 0.42550\n","238/238 [==============================] - 9s 39ms/step - loss: 0.3995 - acc: 0.8284 - val_loss: 0.4275 - val_acc: 0.8175\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3802 - acc: 0.8412\n","Epoch 6: val_loss did not improve from 0.42550\n","238/238 [==============================] - 9s 39ms/step - loss: 0.3803 - acc: 0.8413 - val_loss: 0.4344 - val_acc: 0.8179\n","0.7208660668711292 0.387967714553206 0.827276908923643 0.2406471183013144\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2956 - acc: 0.9146\n","Epoch 1: val_loss improved from inf to 0.26819, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 38ms/step - loss: 0.2950 - acc: 0.9148 - val_loss: 0.2682 - val_acc: 0.9247\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2599 - acc: 0.9213\n","Epoch 2: val_loss improved from 0.26819 to 0.26009, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2599 - acc: 0.9213 - val_loss: 0.2601 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2451 - acc: 0.9218\n","Epoch 3: val_loss did not improve from 0.26009\n","238/238 [==============================] - 9s 37ms/step - loss: 0.2447 - acc: 0.9220 - val_loss: 0.2666 - val_acc: 0.9247\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2349 - acc: 0.9228\n","Epoch 4: val_loss did not improve from 0.26009\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2349 - acc: 0.9227 - val_loss: 0.2788 - val_acc: 0.9140\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2275 - acc: 0.9242\n","Epoch 5: val_loss improved from 0.26009 to 0.25938, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2275 - acc: 0.9243 - val_loss: 0.2594 - val_acc: 0.9251\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2128 - acc: 0.9255\n","Epoch 6: val_loss did not improve from 0.25938\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2126 - acc: 0.9256 - val_loss: 0.2754 - val_acc: 0.9182\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1980 - acc: 0.9308\n","Epoch 7: val_loss did not improve from 0.25938\n","238/238 [==============================] - 8s 36ms/step - loss: 0.1983 - acc: 0.9307 - val_loss: 0.2742 - val_acc: 0.9238\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1792 - acc: 0.9368\n","Epoch 8: val_loss did not improve from 0.25938\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1795 - acc: 0.9367 - val_loss: 0.3118 - val_acc: 0.9062\n","0.7269729064871315 0.21272465365377036 0.9188132474701012 0.048517520215633415\n","Iteration number:  6\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2963 - acc: 0.9012\n","Epoch 1: val_loss improved from inf to 0.24923, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2957 - acc: 0.9014 - val_loss: 0.2492 - val_acc: 0.9117\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2417 - acc: 0.9144\n","Epoch 2: val_loss improved from 0.24923 to 0.23709, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 39ms/step - loss: 0.2418 - acc: 0.9143 - val_loss: 0.2371 - val_acc: 0.9168\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2248 - acc: 0.9201\n","Epoch 3: val_loss improved from 0.23709 to 0.23612, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 39ms/step - loss: 0.2244 - acc: 0.9203 - val_loss: 0.2361 - val_acc: 0.9177\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2104 - acc: 0.9245\n","Epoch 4: val_loss improved from 0.23612 to 0.22467, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 38ms/step - loss: 0.2104 - acc: 0.9246 - val_loss: 0.2247 - val_acc: 0.9173\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1979 - acc: 0.9287\n","Epoch 5: val_loss did not improve from 0.22467\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1975 - acc: 0.9288 - val_loss: 0.2363 - val_acc: 0.9154\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1805 - acc: 0.9336\n","Epoch 6: val_loss did not improve from 0.22467\n","238/238 [==============================] - 9s 38ms/step - loss: 0.1805 - acc: 0.9335 - val_loss: 0.2344 - val_acc: 0.9085\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9426\n","Epoch 7: val_loss did not improve from 0.22467\n","238/238 [==============================] - 9s 39ms/step - loss: 0.1608 - acc: 0.9426 - val_loss: 0.2743 - val_acc: 0.9136\n","0.8704951978147855 0.5439825682034993 0.9107635694572217 0.43440233236151604\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2247 - acc: 0.9328\n","Epoch 1: val_loss improved from inf to 0.17963, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 13s 42ms/step - loss: 0.2243 - acc: 0.9328 - val_loss: 0.1796 - val_acc: 0.9409\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1764 - acc: 0.9436\n","Epoch 2: val_loss improved from 0.17963 to 0.17198, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 39ms/step - loss: 0.1764 - acc: 0.9436 - val_loss: 0.1720 - val_acc: 0.9445\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9455\n","Epoch 3: val_loss improved from 0.17198 to 0.17012, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 40ms/step - loss: 0.1626 - acc: 0.9456 - val_loss: 0.1701 - val_acc: 0.9404\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1534 - acc: 0.9481\n","Epoch 4: val_loss did not improve from 0.17012\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1533 - acc: 0.9482 - val_loss: 0.1715 - val_acc: 0.9399\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9523\n","Epoch 5: val_loss did not improve from 0.17012\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1400 - acc: 0.9522 - val_loss: 0.1716 - val_acc: 0.9418\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9569\n","Epoch 6: val_loss did not improve from 0.17012\n","238/238 [==============================] - 8s 36ms/step - loss: 0.1265 - acc: 0.9570 - val_loss: 0.1728 - val_acc: 0.9344\n","0.8817352560201008 0.5114503559004774 0.9411223551057958 0.43859649122807015\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6812 - acc: 0.6121\n","Epoch 1: val_loss improved from inf to 0.63761, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.6813 - acc: 0.6120 - val_loss: 0.6376 - val_acc: 0.6571\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6309 - acc: 0.6605\n","Epoch 2: val_loss improved from 0.63761 to 0.61638, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.6309 - acc: 0.6607 - val_loss: 0.6164 - val_acc: 0.6659\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6111 - acc: 0.6735\n","Epoch 3: val_loss improved from 0.61638 to 0.61313, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.6112 - acc: 0.6733 - val_loss: 0.6131 - val_acc: 0.6705\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5959 - acc: 0.6890\n","Epoch 4: val_loss did not improve from 0.61313\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5959 - acc: 0.6889 - val_loss: 0.6221 - val_acc: 0.6548\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5826 - acc: 0.6986\n","Epoch 5: val_loss did not improve from 0.61313\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5824 - acc: 0.6986 - val_loss: 0.6218 - val_acc: 0.6636\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5631 - acc: 0.7175\n","Epoch 6: val_loss did not improve from 0.61313\n","238/238 [==============================] - 9s 36ms/step - loss: 0.5633 - acc: 0.7174 - val_loss: 0.6279 - val_acc: 0.6571\n","0.70221176297946 0.6444083718381228 0.6605335786568537 0.5427509293680297\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4882 - acc: 0.8048\n","Epoch 1: val_loss improved from inf to 0.43922, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 12s 40ms/step - loss: 0.4889 - acc: 0.8045 - val_loss: 0.4392 - val_acc: 0.8184\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4395 - acc: 0.8165\n","Epoch 2: val_loss improved from 0.43922 to 0.43044, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 9s 39ms/step - loss: 0.4394 - acc: 0.8166 - val_loss: 0.4304 - val_acc: 0.8165\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4256 - acc: 0.8217\n","Epoch 3: val_loss did not improve from 0.43044\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4254 - acc: 0.8219 - val_loss: 0.4377 - val_acc: 0.8133\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4109 - acc: 0.8267\n","Epoch 4: val_loss did not improve from 0.43044\n","238/238 [==============================] - 8s 35ms/step - loss: 0.4111 - acc: 0.8265 - val_loss: 0.4320 - val_acc: 0.8170\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3980 - acc: 0.8306\n","Epoch 5: val_loss did not improve from 0.43044\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3979 - acc: 0.8307 - val_loss: 0.4366 - val_acc: 0.8142\n","0.7182432266339295 0.37042010618465265 0.827046918123275 0.168141592920354\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2877 - acc: 0.9191\n","Epoch 1: val_loss improved from inf to 0.27160, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.2874 - acc: 0.9192 - val_loss: 0.2716 - val_acc: 0.9242\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2555 - acc: 0.9214\n","Epoch 2: val_loss improved from 0.27160 to 0.26288, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2556 - acc: 0.9213 - val_loss: 0.2629 - val_acc: 0.9238\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2435 - acc: 0.9218\n","Epoch 3: val_loss improved from 0.26288 to 0.26257, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2433 - acc: 0.9219 - val_loss: 0.2626 - val_acc: 0.9247\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2359 - acc: 0.9234\n","Epoch 4: val_loss improved from 0.26257 to 0.25739, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2362 - acc: 0.9233 - val_loss: 0.2574 - val_acc: 0.9242\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2248 - acc: 0.9249\n","Epoch 5: val_loss improved from 0.25739 to 0.25527, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2249 - acc: 0.9249 - val_loss: 0.2553 - val_acc: 0.9242\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2120 - acc: 0.9262\n","Epoch 6: val_loss did not improve from 0.25527\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2123 - acc: 0.9261 - val_loss: 0.2714 - val_acc: 0.9210\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1964 - acc: 0.9310\n","Epoch 7: val_loss did not improve from 0.25527\n","238/238 [==============================] - 8s 36ms/step - loss: 0.1965 - acc: 0.9310 - val_loss: 0.2757 - val_acc: 0.9187\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1721 - acc: 0.9416\n","Epoch 8: val_loss did not improve from 0.25527\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1721 - acc: 0.9417 - val_loss: 0.3007 - val_acc: 0.9191\n","0.7323241989597171 0.19858933967497824 0.9178932842686293 0.03773584905660378\n","Iteration number:  7\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2958 - acc: 0.8997\n","Epoch 1: val_loss improved from inf to 0.24494, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.2959 - acc: 0.8997 - val_loss: 0.2449 - val_acc: 0.9159\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2437 - acc: 0.9133\n","Epoch 2: val_loss improved from 0.24494 to 0.23209, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2433 - acc: 0.9135 - val_loss: 0.2321 - val_acc: 0.9127\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2264 - acc: 0.9186\n","Epoch 3: val_loss improved from 0.23209 to 0.23074, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2263 - acc: 0.9187 - val_loss: 0.2307 - val_acc: 0.9164\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2136 - acc: 0.9237\n","Epoch 4: val_loss did not improve from 0.23074\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2134 - acc: 0.9237 - val_loss: 0.2326 - val_acc: 0.9108\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1978 - acc: 0.9266\n","Epoch 5: val_loss did not improve from 0.23074\n","238/238 [==============================] - 9s 38ms/step - loss: 0.1977 - acc: 0.9267 - val_loss: 0.2425 - val_acc: 0.9085\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1831 - acc: 0.9315\n","Epoch 6: val_loss did not improve from 0.23074\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1833 - acc: 0.9315 - val_loss: 0.2432 - val_acc: 0.9113\n","0.8676617983963345 0.552032994454765 0.9112235510579577 0.41867469879518066\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2269 - acc: 0.9297\n","Epoch 1: val_loss improved from inf to 0.17986, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2268 - acc: 0.9296 - val_loss: 0.1799 - val_acc: 0.9399\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9423\n","Epoch 2: val_loss improved from 0.17986 to 0.16882, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1776 - acc: 0.9422 - val_loss: 0.1688 - val_acc: 0.9422\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1613 - acc: 0.9451\n","Epoch 3: val_loss did not improve from 0.16882\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1616 - acc: 0.9451 - val_loss: 0.1709 - val_acc: 0.9413\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1498 - acc: 0.9488\n","Epoch 4: val_loss improved from 0.16882 to 0.16769, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1504 - acc: 0.9487 - val_loss: 0.1677 - val_acc: 0.9459\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9529\n","Epoch 5: val_loss did not improve from 0.16769\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1398 - acc: 0.9531 - val_loss: 0.1726 - val_acc: 0.9404\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9554\n","Epoch 6: val_loss did not improve from 0.16769\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1268 - acc: 0.9553 - val_loss: 0.1798 - val_acc: 0.9376\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9622\n","Epoch 7: val_loss did not improve from 0.16769\n","238/238 [==============================] - 9s 37ms/step - loss: 0.1110 - acc: 0.9623 - val_loss: 0.1832 - val_acc: 0.9362\n","0.8860839302713923 0.5190911633704843 0.9418123275068997 0.44880174291938996\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6909 - acc: 0.6164\n","Epoch 1: val_loss improved from inf to 0.63744, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 12s 42ms/step - loss: 0.6909 - acc: 0.6166 - val_loss: 0.6374 - val_acc: 0.6613\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6327 - acc: 0.6622\n","Epoch 2: val_loss improved from 0.63744 to 0.61968, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 40ms/step - loss: 0.6329 - acc: 0.6623 - val_loss: 0.6197 - val_acc: 0.6724\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6151 - acc: 0.6748\n","Epoch 3: val_loss improved from 0.61968 to 0.61495, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 40ms/step - loss: 0.6148 - acc: 0.6750 - val_loss: 0.6149 - val_acc: 0.6816\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5974 - acc: 0.6903\n","Epoch 4: val_loss did not improve from 0.61495\n","238/238 [==============================] - 9s 39ms/step - loss: 0.5974 - acc: 0.6903 - val_loss: 0.6189 - val_acc: 0.6738\n","Epoch 5/100\n","238/238 [==============================] - ETA: 0s - loss: 0.5829 - acc: 0.7015\n","Epoch 5: val_loss did not improve from 0.61495\n","238/238 [==============================] - 10s 40ms/step - loss: 0.5829 - acc: 0.7015 - val_loss: 0.6193 - val_acc: 0.6705\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5668 - acc: 0.7127\n","Epoch 6: val_loss did not improve from 0.61495\n","238/238 [==============================] - 10s 43ms/step - loss: 0.5669 - acc: 0.7125 - val_loss: 0.6217 - val_acc: 0.6784\n","0.6973660188266371 0.6407919675423863 0.6607635694572217 0.5462934481697939\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4899 - acc: 0.8034\n","Epoch 1: val_loss improved from inf to 0.44090, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 13s 42ms/step - loss: 0.4897 - acc: 0.8035 - val_loss: 0.4409 - val_acc: 0.8152\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4404 - acc: 0.8180\n","Epoch 2: val_loss improved from 0.44090 to 0.43260, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 40ms/step - loss: 0.4407 - acc: 0.8177 - val_loss: 0.4326 - val_acc: 0.8170\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4239 - acc: 0.8220\n","Epoch 3: val_loss improved from 0.43260 to 0.42921, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 42ms/step - loss: 0.4239 - acc: 0.8219 - val_loss: 0.4292 - val_acc: 0.8161\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4121 - acc: 0.8223\n","Epoch 4: val_loss did not improve from 0.42921\n","238/238 [==============================] - 10s 40ms/step - loss: 0.4117 - acc: 0.8227 - val_loss: 0.4341 - val_acc: 0.8175\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4011 - acc: 0.8318\n","Epoch 5: val_loss did not improve from 0.42921\n","238/238 [==============================] - 9s 40ms/step - loss: 0.4011 - acc: 0.8315 - val_loss: 0.4306 - val_acc: 0.8239\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3854 - acc: 0.8358\n","Epoch 6: val_loss did not improve from 0.42921\n","238/238 [==============================] - 10s 42ms/step - loss: 0.3859 - acc: 0.8357 - val_loss: 0.4446 - val_acc: 0.8226\n","0.7203026740643378 0.3718834242389122 0.8242870285188593 0.13769751693002258\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3028 - acc: 0.9136\n","Epoch 1: val_loss improved from inf to 0.27193, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 12s 42ms/step - loss: 0.3032 - acc: 0.9132 - val_loss: 0.2719 - val_acc: 0.9219\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2598 - acc: 0.9214\n","Epoch 2: val_loss improved from 0.27193 to 0.26270, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 37ms/step - loss: 0.2598 - acc: 0.9215 - val_loss: 0.2627 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2464 - acc: 0.9225\n","Epoch 3: val_loss improved from 0.26270 to 0.26168, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 38ms/step - loss: 0.2463 - acc: 0.9225 - val_loss: 0.2617 - val_acc: 0.9251\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2361 - acc: 0.9232\n","Epoch 4: val_loss did not improve from 0.26168\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2359 - acc: 0.9233 - val_loss: 0.2684 - val_acc: 0.9251\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2254 - acc: 0.9248\n","Epoch 5: val_loss did not improve from 0.26168\n","238/238 [==============================] - 8s 36ms/step - loss: 0.2253 - acc: 0.9248 - val_loss: 0.2659 - val_acc: 0.9228\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2145 - acc: 0.9268\n","Epoch 6: val_loss did not improve from 0.26168\n","238/238 [==============================] - 9s 37ms/step - loss: 0.2143 - acc: 0.9268 - val_loss: 0.2636 - val_acc: 0.9205\n","0.7266555583076265 0.2153909105910104 0.9183532658693653 0.0273972602739726\n","Iteration number:  8\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2908 - acc: 0.9010\n","Epoch 1: val_loss improved from inf to 0.24709, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 11s 35ms/step - loss: 0.2906 - acc: 0.9010 - val_loss: 0.2471 - val_acc: 0.9104\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2424 - acc: 0.9144\n","Epoch 2: val_loss improved from 0.24709 to 0.22896, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2420 - acc: 0.9146 - val_loss: 0.2290 - val_acc: 0.9164\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2227 - acc: 0.9184\n","Epoch 3: val_loss improved from 0.22896 to 0.22780, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2226 - acc: 0.9185 - val_loss: 0.2278 - val_acc: 0.9173\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2093 - acc: 0.9232\n","Epoch 4: val_loss did not improve from 0.22780\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2090 - acc: 0.9233 - val_loss: 0.2284 - val_acc: 0.9201\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1943 - acc: 0.9275\n","Epoch 5: val_loss did not improve from 0.22780\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1945 - acc: 0.9275 - val_loss: 0.2426 - val_acc: 0.9048\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1779 - acc: 0.9331\n","Epoch 6: val_loss did not improve from 0.22780\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1778 - acc: 0.9332 - val_loss: 0.2381 - val_acc: 0.9122\n","0.8735307075513261 0.569076199158858 0.9149034038638455 0.40514469453376206\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9315\n","Epoch 1: val_loss improved from inf to 0.17730, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 11s 37ms/step - loss: 0.2212 - acc: 0.9315 - val_loss: 0.1773 - val_acc: 0.9381\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1774 - acc: 0.9419\n","Epoch 2: val_loss improved from 0.17730 to 0.17234, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1771 - acc: 0.9420 - val_loss: 0.1723 - val_acc: 0.9427\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9446\n","Epoch 3: val_loss improved from 0.17234 to 0.17095, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1606 - acc: 0.9447 - val_loss: 0.1709 - val_acc: 0.9427\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1475 - acc: 0.9498\n","Epoch 4: val_loss improved from 0.17095 to 0.16956, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1474 - acc: 0.9499 - val_loss: 0.1696 - val_acc: 0.9413\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9532\n","Epoch 5: val_loss improved from 0.16956 to 0.16748, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 36ms/step - loss: 0.1374 - acc: 0.9531 - val_loss: 0.1675 - val_acc: 0.9390\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9574\n","Epoch 6: val_loss did not improve from 0.16748\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1216 - acc: 0.9573 - val_loss: 0.1814 - val_acc: 0.9353\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9625\n","Epoch 7: val_loss did not improve from 0.16748\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1062 - acc: 0.9625 - val_loss: 0.1952 - val_acc: 0.9413\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9670\n","Epoch 8: val_loss did not improve from 0.16748\n","238/238 [==============================] - 8s 35ms/step - loss: 0.0892 - acc: 0.9670 - val_loss: 0.1935 - val_acc: 0.9376\n","0.8858837804516443 0.5361386360962066 0.9427322907083716 0.4823284823284823\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6949 - acc: 0.6142\n","Epoch 1: val_loss improved from inf to 0.62944, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.6947 - acc: 0.6140 - val_loss: 0.6294 - val_acc: 0.6664\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6327 - acc: 0.6594\n","Epoch 2: val_loss improved from 0.62944 to 0.61542, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.6324 - acc: 0.6598 - val_loss: 0.6154 - val_acc: 0.6793\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6125 - acc: 0.6771\n","Epoch 3: val_loss improved from 0.61542 to 0.61141, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.6127 - acc: 0.6767 - val_loss: 0.6114 - val_acc: 0.6811\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5983 - acc: 0.6903\n","Epoch 4: val_loss did not improve from 0.61141\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5983 - acc: 0.6904 - val_loss: 0.6165 - val_acc: 0.6710\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5837 - acc: 0.6990\n","Epoch 5: val_loss did not improve from 0.61141\n","238/238 [==============================] - 8s 34ms/step - loss: 0.5841 - acc: 0.6985 - val_loss: 0.6150 - val_acc: 0.6714\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5666 - acc: 0.7137\n","Epoch 6: val_loss did not improve from 0.61141\n","238/238 [==============================] - 8s 35ms/step - loss: 0.5666 - acc: 0.7139 - val_loss: 0.6259 - val_acc: 0.6617\n","0.700998195888525 0.6478226235909574 0.6614535418583257 0.5470769230769231\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4841 - acc: 0.8057\n","Epoch 1: val_loss improved from inf to 0.44371, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 33ms/step - loss: 0.4840 - acc: 0.8057 - val_loss: 0.4437 - val_acc: 0.8105\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4406 - acc: 0.8161\n","Epoch 2: val_loss improved from 0.44371 to 0.42922, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4403 - acc: 0.8163 - val_loss: 0.4292 - val_acc: 0.8198\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4247 - acc: 0.8228\n","Epoch 3: val_loss did not improve from 0.42922\n","238/238 [==============================] - 7s 31ms/step - loss: 0.4249 - acc: 0.8228 - val_loss: 0.4394 - val_acc: 0.8124\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4112 - acc: 0.8268\n","Epoch 4: val_loss improved from 0.42922 to 0.42511, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4111 - acc: 0.8267 - val_loss: 0.4251 - val_acc: 0.8179\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3996 - acc: 0.8309\n","Epoch 5: val_loss did not improve from 0.42511\n","238/238 [==============================] - 8s 33ms/step - loss: 0.3995 - acc: 0.8310 - val_loss: 0.4378 - val_acc: 0.8212\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3826 - acc: 0.8366\n","Epoch 6: val_loss did not improve from 0.42511\n","238/238 [==============================] - 8s 33ms/step - loss: 0.3829 - acc: 0.8364 - val_loss: 0.4438 - val_acc: 0.8082\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3617 - acc: 0.8493\n","Epoch 7: val_loss did not improve from 0.42511\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3617 - acc: 0.8493 - val_loss: 0.4353 - val_acc: 0.8161\n","0.7290418598867213 0.39093973167381263 0.8224471021159153 0.26195028680688337\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2934 - acc: 0.9180\n","Epoch 1: val_loss improved from inf to 0.27090, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.2937 - acc: 0.9179 - val_loss: 0.2709 - val_acc: 0.9242\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2588 - acc: 0.9215\n","Epoch 2: val_loss improved from 0.27090 to 0.26182, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2591 - acc: 0.9215 - val_loss: 0.2618 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2465 - acc: 0.9219\n","Epoch 3: val_loss improved from 0.26182 to 0.26101, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2466 - acc: 0.9220 - val_loss: 0.2610 - val_acc: 0.9242\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2368 - acc: 0.9229\n","Epoch 4: val_loss improved from 0.26101 to 0.25857, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2366 - acc: 0.9229 - val_loss: 0.2586 - val_acc: 0.9251\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2271 - acc: 0.9229\n","Epoch 5: val_loss did not improve from 0.25857\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2270 - acc: 0.9229 - val_loss: 0.2595 - val_acc: 0.9247\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2160 - acc: 0.9254\n","Epoch 6: val_loss did not improve from 0.25857\n","238/238 [==============================] - 8s 36ms/step - loss: 0.2158 - acc: 0.9255 - val_loss: 0.2737 - val_acc: 0.9228\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1992 - acc: 0.9294\n","Epoch 7: val_loss did not improve from 0.25857\n","238/238 [==============================] - 9s 36ms/step - loss: 0.1993 - acc: 0.9294 - val_loss: 0.2789 - val_acc: 0.9210\n","0.7337103983247393 0.2252030077304002 0.9188132474701012 0.06860158311345646\n","Iteration number:  9\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2915 - acc: 0.9006\n","Epoch 1: val_loss improved from inf to 0.24306, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 11s 36ms/step - loss: 0.2914 - acc: 0.9007 - val_loss: 0.2431 - val_acc: 0.9113\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2407 - acc: 0.9117\n","Epoch 2: val_loss improved from 0.24306 to 0.23834, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2404 - acc: 0.9119 - val_loss: 0.2383 - val_acc: 0.9159\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2253 - acc: 0.9190\n","Epoch 3: val_loss improved from 0.23834 to 0.23258, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2249 - acc: 0.9192 - val_loss: 0.2326 - val_acc: 0.9127\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2101 - acc: 0.9248\n","Epoch 4: val_loss did not improve from 0.23258\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2100 - acc: 0.9249 - val_loss: 0.2422 - val_acc: 0.9108\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9283\n","Epoch 5: val_loss improved from 0.23258 to 0.22824, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1984 - acc: 0.9282 - val_loss: 0.2282 - val_acc: 0.9145\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1830 - acc: 0.9333\n","Epoch 6: val_loss did not improve from 0.22824\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1831 - acc: 0.9334 - val_loss: 0.2565 - val_acc: 0.9145\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1655 - acc: 0.9417\n","Epoch 7: val_loss did not improve from 0.22824\n","238/238 [==============================] - 8s 34ms/step - loss: 0.1656 - acc: 0.9415 - val_loss: 0.2677 - val_acc: 0.9071\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9479\n","Epoch 8: val_loss did not improve from 0.22824\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1451 - acc: 0.9478 - val_loss: 0.2883 - val_acc: 0.9108\n","0.8715057494052341 0.572139510526084 0.9153633854645814 0.4757834757834758\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2156 - acc: 0.9346\n","Epoch 1: val_loss improved from inf to 0.17546, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.2156 - acc: 0.9346 - val_loss: 0.1755 - val_acc: 0.9409\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1760 - acc: 0.9422\n","Epoch 2: val_loss improved from 0.17546 to 0.17286, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1760 - acc: 0.9421 - val_loss: 0.1729 - val_acc: 0.9445\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1574 - acc: 0.9473\n","Epoch 3: val_loss improved from 0.17286 to 0.17194, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.1577 - acc: 0.9474 - val_loss: 0.1719 - val_acc: 0.9409\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1475 - acc: 0.9484\n","Epoch 4: val_loss did not improve from 0.17194\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1478 - acc: 0.9482 - val_loss: 0.1743 - val_acc: 0.9409\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9518\n","Epoch 5: val_loss did not improve from 0.17194\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1370 - acc: 0.9516 - val_loss: 0.1777 - val_acc: 0.9404\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9573\n","Epoch 6: val_loss did not improve from 0.17194\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1224 - acc: 0.9573 - val_loss: 0.1761 - val_acc: 0.9399\n","0.8797337578226196 0.5170093583403041 0.9431922723091076 0.44742729306487694\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6810 - acc: 0.6233\n","Epoch 1: val_loss improved from inf to 0.62644, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.6812 - acc: 0.6231 - val_loss: 0.6264 - val_acc: 0.6696\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6304 - acc: 0.6611\n","Epoch 2: val_loss improved from 0.62644 to 0.61522, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.6305 - acc: 0.6610 - val_loss: 0.6152 - val_acc: 0.6742\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6109 - acc: 0.6779\n","Epoch 3: val_loss did not improve from 0.61522\n","238/238 [==============================] - 8s 32ms/step - loss: 0.6109 - acc: 0.6779 - val_loss: 0.6163 - val_acc: 0.6719\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5986 - acc: 0.6891\n","Epoch 4: val_loss improved from 0.61522 to 0.61014, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5985 - acc: 0.6891 - val_loss: 0.6101 - val_acc: 0.6839\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5820 - acc: 0.6988\n","Epoch 5: val_loss did not improve from 0.61014\n","238/238 [==============================] - 8s 32ms/step - loss: 0.5819 - acc: 0.6989 - val_loss: 0.6152 - val_acc: 0.6710\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5661 - acc: 0.7131\n","Epoch 6: val_loss did not improve from 0.61014\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5662 - acc: 0.7129 - val_loss: 0.6214 - val_acc: 0.6668\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5443 - acc: 0.7333\n","Epoch 7: val_loss did not improve from 0.61014\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5445 - acc: 0.7331 - val_loss: 0.6173 - val_acc: 0.6798\n","0.7024914434186618 0.6466641737897725 0.6593836246550138 0.55961938745168\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4825 - acc: 0.8071\n","Epoch 1: val_loss improved from inf to 0.43899, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.4825 - acc: 0.8070 - val_loss: 0.4390 - val_acc: 0.8161\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4428 - acc: 0.8141\n","Epoch 2: val_loss improved from 0.43899 to 0.42876, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.4425 - acc: 0.8143 - val_loss: 0.4288 - val_acc: 0.8198\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4245 - acc: 0.8211\n","Epoch 3: val_loss did not improve from 0.42876\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4245 - acc: 0.8211 - val_loss: 0.4292 - val_acc: 0.8198\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4127 - acc: 0.8242\n","Epoch 4: val_loss did not improve from 0.42876\n","238/238 [==============================] - 8s 34ms/step - loss: 0.4127 - acc: 0.8243 - val_loss: 0.4350 - val_acc: 0.8161\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3993 - acc: 0.8298\n","Epoch 5: val_loss did not improve from 0.42876\n","238/238 [==============================] - 8s 33ms/step - loss: 0.4001 - acc: 0.8294 - val_loss: 0.4355 - val_acc: 0.8184\n","0.7159408533349528 0.3791260276270562 0.8256669733210672 0.2153209109730849\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2977 - acc: 0.9148\n","Epoch 1: val_loss improved from inf to 0.27371, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.2975 - acc: 0.9147 - val_loss: 0.2737 - val_acc: 0.9177\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2610 - acc: 0.9218\n","Epoch 2: val_loss improved from 0.27371 to 0.26569, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2610 - acc: 0.9218 - val_loss: 0.2657 - val_acc: 0.9251\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2462 - acc: 0.9216\n","Epoch 3: val_loss improved from 0.26569 to 0.26245, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2460 - acc: 0.9215 - val_loss: 0.2625 - val_acc: 0.9247\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2352 - acc: 0.9231\n","Epoch 4: val_loss improved from 0.26245 to 0.25603, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2353 - acc: 0.9231 - val_loss: 0.2560 - val_acc: 0.9247\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2232 - acc: 0.9242\n","Epoch 5: val_loss did not improve from 0.25603\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2234 - acc: 0.9242 - val_loss: 0.2622 - val_acc: 0.9238\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2110 - acc: 0.9260\n","Epoch 6: val_loss did not improve from 0.25603\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2108 - acc: 0.9261 - val_loss: 0.2686 - val_acc: 0.9247\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1945 - acc: 0.9307\n","Epoch 7: val_loss did not improve from 0.25603\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1946 - acc: 0.9307 - val_loss: 0.2754 - val_acc: 0.9177\n","0.734680737880255 0.20528169108174302 0.9174333026678932 0.021798365122615803\n","Iteration number:  10\n","Problem type:  mort_hosp\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2869 - acc: 0.9025\n","Epoch 1: val_loss improved from inf to 0.23949, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.2865 - acc: 0.9026 - val_loss: 0.2395 - val_acc: 0.9177\n","Epoch 2/100\n","238/238 [==============================] - ETA: 0s - loss: 0.2435 - acc: 0.9143\n","Epoch 2: val_loss improved from 0.23949 to 0.23180, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2435 - acc: 0.9143 - val_loss: 0.2318 - val_acc: 0.9122\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2250 - acc: 0.9182\n","Epoch 3: val_loss improved from 0.23180 to 0.22773, saving model to avg-concat-mort_hosp-best_model.hdf5\n","238/238 [==============================] - 8s 35ms/step - loss: 0.2247 - acc: 0.9185 - val_loss: 0.2277 - val_acc: 0.9177\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2121 - acc: 0.9239\n","Epoch 4: val_loss did not improve from 0.22773\n","238/238 [==============================] - 8s 33ms/step - loss: 0.2121 - acc: 0.9238 - val_loss: 0.2282 - val_acc: 0.9173\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1985 - acc: 0.9251\n","Epoch 5: val_loss did not improve from 0.22773\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1982 - acc: 0.9253 - val_loss: 0.2335 - val_acc: 0.9154\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9340\n","Epoch 6: val_loss did not improve from 0.22773\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1810 - acc: 0.9340 - val_loss: 0.2391 - val_acc: 0.9182\n","0.8824879945369637 0.5928706589823802 0.9172033118675254 0.45783132530120485\n","Problem type:  mort_icu\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2203 - acc: 0.9328\n","Epoch 1: val_loss improved from inf to 0.17742, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 10s 34ms/step - loss: 0.2197 - acc: 0.9330 - val_loss: 0.1774 - val_acc: 0.9399\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1753 - acc: 0.9427\n","Epoch 2: val_loss improved from 0.17742 to 0.17025, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1755 - acc: 0.9428 - val_loss: 0.1703 - val_acc: 0.9385\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1610 - acc: 0.9465\n","Epoch 3: val_loss did not improve from 0.17025\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1612 - acc: 0.9464 - val_loss: 0.1711 - val_acc: 0.9427\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9488\n","Epoch 4: val_loss improved from 0.17025 to 0.16416, saving model to avg-concat-mort_icu-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1499 - acc: 0.9488 - val_loss: 0.1642 - val_acc: 0.9427\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9523\n","Epoch 5: val_loss did not improve from 0.16416\n","238/238 [==============================] - 7s 31ms/step - loss: 0.1378 - acc: 0.9524 - val_loss: 0.1696 - val_acc: 0.9390\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1244 - acc: 0.9547\n","Epoch 6: val_loss did not improve from 0.16416\n","238/238 [==============================] - 8s 32ms/step - loss: 0.1241 - acc: 0.9549 - val_loss: 0.1865 - val_acc: 0.9409\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9619\n","Epoch 7: val_loss did not improve from 0.16416\n","238/238 [==============================] - 8s 33ms/step - loss: 0.1094 - acc: 0.9617 - val_loss: 0.1830 - val_acc: 0.9404\n","0.8877061972314559 0.5129383891432556 0.9420423183072677 0.43243243243243246\n","Problem type:  los_3\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6800 - acc: 0.6176\n","Epoch 1: val_loss improved from inf to 0.62752, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 10s 35ms/step - loss: 0.6801 - acc: 0.6176 - val_loss: 0.6275 - val_acc: 0.6650\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6286 - acc: 0.6641\n","Epoch 2: val_loss improved from 0.62752 to 0.61608, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 32ms/step - loss: 0.6288 - acc: 0.6638 - val_loss: 0.6161 - val_acc: 0.6844\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.6099 - acc: 0.6778\n","Epoch 3: val_loss did not improve from 0.61608\n","238/238 [==============================] - 8s 33ms/step - loss: 0.6099 - acc: 0.6779 - val_loss: 0.6285 - val_acc: 0.6677\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5986 - acc: 0.6874\n","Epoch 4: val_loss improved from 0.61608 to 0.61115, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5984 - acc: 0.6874 - val_loss: 0.6111 - val_acc: 0.6738\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5834 - acc: 0.6981\n","Epoch 5: val_loss improved from 0.61115 to 0.60915, saving model to avg-concat-los_3-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5830 - acc: 0.6987 - val_loss: 0.6091 - val_acc: 0.6825\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5646 - acc: 0.7151\n","Epoch 6: val_loss did not improve from 0.60915\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5645 - acc: 0.7152 - val_loss: 0.6217 - val_acc: 0.6724\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5437 - acc: 0.7292\n","Epoch 7: val_loss did not improve from 0.60915\n","238/238 [==============================] - 8s 33ms/step - loss: 0.5437 - acc: 0.7292 - val_loss: 0.6186 - val_acc: 0.6719\n","Epoch 8/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.5136 - acc: 0.7513\n","Epoch 8: val_loss did not improve from 0.60915\n","238/238 [==============================] - 8s 32ms/step - loss: 0.5139 - acc: 0.7510 - val_loss: 0.6451 - val_acc: 0.6617\n","0.6977401129943502 0.6418404042603052 0.6603035878564857 0.5692621755613881\n","Problem type:  los_5\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4841 - acc: 0.8061\n","Epoch 1: val_loss improved from inf to 0.44240, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 11s 35ms/step - loss: 0.4840 - acc: 0.8061 - val_loss: 0.4424 - val_acc: 0.8165\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4407 - acc: 0.8171\n","Epoch 2: val_loss improved from 0.44240 to 0.42832, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.4403 - acc: 0.8175 - val_loss: 0.4283 - val_acc: 0.8165\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4247 - acc: 0.8230\n","Epoch 3: val_loss did not improve from 0.42832\n","238/238 [==============================] - 8s 32ms/step - loss: 0.4249 - acc: 0.8229 - val_loss: 0.4283 - val_acc: 0.8152\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.4128 - acc: 0.8250\n","Epoch 4: val_loss improved from 0.42832 to 0.42665, saving model to avg-concat-los_5-best_model.hdf5\n","238/238 [==============================] - 8s 33ms/step - loss: 0.4124 - acc: 0.8252 - val_loss: 0.4267 - val_acc: 0.8221\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3997 - acc: 0.8310\n","Epoch 5: val_loss did not improve from 0.42665\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3997 - acc: 0.8311 - val_loss: 0.4364 - val_acc: 0.8207\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3857 - acc: 0.8370\n","Epoch 6: val_loss did not improve from 0.42665\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3859 - acc: 0.8370 - val_loss: 0.4392 - val_acc: 0.8189\n","Epoch 7/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.3675 - acc: 0.8484\n","Epoch 7: val_loss did not improve from 0.42665\n","238/238 [==============================] - 8s 34ms/step - loss: 0.3673 - acc: 0.8484 - val_loss: 0.4440 - val_acc: 0.8147\n","0.7156299660626777 0.37701960568314163 0.8263569457221711 0.16941694169416943\n","Problem type:  los_7\n","__________________\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Epoch 1/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2953 - acc: 0.9153\n","Epoch 1: val_loss improved from inf to 0.26762, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 11s 35ms/step - loss: 0.2949 - acc: 0.9155 - val_loss: 0.2676 - val_acc: 0.9242\n","Epoch 2/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2584 - acc: 0.9211\n","Epoch 2: val_loss improved from 0.26762 to 0.26627, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 8s 34ms/step - loss: 0.2580 - acc: 0.9213 - val_loss: 0.2663 - val_acc: 0.9247\n","Epoch 3/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2463 - acc: 0.9221\n","Epoch 3: val_loss improved from 0.26627 to 0.25873, saving model to avg-concat-los_7-best_model.hdf5\n","238/238 [==============================] - 9s 36ms/step - loss: 0.2460 - acc: 0.9222 - val_loss: 0.2587 - val_acc: 0.9242\n","Epoch 4/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2357 - acc: 0.9236\n","Epoch 4: val_loss did not improve from 0.25873\n","238/238 [==============================] - 9s 38ms/step - loss: 0.2363 - acc: 0.9233 - val_loss: 0.2608 - val_acc: 0.9251\n","Epoch 5/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2264 - acc: 0.9236\n","Epoch 5: val_loss did not improve from 0.25873\n","238/238 [==============================] - 9s 38ms/step - loss: 0.2265 - acc: 0.9236 - val_loss: 0.2724 - val_acc: 0.9242\n","Epoch 6/100\n","237/238 [============================>.] - ETA: 0s - loss: 0.2123 - acc: 0.9273\n","Epoch 6: val_loss did not improve from 0.25873\n","238/238 [==============================] - 9s 38ms/step - loss: 0.2130 - acc: 0.9271 - val_loss: 0.2768 - val_acc: 0.9145\n","0.7235348506000765 0.2074304727347698 0.9185832566697332 0.016666666666666666\n"]}],"source":["#embedding_types = ['concat']\n","#embedding_dict = [ner_concat]\n","#target_problems = ['mort_hosp']\n","\n","embedding_types = ['word2vec', 'fasttext', 'concat']\n","embedding_dict = [ner_word2vec, ner_fasttext, ner_concat]\n","target_problems = ['mort_hosp', 'mort_icu', 'los_3', 'los_5', 'los_7']\n","\n","\n","#num_epoch = 2\n","num_epoch = 100\n","model_patience = 3\n","monitor_criteria = 'val_loss'\n","batch_size = 64\n","iter_num = 11\n","#iter_num = 2\n","unit_sizes = [128, 256]\n","#unit_sizes = [256]\n","#unit_sizes = [128]\n","#layers = [\"LSTM\", \"GRU\"]\n","layers = [\"GRU\"]\n","\n","for each_layer in layers:\n","    print (\"Layer: \", each_layer)\n","    for each_unit_size in unit_sizes:\n","        print (\"Hidden unit: \", each_unit_size)\n","\n","        for embed_dict, embed_name in zip(embedding_dict, embedding_types):    \n","            print (\"Embedding: \", embed_name)\n","            print(\"=============================\")\n","\n","            temp_train_ner = dict((k, ner_word2vec[k]) for k in train_ids)\n","            temp_dev_ner = dict((k, ner_word2vec[k]) for k in dev_ids)\n","            temp_test_ner = dict((k, ner_word2vec[k]) for k in test_ids)\n","\n","            #print(\"temp_train_ner: \", temp_train_ner.shape)\n","            #print(\"temp_dev_ner: \", temp_dev_ner.shape)\n","            #print(\"temp_test_ner: \", temp_test_ner.shape)\n","\n","            x_train_ner = create_dataset(temp_train_ner)\n","            x_dev_ner = create_dataset(temp_dev_ner)\n","            x_test_ner = create_dataset(temp_test_ner)\n","\n","            for iteration in range(1, iter_num):\n","                print (\"Iteration number: \", iteration)\n","\n","                for each_problem in target_problems:\n","                    print (\"Problem type: \", each_problem)\n","                    print (\"__________________\")\n","\n","                    early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n","                    best_model_name = \"avg-\"+str(embed_name)+\"-\"+str(each_problem)+\"-\"+\"best_model.hdf5\"\n","                    checkpoint = ModelCheckpoint(best_model_name, monitor='val_loss', verbose=1,\n","                        save_best_only=True, mode='min', period=1)\n","\n","\n","                    callbacks = [early_stopping_monitor, checkpoint]\n","\n","                    model = avg_ner_model(each_layer, each_unit_size, embed_name)\n","                    \n","                    #print(\"x_train_lstm: \", x_train_lstm.shape)\n","                    #print(\"x_train_ner: \", x_train_ner.shape)\n","                    #print(\"y_train[each_problem]: \", (y_train[each_problem]).shape)\n","                    #print(\"x_dev_lstm: \", x_dev_lstm.shape)\n","                    #print(\"x_dev_ner: \", x_dev_ner.shape)\n","                    #print(\"y_dev[each_problem]: \", (y_dev[each_problem]).shape)\n","\n","\n","                    model.fit([x_train_lstm, x_train_ner], y_train[each_problem], epochs=num_epoch, verbose=1, \n","                              validation_data=([x_dev_lstm, x_dev_ner], y_dev[each_problem]), callbacks=callbacks, \n","                              batch_size=batch_size )\n","\n","                    model.load_weights(best_model_name)\n","\n","                    probs, predictions = make_prediction_multi_avg(model, [x_test_lstm, x_test_ner])\n","                    \n","                    save_scores_multi_avg(predictions, probs, y_test[each_problem], \n","                                embed_name, each_problem, iteration, each_unit_size, \n","                                each_layer, type_of_ner)\n","                    \n","                    reset_keras(model)\n","                    #del model\n","                    clear_session()\n","                    gc.collect()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"name":"08-Multimodal-Baseline_LoS.ipynb","provenance":[{"file_id":"1UVCwqEa9oBTs454oPvT02Bolfu_jYiqr","timestamp":1651118759028}],"machine_shape":"hm","collapsed_sections":[]},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}