{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASkw1OAYfZSW","executionInfo":{"status":"ok","timestamp":1649393170665,"user_tz":300,"elapsed":15676,"user":{"displayName":"Suraj Bisht","userId":"14494261012766270308"}},"outputId":"6af75523-014a-40ad-db2d-6fe4d0820493"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["print(os.path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4tH6OBAMhIvz","executionInfo":{"status":"ok","timestamp":1649393599518,"user_tz":300,"elapsed":125,"user":{"displayName":"Suraj Bisht","userId":"14494261012766270308"}},"outputId":"45fd0762-9862-475b-ed92-0f5cce59b413"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<module 'posixpath' from '/usr/lib/python3.7/posixpath.py'>\n"]}]},{"cell_type":"code","source":["# This code is taken from https://github.com/kaggarwal/ClinicalNotesICU\n","\n","from nltk import sent_tokenize, word_tokenize\n","import re\n","import pandas as pd\n","\n","SECTION_TITLES = re.compile(\n","    r'('\n","    r'ABDOMEN AND PELVIS|CLINICAL HISTORY|CLINICAL INDICATION|COMPARISON|COMPARISON STUDY DATE'\n","    r'|EXAM|EXAMINATION|FINDINGS|HISTORY|IMPRESSION|INDICATION'\n","    r'|MEDICAL CONDITION|PROCEDURE|REASON FOR EXAM|REASON FOR STUDY|REASON FOR THIS EXAMINATION'\n","    r'|TECHNIQUE'\n","    r'):|FINAL REPORT',\n","    re.I | re.M)\n","    \n","    \n","def getSentences(t):\n","    return list(preprocess_mimic(t))\n","    \n","def pattern_repl(matchobj):\n","    \"\"\"\n","    Return a replacement string to be used for match object\n","    \"\"\"\n","    return ' '.rjust(len(matchobj.group(0)))\n","    \n","def clean_text(text):\n","    \"\"\"\n","    Clean text\n","    \"\"\"\n","\n","    # Replace [**Patterns**] with spaces.\n","    text = re.sub(r'\\[\\*\\*.*?\\*\\*\\]', pattern_repl, text)\n","    # Replace `_` with spaces.\n","    text = re.sub(r'_', ' ', text)\n","\n","    start = 0\n","    end = find_end(text)\n","    new_text = ''\n","    if start > 0:\n","        new_text += ' ' * start\n","    new_text = text[start:end]\n","\n","    # make sure the new text has the same length of old text.\n","    if len(text) - end > 0:\n","        new_text += ' ' * (len(text) - end)\n","    return new_text\n","\n","def preprocess_mimic(text):\n","    \"\"\"\n","    Preprocess reports in MIMIC-III.\n","    1. remove [**Patterns**] and signature\n","    2. split the report into sections\n","    3. tokenize sentences and words\n","    4. lowercase\n","    \"\"\"\n","    for sec in split_heading(clean_text(text)):\n","        for sent in sent_tokenize(sec):\n","            text = ' '.join(word_tokenize(sent))\n","            yield text.lower()\n","            \n","def split_heading(text):\n","    \"\"\"Split the report into sections\"\"\"\n","    start = 0\n","    for matcher in SECTION_TITLES.finditer(text):\n","        # add last\n","        end = matcher.start()\n","        if end != start:\n","            section = text[start:end].strip()\n","            if section:\n","                yield section\n","\n","        # add title\n","        start = end\n","        end = matcher.end()\n","        if end != start:\n","            section = text[start:end].strip()\n","            if section:\n","                yield section\n","\n","        start = end\n","\n","    # add last piece\n","    end = len(text)\n","    if start < end:\n","        section = text[start:end].strip()\n","        if section:\n","            yield section\n","            \n","def find_end(text):\n","    \"\"\"Find the end of the report.\"\"\"\n","    ends = [len(text)]\n","    patterns = [\n","        re.compile(r'BY ELECTRONICALLY SIGNING THIS REPORT', re.I),\n","        re.compile(r'\\n {3,}DR.', re.I),\n","        re.compile(r'[ ]{1,}RADLINE ', re.I),\n","        re.compile(r'.*electronically signed on', re.I),\n","        re.compile(r'M\\[0KM\\[0KM')\n","    ]\n","    for pattern in patterns:\n","        matchobj = pattern.search(text)\n","        if matchobj:\n","            ends.append(matchobj.start())\n","    return min(ends)"],"metadata":{"id":"fKSV4KOxhm43"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1LPtixMOfXS0"},"outputs":[],"source":["PREPROCESS = \"/content/drive/MyDrive/Colab Notebooks/ConvolutionMedicalNer-master/data/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HMGhdGXSfXSp"},"outputs":[],"source":["import pandas as pd\n","import os\n","import numpy as np\n","import re\n","\n","#import (os.path.join(PREPROCESS, \"preprocess.py\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BnQe_dtKfXS2","executionInfo":{"status":"ok","timestamp":1649393731192,"user_tz":300,"elapsed":2328,"user":{"displayName":"Suraj Bisht","userId":"14494261012766270308"}},"outputId":"e95f89a4-6793-4024-f0e8-7d8608de9c47"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(181483, 20)"]},"metadata":{},"execution_count":13}],"source":["clinical_notes = pd.read_pickle(os.path.join(PREPROCESS, \"sub_notes.p\"))\n","clinical_notes.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wcywgJghfXS4"},"outputs":[],"source":["sub_notes = clinical_notes[clinical_notes.SUBJECT_ID.notnull()]\n","sub_notes = sub_notes[sub_notes.CHARTTIME.notnull()]\n","sub_notes = sub_notes[sub_notes.TEXT.notnull()]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TX1T9Ba_fXS5","executionInfo":{"status":"ok","timestamp":1649393739194,"user_tz":300,"elapsed":97,"user":{"displayName":"Suraj Bisht","userId":"14494261012766270308"}},"outputId":"b146262b-6564-4207-9721-930bd83ad3bd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(181483, 20)"]},"metadata":{},"execution_count":15}],"source":["sub_notes.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dln220pFfXS7"},"outputs":[],"source":["sub_notes = sub_notes[['SUBJECT_ID', 'HADM_ID_y', 'CHARTTIME', 'TEXT']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q86KNQRPfXS9"},"outputs":[],"source":["sub_notes['preprocessed_text'] = None"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1W6on9r1fXS-","executionInfo":{"status":"ok","timestamp":1649395133341,"user_tz":300,"elapsed":987931,"user":{"displayName":"Suraj Bisht","userId":"14494261012766270308"}},"outputId":"808e566f-054f-45ee-9175-1cbdab7b3344"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import nltk\n","nltk.download('punkt')\n","for each_note in sub_notes.itertuples():\n","    text = each_note.TEXT\n","    #sub_notes.at[each_note.Index, 'preprocessed_text'] = preprocess.getSentences(text)\n","    sub_notes.at[each_note.Index, 'preprocessed_text'] = getSentences(text)"]},{"cell_type":"markdown","metadata":{"id":"l06CwqhBfXTA"},"source":["### Save notes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UoQQzeBPfXTF"},"outputs":[],"source":["pd.to_pickle(sub_notes, os.path.join(PREPROCESS, \"preprocessed_notes.p\"))"]},{"cell_type":"markdown","metadata":{"id":"qxYFyRcBfXTI"},"source":["### Additional preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GKa8nzD5fXTK"},"outputs":[],"source":["# sub_notes = pd.read_pickle(os.path.join(PREPROCESS, \"preprocessed_notes.p\"))\n","\n","# def preprocess1(x):\n","#     y=re.sub('\\\\[(.*?)\\\\]','',x) #remove de-identified brackets\n","#     y=re.sub('[0-9]+\\.','',y) #remove 1.2. since the segmenter segments based on this\n","#     y=re.sub('dr\\.','doctor',y)\n","#     y=re.sub('m\\.d\\.','md',y)\n","#     y=re.sub('admission date:','',y)\n","#     y=re.sub('discharge date:','',y)\n","#     y=re.sub('--|__|==','',y)\n","#     return y\n","\n","# def preprocessing(df_less_n): \n","#     df_less_n['preprocessed_text_v2']=df_less_n['preprocessed_text'].fillna(' ')\n","#     df_less_n['preprocessed_text_v2']=df_less_n['preprocessed_text_v2'].str.replace('\\n',' ')\n","#     #df_less_n['preprocessed_text_v2']=df_less_n['preprocessed_text_v2'].str.replace('\\r',' ')\n","#     #df_less_n['preprocessed_text_v2']=df_less_n['preprocessed_text_v2'].apply(str.strip)\n","#     #df_less_n['preprocessed_text_v2']=df_less_n['preprocessed_text_v2'].str.lower()\n","\n","#     df_less_n['preprocessed_text_v2']=df_less_n['preprocessed_text_v2'].apply(lambda x: preprocess1(x))\n","    \n","# sub_notes = preprocessing(sub_notes)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"name":"03-Preprocess-Clinical-Notes.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}